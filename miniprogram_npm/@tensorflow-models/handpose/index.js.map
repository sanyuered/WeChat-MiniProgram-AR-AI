{"version":3,"sources":["index.js","hand.js","box.js","keypoints.js","pipeline.js","util.js"],"names":[],"mappings":";;;;;;;AAAA;AACA;AACA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;AELA,ADGA,ADGA;AELA,ADGA,ADGA;AELA,ADGA,ADGA;AELA,ADGA,ADGA,AGTA;ADIA,ADGA,ADGA,AGTA;ADIA,ADGA,ADGA,AGTA;ADIA,ADGA,ADGA,AGTA,ACHA;AFOA,ADGA,ADGA,AGTA,ACHA;AFOA,ADGA,ADGA,AGTA,ACHA;AFOA,ADGA,ADGA,AGTA,ACHA,ACHA;AHUA,ADGA,ADGA,AGTA,ACHA,ACHA;AHUA,ADGA,ADGA,AGTA,ACHA,ACHA;AHUA,ADGA,ADGA,AGTA,ACHA,ACHA;AHUA,ADGA,ADGA,AGTA,ACHA,ACHA;AHUA,ADGA,ADGA,AGTA,ACHA,ACHA;AHUA,ADGA,ADGA,AGTA,ACHA,ACHA;AHUA,ADGA,ADGA,AGTA,ACHA,ACHA;AHUA,ADGA,ADGA,AGTA,ACHA,ACHA;AHUA,ADGA,ADGA,AGTA,ACHA,ACHA;AHUA,ADGA,ADGA,AGTA,ACHA,ACHA;AHUA,ADGA,ADGA,AGTA,ACHA,ACHA;AHUA,ADGA,ADGA,AGTA,ACHA,ACHA;AHUA,ADGA,ADGA,AGTA,ACHA,ACHA;AHUA,ADGA,ADGA,AGTA,ACHA,ACHA;AHUA,ADGA,ADGA,AGTA,ACHA,ACHA;AHUA,ADGA,ADGA,AGTA,ACHA,ACHA;AHUA,ADGA,ADGA,AGTA,ACHA,ACHA;AHUA,ADGA,ADGA,AGTA,ACHA,ACHA;AHUA,ADGA,ADGA,AGTA,ACHA,ACHA;AHUA,ADGA,ADGA,AGTA,ACHA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AHUA,ADGA,ADGA,AIZA,ACHA;AJaA,ADGA,AIZA,ACHA;AJaA,ADGA,AIZA,ACHA;AJaA,ADGA,AIZA,ACHA;AJaA,ADGA,AIZA,ACHA;AJaA,ADGA,AIZA,ACHA;AJaA,ADGA,AIZA,ACHA;AJaA,ADGA,AIZA,ACHA;AJaA,ADGA,AIZA,ACHA;AJaA,ADGA,AIZA,ACHA;AJaA,ADGA,AIZA,ACHA;AJaA,ADGA,AIZA,ACHA;AJaA,ADGA,AIZA,ACHA;AJaA,ADGA,AIZA,ACHA;AJaA,ADGA,AIZA,ACHA;AJaA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AHUA,ADGA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"index.js","sourcesContent":["\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tfconv = require(\"@tensorflow/tfjs-converter\");\nvar tf = require(\"@tensorflow/tfjs-core\");\nvar hand_1 = require(\"./hand\");\nvar keypoints_1 = require(\"./keypoints\");\nvar pipeline_1 = require(\"./pipeline\");\n// Load the bounding box detector model.\nfunction loadHandDetectorModel() {\n    return __awaiter(this, void 0, void 0, function () {\n        var HANDDETECT_MODEL_PATH;\n        return __generator(this, function (_a) {\n            HANDDETECT_MODEL_PATH = 'https://tfhub.dev/mediapipe/tfjs-model/handdetector/1/default/1';\n            return [2 /*return*/, tfconv.loadGraphModel(HANDDETECT_MODEL_PATH, { fromTFHub: true })];\n        });\n    });\n}\nvar MESH_MODEL_INPUT_WIDTH = 256;\nvar MESH_MODEL_INPUT_HEIGHT = 256;\n// Load the mesh detector model.\nfunction loadHandPoseModel() {\n    return __awaiter(this, void 0, void 0, function () {\n        var HANDPOSE_MODEL_PATH;\n        return __generator(this, function (_a) {\n            HANDPOSE_MODEL_PATH = 'https://tfhub.dev/mediapipe/tfjs-model/handskeleton/1/default/1';\n            return [2 /*return*/, tfconv.loadGraphModel(HANDPOSE_MODEL_PATH, { fromTFHub: true })];\n        });\n    });\n}\n// In single shot detector pipelines, the output space is discretized into a set\n// of bounding boxes, each of which is assigned a score during prediction. The\n// anchors define the coordinates of these boxes.\nfunction loadAnchors() {\n    return __awaiter(this, void 0, void 0, function () {\n        return __generator(this, function (_a) {\n            return [2 /*return*/, tf.util\n                    .fetch('https://tfhub.dev/mediapipe/tfjs-model/handskeleton/1/default/1/anchors.json?tfjs-format=file')\n                    .then(function (d) { return d.json(); })];\n        });\n    });\n}\n/**\n * Load handpose.\n *\n * @param config A configuration object with the following properties:\n * - `maxContinuousChecks` How many frames to go without running the bounding\n * box detector. Defaults to infinity. Set to a lower value if you want a safety\n * net in case the mesh detector produces consistently flawed predictions.\n * - `detectionConfidence` Threshold for discarding a prediction. Defaults to\n * 0.8.\n * - `iouThreshold` A float representing the threshold for deciding whether\n * boxes overlap too much in non-maximum suppression. Must be between [0, 1].\n * Defaults to 0.3.\n * - `scoreThreshold` A threshold for deciding when to remove boxes based\n * on score in non-maximum suppression. Defaults to 0.75.\n */\nfunction load(_a) {\n    var _b = _a === void 0 ? {} : _a, _c = _b.maxContinuousChecks, maxContinuousChecks = _c === void 0 ? Infinity : _c, _d = _b.detectionConfidence, detectionConfidence = _d === void 0 ? 0.8 : _d, _e = _b.iouThreshold, iouThreshold = _e === void 0 ? 0.3 : _e, _f = _b.scoreThreshold, scoreThreshold = _f === void 0 ? 0.5 : _f;\n    return __awaiter(this, void 0, void 0, function () {\n        var _g, ANCHORS, handDetectorModel, handPoseModel, detector, pipeline, handpose;\n        return __generator(this, function (_h) {\n            switch (_h.label) {\n                case 0: return [4 /*yield*/, Promise.all([loadAnchors(), loadHandDetectorModel(), loadHandPoseModel()])];\n                case 1:\n                    _g = _h.sent(), ANCHORS = _g[0], handDetectorModel = _g[1], handPoseModel = _g[2];\n                    detector = new hand_1.HandDetector(handDetectorModel, MESH_MODEL_INPUT_WIDTH, MESH_MODEL_INPUT_HEIGHT, ANCHORS, iouThreshold, scoreThreshold);\n                    pipeline = new pipeline_1.HandPipeline(detector, handPoseModel, MESH_MODEL_INPUT_WIDTH, MESH_MODEL_INPUT_HEIGHT, maxContinuousChecks, detectionConfidence);\n                    handpose = new HandPose(pipeline);\n                    return [2 /*return*/, handpose];\n            }\n        });\n    });\n}\nexports.load = load;\nfunction getInputTensorDimensions(input) {\n    return input instanceof tf.Tensor ? [input.shape[0], input.shape[1]] :\n        [input.height, input.width];\n}\nfunction flipHandHorizontal(prediction, width) {\n    var handInViewConfidence = prediction.handInViewConfidence, landmarks = prediction.landmarks, boundingBox = prediction.boundingBox;\n    return {\n        handInViewConfidence: handInViewConfidence,\n        landmarks: landmarks.map(function (coord) {\n            return [width - 1 - coord[0], coord[1], coord[2]];\n        }),\n        boundingBox: {\n            topLeft: [width - 1 - boundingBox.topLeft[0], boundingBox.topLeft[1]],\n            bottomRight: [\n                width - 1 - boundingBox.bottomRight[0], boundingBox.bottomRight[1]\n            ]\n        }\n    };\n}\nvar HandPose = /** @class */ (function () {\n    function HandPose(pipeline) {\n        this.pipeline = pipeline;\n    }\n    HandPose.getAnnotations = function () {\n        return keypoints_1.MESH_ANNOTATIONS;\n    };\n    /**\n     * Finds hands in the input image.\n     *\n     * @param input The image to classify. Can be a tensor, DOM element image,\n     * video, or canvas.\n     * @param flipHorizontal Whether to flip the hand keypoints horizontally.\n     * Should be true for videos that are flipped by default (e.g. webcams).\n     */\n    HandPose.prototype.estimateHands = function (input, flipHorizontal) {\n        if (flipHorizontal === void 0) { flipHorizontal = false; }\n        return __awaiter(this, void 0, void 0, function () {\n            var _a, width, image, result, prediction, annotations, _i, _b, key;\n            return __generator(this, function (_c) {\n                switch (_c.label) {\n                    case 0:\n                        _a = getInputTensorDimensions(input), width = _a[1];\n                        image = tf.tidy(function () {\n                            if (!(input instanceof tf.Tensor)) {\n                                input = tf.browser.fromPixels(input);\n                            }\n                            return input.toFloat().expandDims(0);\n                        });\n                        return [4 /*yield*/, this.pipeline.estimateHand(image)];\n                    case 1:\n                        result = _c.sent();\n                        image.dispose();\n                        if (result === null) {\n                            return [2 /*return*/, []];\n                        }\n                        prediction = result;\n                        if (flipHorizontal === true) {\n                            prediction = flipHandHorizontal(result, width);\n                        }\n                        annotations = {};\n                        for (_i = 0, _b = Object.keys(keypoints_1.MESH_ANNOTATIONS); _i < _b.length; _i++) {\n                            key = _b[_i];\n                            annotations[key] =\n                                keypoints_1.MESH_ANNOTATIONS[key].map(function (index) { return prediction.landmarks[index]; });\n                        }\n                        return [2 /*return*/, [{\n                                    handInViewConfidence: prediction.handInViewConfidence,\n                                    boundingBox: prediction.boundingBox,\n                                    landmarks: prediction.landmarks,\n                                    annotations: annotations\n                                }]];\n                }\n            });\n        });\n    };\n    return HandPose;\n}());\nexports.HandPose = HandPose;\n//# sourceMappingURL=index.js.map","\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tf = require(\"@tensorflow/tfjs-core\");\nvar box_1 = require(\"./box\");\nvar HandDetector = /** @class */ (function () {\n    function HandDetector(model, width, height, anchors, iouThreshold, scoreThreshold) {\n        this.model = model;\n        this.width = width;\n        this.height = height;\n        this.iouThreshold = iouThreshold;\n        this.scoreThreshold = scoreThreshold;\n        this.anchors = anchors.map(function (anchor) { return [anchor.x_center, anchor.y_center]; });\n        this.anchorsTensor = tf.tensor2d(this.anchors);\n        this.inputSizeTensor = tf.tensor1d([width, height]);\n        this.doubleInputSizeTensor = tf.tensor1d([width * 2, height * 2]);\n    }\n    HandDetector.prototype.normalizeBoxes = function (boxes) {\n        var _this = this;\n        return tf.tidy(function () {\n            var boxOffsets = tf.slice(boxes, [0, 0], [-1, 2]);\n            var boxSizes = tf.slice(boxes, [0, 2], [-1, 2]);\n            var boxCenterPoints = tf.add(tf.div(boxOffsets, _this.inputSizeTensor), _this.anchorsTensor);\n            var halfBoxSizes = tf.div(boxSizes, _this.doubleInputSizeTensor);\n            var startPoints = tf.mul(tf.sub(boxCenterPoints, halfBoxSizes), _this.inputSizeTensor);\n            var endPoints = tf.mul(tf.add(boxCenterPoints, halfBoxSizes), _this.inputSizeTensor);\n            return tf.concat2d([startPoints, endPoints], 1);\n        });\n    };\n    HandDetector.prototype.normalizeLandmarks = function (rawPalmLandmarks, index) {\n        var _this = this;\n        return tf.tidy(function () {\n            var landmarks = tf.add(tf.div(rawPalmLandmarks.reshape([-1, 7, 2]), _this.inputSizeTensor), _this.anchors[index]);\n            return tf.mul(landmarks, _this.inputSizeTensor);\n        });\n    };\n    HandDetector.prototype.getBoundingBoxes = function (input) {\n        return __awaiter(this, void 0, void 0, function () {\n            var normalizedInput, batchedPrediction, savedWebglPackDepthwiseConvFlag, prediction, scores, rawBoxes, boxes, savedConsoleWarnFn, boxesWithHandsTensor, boxesWithHands, toDispose, boxIndex, matchingBox, rawPalmLandmarks, palmLandmarks;\n            var _this = this;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        normalizedInput = tf.tidy(function () { return tf.mul(tf.sub(input, 0.5), 2); });\n                        if (tf.getBackend() === 'webgl') {\n                            savedWebglPackDepthwiseConvFlag = tf.env().get('WEBGL_PACK_DEPTHWISECONV');\n                            tf.env().set('WEBGL_PACK_DEPTHWISECONV', true);\n                            // The model returns a tensor with the following shape:\n                            //  [1 (batch), 2944 (anchor points), 19 (data for each anchor)]\n                            batchedPrediction = this.model.predict(normalizedInput);\n                            tf.env().set('WEBGL_PACK_DEPTHWISECONV', savedWebglPackDepthwiseConvFlag);\n                        }\n                        else {\n                            batchedPrediction = this.model.predict(normalizedInput);\n                        }\n                        prediction = batchedPrediction.squeeze();\n                        scores = tf.tidy(function () { return tf.sigmoid(tf.slice(prediction, [0, 0], [-1, 1])).squeeze(); });\n                        rawBoxes = tf.slice(prediction, [0, 1], [-1, 4]);\n                        boxes = this.normalizeBoxes(rawBoxes);\n                        savedConsoleWarnFn = console.warn;\n                        console.warn = function () { };\n                        boxesWithHandsTensor = tf.image.nonMaxSuppression(boxes, scores, 1, this.iouThreshold, this.scoreThreshold);\n                        console.warn = savedConsoleWarnFn;\n                        return [4 /*yield*/, boxesWithHandsTensor.array()];\n                    case 1:\n                        boxesWithHands = _a.sent();\n                        toDispose = [\n                            normalizedInput, batchedPrediction, boxesWithHandsTensor, prediction,\n                            boxes, rawBoxes, scores\n                        ];\n                        if (boxesWithHands.length === 0) {\n                            toDispose.forEach(function (tensor) { return tensor.dispose(); });\n                            return [2 /*return*/, null];\n                        }\n                        boxIndex = boxesWithHands[0];\n                        matchingBox = tf.slice(boxes, [boxIndex, 0], [1, -1]);\n                        rawPalmLandmarks = tf.slice(prediction, [boxIndex, 5], [1, 14]);\n                        palmLandmarks = tf.tidy(function () { return _this.normalizeLandmarks(rawPalmLandmarks, boxIndex).reshape([\n                            -1, 2\n                        ]); });\n                        toDispose.push(rawPalmLandmarks);\n                        toDispose.forEach(function (tensor) { return tensor.dispose(); });\n                        return [2 /*return*/, { boxes: matchingBox, palmLandmarks: palmLandmarks }];\n                }\n            });\n        });\n    };\n    /**\n     * Returns a Box identifying the bounding box of a hand within the image.\n     * Returns null if there is no hand in the image.\n     *\n     * @param input The image to classify.\n     */\n    HandDetector.prototype.estimateHandBounds = function (input) {\n        return __awaiter(this, void 0, void 0, function () {\n            var inputHeight, inputWidth, image, prediction, boundingBoxes, startPoint, endPoint, palmLandmarks;\n            var _this = this;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        inputHeight = input.shape[1];\n                        inputWidth = input.shape[2];\n                        image = tf.tidy(function () { return input.resizeBilinear([_this.width, _this.height]).div(255); });\n                        return [4 /*yield*/, this.getBoundingBoxes(image)];\n                    case 1:\n                        prediction = _a.sent();\n                        if (prediction === null) {\n                            image.dispose();\n                            return [2 /*return*/, null];\n                        }\n                        boundingBoxes = prediction.boxes.arraySync();\n                        startPoint = boundingBoxes[0].slice(0, 2);\n                        endPoint = boundingBoxes[0].slice(2, 4);\n                        palmLandmarks = prediction.palmLandmarks.arraySync();\n                        image.dispose();\n                        prediction.boxes.dispose();\n                        prediction.palmLandmarks.dispose();\n                        return [2 /*return*/, box_1.scaleBoxCoordinates({ startPoint: startPoint, endPoint: endPoint, palmLandmarks: palmLandmarks }, [inputWidth / this.width, inputHeight / this.height])];\n                }\n            });\n        });\n    };\n    return HandDetector;\n}());\nexports.HandDetector = HandDetector;\n//# sourceMappingURL=hand.js.map","\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tf = require(\"@tensorflow/tfjs-core\");\nfunction getBoxSize(box) {\n    return [\n        Math.abs(box.endPoint[0] - box.startPoint[0]),\n        Math.abs(box.endPoint[1] - box.startPoint[1])\n    ];\n}\nexports.getBoxSize = getBoxSize;\nfunction getBoxCenter(box) {\n    return [\n        box.startPoint[0] + (box.endPoint[0] - box.startPoint[0]) / 2,\n        box.startPoint[1] + (box.endPoint[1] - box.startPoint[1]) / 2\n    ];\n}\nexports.getBoxCenter = getBoxCenter;\nfunction cutBoxFromImageAndResize(box, image, cropSize) {\n    var h = image.shape[1];\n    var w = image.shape[2];\n    var boxes = [[\n            box.startPoint[1] / h, box.startPoint[0] / w, box.endPoint[1] / h,\n            box.endPoint[0] / w\n        ]];\n    return tf.image.cropAndResize(image, boxes, [0], cropSize);\n}\nexports.cutBoxFromImageAndResize = cutBoxFromImageAndResize;\nfunction scaleBoxCoordinates(box, factor) {\n    var startPoint = [box.startPoint[0] * factor[0], box.startPoint[1] * factor[1]];\n    var endPoint = [box.endPoint[0] * factor[0], box.endPoint[1] * factor[1]];\n    var palmLandmarks = box.palmLandmarks.map(function (coord) {\n        var scaledCoord = [coord[0] * factor[0], coord[1] * factor[1]];\n        return scaledCoord;\n    });\n    return { startPoint: startPoint, endPoint: endPoint, palmLandmarks: palmLandmarks };\n}\nexports.scaleBoxCoordinates = scaleBoxCoordinates;\nfunction enlargeBox(box, factor) {\n    if (factor === void 0) { factor = 1.5; }\n    var center = getBoxCenter(box);\n    var size = getBoxSize(box);\n    var newHalfSize = [factor * size[0] / 2, factor * size[1] / 2];\n    var startPoint = [center[0] - newHalfSize[0], center[1] - newHalfSize[1]];\n    var endPoint = [center[0] + newHalfSize[0], center[1] + newHalfSize[1]];\n    return { startPoint: startPoint, endPoint: endPoint, palmLandmarks: box.palmLandmarks };\n}\nexports.enlargeBox = enlargeBox;\nfunction squarifyBox(box) {\n    var centers = getBoxCenter(box);\n    var size = getBoxSize(box);\n    var maxEdge = Math.max.apply(Math, size);\n    var halfSize = maxEdge / 2;\n    var startPoint = [centers[0] - halfSize, centers[1] - halfSize];\n    var endPoint = [centers[0] + halfSize, centers[1] + halfSize];\n    return { startPoint: startPoint, endPoint: endPoint, palmLandmarks: box.palmLandmarks };\n}\nexports.squarifyBox = squarifyBox;\nfunction shiftBox(box, shiftFactor) {\n    var boxSize = [\n        box.endPoint[0] - box.startPoint[0], box.endPoint[1] - box.startPoint[1]\n    ];\n    var shiftVector = [boxSize[0] * shiftFactor[0], boxSize[1] * shiftFactor[1]];\n    var startPoint = [box.startPoint[0] + shiftVector[0], box.startPoint[1] + shiftVector[1]];\n    var endPoint = [box.endPoint[0] + shiftVector[0], box.endPoint[1] + shiftVector[1]];\n    return { startPoint: startPoint, endPoint: endPoint, palmLandmarks: box.palmLandmarks };\n}\nexports.shiftBox = shiftBox;\n//# sourceMappingURL=box.js.map","\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.MESH_ANNOTATIONS = {\n    thumb: [1, 2, 3, 4],\n    indexFinger: [5, 6, 7, 8],\n    middleFinger: [9, 10, 11, 12],\n    ringFinger: [13, 14, 15, 16],\n    pinky: [17, 18, 19, 20],\n    palmBase: [0]\n};\n//# sourceMappingURL=keypoints.js.map","\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tf = require(\"@tensorflow/tfjs-core\");\nvar box_1 = require(\"./box\");\nvar util_1 = require(\"./util\");\nvar UPDATE_REGION_OF_INTEREST_IOU_THRESHOLD = 0.8;\nvar PALM_BOX_SHIFT_VECTOR = [0, -0.4];\nvar PALM_BOX_ENLARGE_FACTOR = 3;\nvar HAND_BOX_SHIFT_VECTOR = [0, -0.1];\nvar HAND_BOX_ENLARGE_FACTOR = 1.65;\nvar PALM_LANDMARK_IDS = [0, 5, 9, 13, 17, 1, 2];\nvar PALM_LANDMARKS_INDEX_OF_PALM_BASE = 0;\nvar PALM_LANDMARKS_INDEX_OF_MIDDLE_FINGER_BASE = 2;\n// The Pipeline coordinates between the bounding box and skeleton models.\nvar HandPipeline = /** @class */ (function () {\n    function HandPipeline(boundingBoxDetector, meshDetector, meshWidth, meshHeight, maxContinuousChecks, detectionConfidence) {\n        // An array of hand bounding boxes.\n        this.regionsOfInterest = [];\n        this.runsWithoutHandDetector = 0;\n        this.boundingBoxDetector = boundingBoxDetector;\n        this.meshDetector = meshDetector;\n        this.maxContinuousChecks = maxContinuousChecks;\n        this.detectionConfidence = detectionConfidence;\n        this.meshWidth = meshWidth;\n        this.meshHeight = meshHeight;\n        this.maxHandsNumber = 1; // TODO(annxingyuan): Add multi-hand support.\n    }\n    // Get the bounding box surrounding the hand, given palm landmarks.\n    HandPipeline.prototype.getBoxForPalmLandmarks = function (palmLandmarks, rotationMatrix) {\n        var rotatedPalmLandmarks = palmLandmarks.map(function (coord) {\n            var homogeneousCoordinate = coord.concat([1]);\n            return util_1.rotatePoint(homogeneousCoordinate, rotationMatrix);\n        });\n        var boxAroundPalm = this.calculateLandmarksBoundingBox(rotatedPalmLandmarks);\n        // boxAroundPalm only surrounds the palm - therefore we shift it\n        // upwards so it will capture fingers once enlarged + squarified.\n        return box_1.enlargeBox(box_1.squarifyBox(box_1.shiftBox(boxAroundPalm, PALM_BOX_SHIFT_VECTOR)), PALM_BOX_ENLARGE_FACTOR);\n    };\n    // Get the bounding box surrounding the hand, given all hand landmarks.\n    HandPipeline.prototype.getBoxForHandLandmarks = function (landmarks) {\n        // The MediaPipe hand mesh model is trained on hands with empty space\n        // around them, so we still need to shift / enlarge boxAroundHand even\n        // though it surrounds the entire hand.\n        var boundingBox = this.calculateLandmarksBoundingBox(landmarks);\n        var boxAroundHand = box_1.enlargeBox(box_1.squarifyBox(box_1.shiftBox(boundingBox, HAND_BOX_SHIFT_VECTOR)), HAND_BOX_ENLARGE_FACTOR);\n        var palmLandmarks = [];\n        for (var i = 0; i < PALM_LANDMARK_IDS.length; i++) {\n            palmLandmarks.push(landmarks[PALM_LANDMARK_IDS[i]].slice(0, 2));\n        }\n        boxAroundHand.palmLandmarks = palmLandmarks;\n        return boxAroundHand;\n    };\n    // Scale, rotate, and translate raw keypoints from the model so they map to\n    // the input coordinates.\n    HandPipeline.prototype.transformRawCoords = function (rawCoords, box, angle, rotationMatrix) {\n        var _this = this;\n        var boxSize = box_1.getBoxSize(box);\n        var scaleFactor = [boxSize[0] / this.meshWidth, boxSize[1] / this.meshHeight];\n        var coordsScaled = rawCoords.map(function (coord) {\n            return [\n                scaleFactor[0] * (coord[0] - _this.meshWidth / 2),\n                scaleFactor[1] * (coord[1] - _this.meshHeight / 2), coord[2]\n            ];\n        });\n        var coordsRotationMatrix = util_1.buildRotationMatrix(angle, [0, 0]);\n        var coordsRotated = coordsScaled.map(function (coord) {\n            var rotated = util_1.rotatePoint(coord, coordsRotationMatrix);\n            return rotated.concat([coord[2]]);\n        });\n        var inverseRotationMatrix = util_1.invertTransformMatrix(rotationMatrix);\n        var boxCenter = box_1.getBoxCenter(box).concat([1]);\n        var originalBoxCenter = [\n            util_1.dot(boxCenter, inverseRotationMatrix[0]),\n            util_1.dot(boxCenter, inverseRotationMatrix[1])\n        ];\n        return coordsRotated.map(function (coord) {\n            return [\n                coord[0] + originalBoxCenter[0], coord[1] + originalBoxCenter[1],\n                coord[2]\n            ];\n        });\n    };\n    HandPipeline.prototype.estimateHand = function (image) {\n        return __awaiter(this, void 0, void 0, function () {\n            var useFreshBox, boundingBoxPrediction, currentBox, angle, palmCenter, palmCenterNormalized, rotatedImage, rotationMatrix, box, croppedInput, handImage, prediction, savedWebglPackDepthwiseConvFlag, flag, keypoints, flagValue, keypointsReshaped, rawCoords, coords, nextBoundingBox, result;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        useFreshBox = this.shouldUpdateRegionsOfInterest();\n                        if (!(useFreshBox === true)) return [3 /*break*/, 2];\n                        return [4 /*yield*/, this.boundingBoxDetector.estimateHandBounds(image)];\n                    case 1:\n                        boundingBoxPrediction = _a.sent();\n                        if (boundingBoxPrediction === null) {\n                            image.dispose();\n                            this.regionsOfInterest = [];\n                            return [2 /*return*/, null];\n                        }\n                        this.updateRegionsOfInterest(boundingBoxPrediction, true /*force update*/);\n                        this.runsWithoutHandDetector = 0;\n                        return [3 /*break*/, 3];\n                    case 2:\n                        this.runsWithoutHandDetector++;\n                        _a.label = 3;\n                    case 3:\n                        currentBox = this.regionsOfInterest[0];\n                        angle = util_1.computeRotation(currentBox.palmLandmarks[PALM_LANDMARKS_INDEX_OF_PALM_BASE], currentBox.palmLandmarks[PALM_LANDMARKS_INDEX_OF_MIDDLE_FINGER_BASE]);\n                        palmCenter = box_1.getBoxCenter(currentBox);\n                        palmCenterNormalized = [palmCenter[0] / image.shape[2], palmCenter[1] / image.shape[1]];\n                        rotatedImage = tf.image.rotateWithOffset(image, angle, 0, palmCenterNormalized);\n                        rotationMatrix = util_1.buildRotationMatrix(-angle, palmCenter);\n                        // The bounding box detector only detects palms, so if we're using a fresh\n                        // bounding box prediction, we have to construct the hand bounding box from\n                        // the palm keypoints.\n                        if (useFreshBox === true) {\n                            box =\n                                this.getBoxForPalmLandmarks(currentBox.palmLandmarks, rotationMatrix);\n                        }\n                        else {\n                            box = currentBox;\n                        }\n                        croppedInput = box_1.cutBoxFromImageAndResize(box, rotatedImage, [this.meshWidth, this.meshHeight]);\n                        handImage = croppedInput.div(255);\n                        croppedInput.dispose();\n                        rotatedImage.dispose();\n                        if (tf.getBackend() === 'webgl') {\n                            savedWebglPackDepthwiseConvFlag = tf.env().get('WEBGL_PACK_DEPTHWISECONV');\n                            tf.env().set('WEBGL_PACK_DEPTHWISECONV', true);\n                            prediction =\n                                this.meshDetector.predict(handImage);\n                            tf.env().set('WEBGL_PACK_DEPTHWISECONV', savedWebglPackDepthwiseConvFlag);\n                        }\n                        else {\n                            prediction =\n                                this.meshDetector.predict(handImage);\n                        }\n                        flag = prediction[0], keypoints = prediction[1];\n                        handImage.dispose();\n                        flagValue = flag.dataSync()[0];\n                        flag.dispose();\n                        if (flagValue < this.detectionConfidence) {\n                            keypoints.dispose();\n                            this.regionsOfInterest = [];\n                            return [2 /*return*/, null];\n                        }\n                        keypointsReshaped = tf.reshape(keypoints, [-1, 3]);\n                        rawCoords = keypointsReshaped.arraySync();\n                        keypoints.dispose();\n                        keypointsReshaped.dispose();\n                        coords = this.transformRawCoords(rawCoords, box, angle, rotationMatrix);\n                        nextBoundingBox = this.getBoxForHandLandmarks(coords);\n                        this.updateRegionsOfInterest(nextBoundingBox, false /* force replace */);\n                        result = {\n                            landmarks: coords,\n                            handInViewConfidence: flagValue,\n                            boundingBox: {\n                                topLeft: nextBoundingBox.startPoint,\n                                bottomRight: nextBoundingBox.endPoint\n                            }\n                        };\n                        return [2 /*return*/, result];\n                }\n            });\n        });\n    };\n    HandPipeline.prototype.calculateLandmarksBoundingBox = function (landmarks) {\n        var xs = landmarks.map(function (d) { return d[0]; });\n        var ys = landmarks.map(function (d) { return d[1]; });\n        var startPoint = [Math.min.apply(Math, xs), Math.min.apply(Math, ys)];\n        var endPoint = [Math.max.apply(Math, xs), Math.max.apply(Math, ys)];\n        return { startPoint: startPoint, endPoint: endPoint };\n    };\n    // Updates regions of interest if the intersection over union between\n    // the incoming and previous regions falls below a threshold.\n    HandPipeline.prototype.updateRegionsOfInterest = function (box, forceUpdate) {\n        if (forceUpdate) {\n            this.regionsOfInterest = [box];\n        }\n        else {\n            var previousBox = this.regionsOfInterest[0];\n            var iou = 0;\n            if (previousBox != null && previousBox.startPoint != null) {\n                var _a = box.startPoint, boxStartX = _a[0], boxStartY = _a[1];\n                var _b = box.endPoint, boxEndX = _b[0], boxEndY = _b[1];\n                var _c = previousBox.startPoint, previousBoxStartX = _c[0], previousBoxStartY = _c[1];\n                var _d = previousBox.endPoint, previousBoxEndX = _d[0], previousBoxEndY = _d[1];\n                var xStartMax = Math.max(boxStartX, previousBoxStartX);\n                var yStartMax = Math.max(boxStartY, previousBoxStartY);\n                var xEndMin = Math.min(boxEndX, previousBoxEndX);\n                var yEndMin = Math.min(boxEndY, previousBoxEndY);\n                var intersection = (xEndMin - xStartMax) * (yEndMin - yStartMax);\n                var boxArea = (boxEndX - boxStartX) * (boxEndY - boxStartY);\n                var previousBoxArea = (previousBoxEndX - previousBoxStartX) *\n                    (previousBoxEndY - boxStartY);\n                iou = intersection / (boxArea + previousBoxArea - intersection);\n            }\n            this.regionsOfInterest[0] =\n                iou > UPDATE_REGION_OF_INTEREST_IOU_THRESHOLD ? previousBox : box;\n        }\n    };\n    HandPipeline.prototype.shouldUpdateRegionsOfInterest = function () {\n        var roisCount = this.regionsOfInterest.length;\n        return roisCount !== this.maxHandsNumber ||\n            this.runsWithoutHandDetector >= this.maxContinuousChecks;\n    };\n    return HandPipeline;\n}());\nexports.HandPipeline = HandPipeline;\n//# sourceMappingURL=pipeline.js.map","\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nfunction normalizeRadians(angle) {\n    return angle - 2 * Math.PI * Math.floor((angle + Math.PI) / (2 * Math.PI));\n}\nexports.normalizeRadians = normalizeRadians;\nfunction computeRotation(point1, point2) {\n    var radians = Math.PI / 2 - Math.atan2(-(point2[1] - point1[1]), point2[0] - point1[0]);\n    return normalizeRadians(radians);\n}\nexports.computeRotation = computeRotation;\nvar buildTranslationMatrix = function (x, y) {\n    return ([[1, 0, x], [0, 1, y], [0, 0, 1]]);\n};\nfunction dot(v1, v2) {\n    var product = 0;\n    for (var i = 0; i < v1.length; i++) {\n        product += v1[i] * v2[i];\n    }\n    return product;\n}\nexports.dot = dot;\nfunction getColumnFrom2DArr(arr, columnIndex) {\n    var column = [];\n    for (var i = 0; i < arr.length; i++) {\n        column.push(arr[i][columnIndex]);\n    }\n    return column;\n}\nexports.getColumnFrom2DArr = getColumnFrom2DArr;\nfunction multiplyTransformMatrices(mat1, mat2) {\n    var product = [];\n    var size = mat1.length;\n    for (var row = 0; row < size; row++) {\n        product.push([]);\n        for (var col = 0; col < size; col++) {\n            product[row].push(dot(mat1[row], getColumnFrom2DArr(mat2, col)));\n        }\n    }\n    return product;\n}\nfunction buildRotationMatrix(rotation, center) {\n    var cosA = Math.cos(rotation);\n    var sinA = Math.sin(rotation);\n    var rotationMatrix = [[cosA, -sinA, 0], [sinA, cosA, 0], [0, 0, 1]];\n    var translationMatrix = buildTranslationMatrix(center[0], center[1]);\n    var translationTimesRotation = multiplyTransformMatrices(translationMatrix, rotationMatrix);\n    var negativeTranslationMatrix = buildTranslationMatrix(-center[0], -center[1]);\n    return multiplyTransformMatrices(translationTimesRotation, negativeTranslationMatrix);\n}\nexports.buildRotationMatrix = buildRotationMatrix;\nfunction invertTransformMatrix(matrix) {\n    var rotationComponent = [[matrix[0][0], matrix[1][0]], [matrix[0][1], matrix[1][1]]];\n    var translationComponent = [matrix[0][2], matrix[1][2]];\n    var invertedTranslation = [\n        -dot(rotationComponent[0], translationComponent),\n        -dot(rotationComponent[1], translationComponent)\n    ];\n    return [\n        rotationComponent[0].concat(invertedTranslation[0]),\n        rotationComponent[1].concat(invertedTranslation[1]),\n        [0, 0, 1]\n    ];\n}\nexports.invertTransformMatrix = invertTransformMatrix;\nfunction rotatePoint(homogeneousCoordinate, rotationMatrix) {\n    return [\n        dot(homogeneousCoordinate, rotationMatrix[0]),\n        dot(homogeneousCoordinate, rotationMatrix[1])\n    ];\n}\nexports.rotatePoint = rotatePoint;\n//# sourceMappingURL=util.js.map"]}