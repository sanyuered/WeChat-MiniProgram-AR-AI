{"version":3,"file":"tf-converter.min.js","sources":["../src/data/compiled_api.ts","../src/operations/custom_op/register.ts","../src/operations/executors/utils.ts","../src/operations/op_list/arithmetic.ts","../src/operations/op_list/basic_math.ts","../src/operations/op_list/control.ts","../src/operations/op_list/convolution.ts","../src/operations/op_list/creation.ts","../src/operations/op_list/dynamic.ts","../src/operations/op_list/evaluation.ts","../src/operations/op_list/graph.ts","../src/operations/op_list/image.ts","../src/operations/op_list/logical.ts","../src/operations/op_list/matrices.ts","../src/operations/op_list/normalization.ts","../src/operations/op_list/reduction.ts","../src/operations/op_list/slice_join.ts","../src/operations/op_list/spectral.ts","../src/operations/op_list/transformation.ts","../src/operations/operation_mapper.ts","../src/operations/custom_op/node_value_impl.ts","../src/executor/tensor_utils.ts","../src/executor/tensor_array.ts","../src/executor/tensor_list.ts","../src/operations/executors/control_executor.ts","../src/operations/operation_executor.ts","../src/operations/executors/arithmetic_executor.ts","../src/operations/executors/basic_math_executor.ts","../src/operations/executors/convolution_executor.ts","../src/operations/executors/creation_executor.ts","../src/operations/executors/dynamic_executor.ts","../src/operations/executors/evaluation_executor.ts","../src/operations/executors/image_executor.ts","../src/operations/executors/graph_executor.ts","../src/operations/executors/logical_executor.ts","../src/operations/executors/matrices_executor.ts","../src/operations/executors/normalization_executor.ts","../src/operations/executors/reduction_executor.ts","../src/operations/executors/slice_join_executor.ts","../src/operations/executors/spectral_executor.ts","../src/operations/executors/transformation_executor.ts","../src/executor/execution_context.ts","../src/executor/model_analysis.ts","../src/executor/graph_executor.ts","../src/executor/graph_model.ts","../src/version.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\n/* tslint:disable */\n\n/** Properties of an Any. */\nexport declare interface IAny {\n  /** Any typeUrl */\n  typeUrl?: (string|null);\n\n  /** Any value */\n  value?: (Uint8Array|null);\n}\n\n/** DataType enum. */\nexport enum DataType {\n  'DT_INVALID' = 0,\n  'DT_FLOAT' = 1,\n  'DT_DOUBLE' = 2,\n  'DT_INT32' = 3,\n  'DT_UINT8' = 4,\n  'DT_INT16' = 5,\n  'DT_INT8' = 6,\n  'DT_STRING' = 7,\n  'DT_COMPLEX64' = 8,\n  'DT_INT64' = 9,\n  'DT_BOOL' = 10,\n  'DT_QINT8' = 11,\n  'DT_QUINT8' = 12,\n  'DT_QINT32' = 13,\n  'DT_BFLOAT16' = 14,\n  'DT_FLOAT_REF' = 101,\n  'DT_DOUBLE_REF' = 102,\n  'DT_INT32_REF' = 103,\n  'DT_UINT8_REF' = 104,\n  'DT_INT16_REF' = 105,\n  'DT_INT8_REF' = 106,\n  'DT_STRING_REF' = 107,\n  'DT_COMPLEX64_REF' = 108,\n  'DT_INT64_REF' = 109,\n  'DT_BOOL_REF' = 110,\n  'DT_QINT8_REF' = 111,\n  'DT_QUINT8_REF' = 112,\n  'DT_QINT32_REF' = 113,\n  'DT_BFLOAT16_REF' = 114\n}\n\n/** Properties of a TensorShape. */\nexport declare interface ITensorShape {\n  /** TensorShape dim */\n  dim?: (TensorShape.IDim[]|null);\n\n  /** TensorShape unknownRank */\n  unknownRank?: (boolean|null);\n}\n\nexport namespace TensorShape {\n  /** Properties of a Dim. */\n  export declare interface IDim {\n    /** Dim size */\n    size?: (number|string|null);\n\n    /** Dim name */\n    name?: (string|null);\n  }\n}\n\n/** Properties of a Tensor. */\nexport declare interface ITensor {\n  /** Tensor dtype */\n  dtype?: (DataType|null);\n\n  /** Tensor tensorShape */\n  tensorShape?: (ITensorShape|null);\n\n  /** Tensor versionNumber */\n  versionNumber?: (number|null);\n\n  /** Tensor tensorContent */\n  tensorContent?: (Uint8Array|null);\n\n  /** Tensor floatVal */\n  floatVal?: (number[]|null);\n\n  /** Tensor doubleVal */\n  doubleVal?: (number[]|null);\n\n  /** Tensor intVal */\n  intVal?: (number[]|null);\n\n  /** Tensor stringVal */\n  stringVal?: (Uint8Array[]|null);\n\n  /** Tensor scomplexVal */\n  scomplexVal?: (number[]|null);\n\n  /** Tensor int64Val */\n  int64Val?: ((number | string)[]|null);\n\n  /** Tensor boolVal */\n  boolVal?: (boolean[]|null);\n\n  /** Tensor uint32Val */\n  uint32Val?: (number[]|null);\n\n  /** Tensor uint64Val */\n  uint64Val?: ((number | string)[]|null);\n}\n\n/** Properties of an AttrValue. */\nexport declare interface IAttrValue {\n  /** AttrValue list */\n  list?: (AttrValue.IListValue|null);\n\n  /** AttrValue s */\n  s?: (string|null);\n\n  /** AttrValue i */\n  i?: (number|string|null);\n\n  /** AttrValue f */\n  f?: (number|null);\n\n  /** AttrValue b */\n  b?: (boolean|null);\n\n  /** AttrValue type */\n  type?: (DataType|null);\n\n  /** AttrValue shape */\n  shape?: (ITensorShape|null);\n\n  /** AttrValue tensor */\n  tensor?: (ITensor|null);\n\n  /** AttrValue placeholder */\n  placeholder?: (string|null);\n\n  /** AttrValue func */\n  func?: (INameAttrList|null);\n}\n\nexport namespace AttrValue {\n  /** Properties of a ListValue. */\n  export declare interface IListValue {\n    /** ListValue s */\n    s?: (string[]|null);\n\n    /** ListValue i */\n    i?: ((number | string)[]|null);\n\n    /** ListValue f */\n    f?: (number[]|null);\n\n    /** ListValue b */\n    b?: (boolean[]|null);\n\n    /** ListValue type */\n    type?: (DataType[]|null);\n\n    /** ListValue shape */\n    shape?: (ITensorShape[]|null);\n\n    /** ListValue tensor */\n    tensor?: (ITensor[]|null);\n\n    /** ListValue func */\n    func?: (INameAttrList[]|null);\n  }\n}\n\n/** Properties of a NameAttrList. */\nexport declare interface INameAttrList {\n  /** NameAttrList name */\n  name?: (string|null);\n\n  /** NameAttrList attr */\n  attr?: ({[k: string]: IAttrValue}|null);\n}\n\n/** Properties of a NodeDef. */\nexport declare interface INodeDef {\n  /** NodeDef name */\n  name?: (string|null);\n\n  /** NodeDef op */\n  op?: (string|null);\n\n  /** NodeDef input */\n  input?: (string[]|null);\n\n  /** NodeDef device */\n  device?: (string|null);\n\n  /** NodeDef attr */\n  attr?: ({[k: string]: IAttrValue}|null);\n}\n\n/** Properties of a VersionDef. */\nexport declare interface IVersionDef {\n  /** VersionDef producer */\n  producer?: (number|null);\n\n  /** VersionDef minConsumer */\n  minConsumer?: (number|null);\n\n  /** VersionDef badConsumers */\n  badConsumers?: (number[]|null);\n}\n\n/** Properties of a GraphDef. */\nexport declare interface IGraphDef {\n  /** GraphDef node */\n  node?: (INodeDef[]|null);\n\n  /** GraphDef versions */\n  versions?: (IVersionDef|null);\n\n  /** GraphDef library */\n  library?: (IFunctionDefLibrary|null);\n}\n\n/** Properties of a CollectionDef. */\nexport declare interface ICollectionDef {\n  /** CollectionDef nodeList */\n  nodeList?: (CollectionDef.INodeList|null);\n\n  /** CollectionDef bytesList */\n  bytesList?: (CollectionDef.IBytesList|null);\n\n  /** CollectionDef int64List */\n  int64List?: (CollectionDef.IInt64List|null);\n\n  /** CollectionDef floatList */\n  floatList?: (CollectionDef.IFloatList|null);\n\n  /** CollectionDef anyList */\n  anyList?: (CollectionDef.IAnyList|null);\n}\n\nexport namespace CollectionDef {\n  /** Properties of a NodeList. */\n  export declare interface INodeList {\n    /** NodeList value */\n    value?: (string[]|null);\n  }\n\n  /** Properties of a BytesList. */\n  export declare interface IBytesList {\n    /** BytesList value */\n    value?: (Uint8Array[]|null);\n  }\n\n  /** Properties of an Int64List. */\n  export declare interface IInt64List {\n    /** Int64List value */\n    value?: ((number | string)[]|null);\n  }\n\n  /** Properties of a FloatList. */\n  export declare interface IFloatList {\n    /** FloatList value */\n    value?: (number[]|null);\n  }\n\n  /** Properties of an AnyList. */\n  export declare interface IAnyList {\n    /** AnyList value */\n    value?: (IAny[]|null);\n  }\n}\n\n/** Properties of a SaverDef. */\nexport declare interface ISaverDef {\n  /** SaverDef filenameTensorName */\n  filenameTensorName?: (string|null);\n\n  /** SaverDef saveTensorName */\n  saveTensorName?: (string|null);\n\n  /** SaverDef restoreOpName */\n  restoreOpName?: (string|null);\n\n  /** SaverDef maxToKeep */\n  maxToKeep?: (number|null);\n\n  /** SaverDef sharded */\n  sharded?: (boolean|null);\n\n  /** SaverDef keepCheckpointEveryNHours */\n  keepCheckpointEveryNHours?: (number|null);\n\n  /** SaverDef version */\n  version?: (SaverDef.CheckpointFormatVersion|null);\n}\n\nexport namespace SaverDef {\n  /** CheckpointFormatVersion enum. */\n  export enum CheckpointFormatVersion {'LEGACY' = 0, 'V1' = 1, 'V2' = 2}\n}\n\n/** Properties of a TensorInfo. */\nexport declare interface ITensorInfo {\n  /** TensorInfo name */\n  name?: (string|null);\n\n  /** TensorInfo cooSparse */\n  cooSparse?: (TensorInfo.ICooSparse|null);\n\n  /** TensorInfo dtype */\n  dtype?: (DataType|null);\n\n  /** TensorInfo tensorShape */\n  tensorShape?: (ITensorShape|null);\n}\n\nexport namespace TensorInfo {\n  /** Properties of a CooSparse. */\n  export declare interface ICooSparse {\n    /** CooSparse valuesTensorName */\n    valuesTensorName?: (string|null);\n\n    /** CooSparse indicesTensorName */\n    indicesTensorName?: (string|null);\n\n    /** CooSparse denseShapeTensorName */\n    denseShapeTensorName?: (string|null);\n  }\n}\n\n/** Properties of a SignatureDef. */\nexport declare interface ISignatureDef {\n  /** SignatureDef inputs */\n  inputs?: ({[k: string]: ITensorInfo}|null);\n\n  /** SignatureDef outputs */\n  outputs?: ({[k: string]: ITensorInfo}|null);\n\n  /** SignatureDef methodName */\n  methodName?: (string|null);\n}\n\n/** Properties of an AssetFileDef. */\nexport declare interface IAssetFileDef {\n  /** AssetFileDef tensorInfo */\n  tensorInfo?: (ITensorInfo|null);\n\n  /** AssetFileDef filename */\n  filename?: (string|null);\n}\n\n/** Properties of an OpDef. */\nexport declare interface IOpDef {\n  /** OpDef name */\n  name?: (string|null);\n\n  /** OpDef inputArg */\n  inputArg?: (OpDef.IArgDef[]|null);\n\n  /** OpDef outputArg */\n  outputArg?: (OpDef.IArgDef[]|null);\n\n  /** OpDef attr */\n  attr?: (OpDef.IAttrDef[]|null);\n\n  /** OpDef deprecation */\n  deprecation?: (OpDef.IOpDeprecation|null);\n\n  /** OpDef summary */\n  summary?: (string|null);\n\n  /** OpDef description */\n  description?: (string|null);\n\n  /** OpDef isCommutative */\n  isCommutative?: (boolean|null);\n\n  /** OpDef isAggregate */\n  isAggregate?: (boolean|null);\n\n  /** OpDef isStateful */\n  isStateful?: (boolean|null);\n\n  /** OpDef allowsUninitializedInput */\n  allowsUninitializedInput?: (boolean|null);\n}\n\nexport namespace OpDef {\n  /** Properties of an ArgDef. */\n  export declare interface IArgDef {\n    /** ArgDef name */\n    name?: (string|null);\n\n    /** ArgDef description */\n    description?: (string|null);\n\n    /** ArgDef type */\n    type?: (DataType|null);\n\n    /** ArgDef typeAttr */\n    typeAttr?: (string|null);\n\n    /** ArgDef numberAttr */\n    numberAttr?: (string|null);\n\n    /** ArgDef typeListAttr */\n    typeListAttr?: (string|null);\n\n    /** ArgDef isRef */\n    isRef?: (boolean|null);\n  }\n\n  /** Properties of an AttrDef. */\n  export declare interface IAttrDef {\n    /** AttrDef name */\n    name?: (string|null);\n\n    /** AttrDef type */\n    type?: (string|null);\n\n    /** AttrDef defaultValue */\n    defaultValue?: (IAttrValue|null);\n\n    /** AttrDef description */\n    description?: (string|null);\n\n    /** AttrDef hasMinimum */\n    hasMinimum?: (boolean|null);\n\n    /** AttrDef minimum */\n    minimum?: (number|string|null);\n\n    /** AttrDef allowedValues */\n    allowedValues?: (IAttrValue|null);\n  }\n\n  /** Properties of an OpDeprecation. */\n  export declare interface IOpDeprecation {\n    /** OpDeprecation version */\n    version?: (number|null);\n\n    /** OpDeprecation explanation */\n    explanation?: (string|null);\n  }\n}\n\n/** Properties of an OpList. */\nexport declare interface IOpList {\n  /** OpList op */\n  op?: (IOpDef[]|null);\n}\n\n/** Properties of a MetaGraphDef. */\nexport declare interface IMetaGraphDef {\n  /** MetaGraphDef metaInfoDef */\n  metaInfoDef?: (MetaGraphDef.IMetaInfoDef|null);\n\n  /** MetaGraphDef graphDef */\n  graphDef?: (IGraphDef|null);\n\n  /** MetaGraphDef saverDef */\n  saverDef?: (ISaverDef|null);\n\n  /** MetaGraphDef collectionDef */\n  collectionDef?: ({[k: string]: ICollectionDef}|null);\n\n  /** MetaGraphDef signatureDef */\n  signatureDef?: ({[k: string]: ISignatureDef}|null);\n\n  /** MetaGraphDef assetFileDef */\n  assetFileDef?: (IAssetFileDef[]|null);\n}\n\nexport namespace MetaGraphDef {\n  /** Properties of a MetaInfoDef. */\n  export declare interface IMetaInfoDef {\n    /** MetaInfoDef metaGraphVersion */\n    metaGraphVersion?: (string|null);\n\n    /** MetaInfoDef strippedOpList */\n    strippedOpList?: (IOpList|null);\n\n    /** MetaInfoDef anyInfo */\n    anyInfo?: (IAny|null);\n\n    /** MetaInfoDef tags */\n    tags?: (string[]|null);\n\n    /** MetaInfoDef tensorflowVersion */\n    tensorflowVersion?: (string|null);\n\n    /** MetaInfoDef tensorflowGitVersion */\n    tensorflowGitVersion?: (string|null);\n  }\n}\n\n/** Properties of a SavedModel. */\nexport declare interface ISavedModel {\n  /** SavedModel savedModelSchemaVersion */\n  savedModelSchemaVersion?: (number|string|null);\n\n  /** SavedModel metaGraphs */\n  metaGraphs?: (IMetaGraphDef[]|null);\n}\n\n/** Properties of a FunctionDefLibrary. */\nexport declare interface IFunctionDefLibrary {\n  /** FunctionDefLibrary function */\n  'function'?: (IFunctionDef[]|null);\n\n  /** FunctionDefLibrary gradient */\n  gradient?: (IGradientDef[]|null);\n}\n\n/** Properties of a FunctionDef. */\nexport declare interface IFunctionDef {\n  /** FunctionDef signature */\n  signature?: (IOpDef|null);\n\n  /** FunctionDef attr */\n  attr?: ({[k: string]: IAttrValue}|null);\n\n  /** FunctionDef nodeDef */\n  nodeDef?: (INodeDef[]|null);\n\n  /** FunctionDef ret */\n  ret?: ({[k: string]: string}|null);\n}\n\n/** Properties of a GradientDef. */\nexport declare interface IGradientDef {\n  /** GradientDef functionName */\n  functionName?: (string|null);\n\n  /** GradientDef gradientFunc */\n  gradientFunc?: (string|null);\n}\n","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpExecutor, OpMapper} from '../types';\n\nconst CUSTOM_OPS: {[key: string]: OpMapper} = {};\n\n/**\n * Register an Op for graph model executor. This allow you to register\n * TensorFlow custom op or override existing op.\n *\n * Here is an example of registering a new MatMul Op.\n * ```js\n * const customMatmul = (node) =>\n *    tf.matMul(\n *        node.inputs[0], node.inputs[1],\n *        node.attrs['transpose_a'], node.attrs['transpose_b']);\n *\n * tf.registerOp('MatMul', customMatmul);\n * ```\n * The inputs and attrs of the node object is based on the TensorFlow op\n * registry.\n *\n * @param name The Tensorflow Op name.\n * @param opFunc An op function which is called with the current graph node\n * during execution and needs to return a tensor or a list of tensors. The node\n * has the following attributes:\n *    - attr: A map from attribute name to its value\n *    - inputs: A list of input tensors\n */\n/** @doc {heading: 'Models', subheading: 'Op Registry'} */\nexport function registerOp(name: string, opFunc: OpExecutor) {\n  const opMapper: OpMapper = {\n    tfOpName: name,\n    category: 'custom',\n    inputs: [],\n    attrs: [],\n    customExecutor: opFunc\n  };\n\n  CUSTOM_OPS[name] = opMapper;\n}\n\n/**\n * Retrieve the OpMapper object for the registered op.\n *\n * @param name The Tensorflow Op name.\n */\n/** @doc {heading: 'Models', subheading: 'Op Registry'} */\n\nexport function getRegisteredOp(name: string): OpMapper {\n  return CUSTOM_OPS[name];\n}\n\n/**\n * Deregister the Op for graph model executor.\n *\n * @param name The Tensorflow Op name.\n */\n/** @doc {heading: 'Models', subheading: 'Op Registry'} */\nexport function deregisterOp(name: string) {\n  delete CUSTOM_OPS[name];\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {Node, ValueType} from '../types';\n\nexport function getParamValue(\n    paramName: string, node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext): ValueType {\n  const inputParam = node.inputParams[paramName];\n  if (inputParam && inputParam.inputIndexStart !== undefined) {\n    const start = inputParam.inputIndexStart;\n    const end = inputParam.inputIndexEnd === 0 ?\n        undefined :\n        (inputParam.inputIndexEnd === undefined ? start + 1 :\n                                                  inputParam.inputIndexEnd);\n    if (inputParam.type === 'tensor') {\n      return getTensor(\n          node.inputNames[inputParam.inputIndexStart], tensorMap, context);\n    }\n    if (inputParam.type === 'tensors') {\n      const inputs = node.inputNames.slice(start, end);\n\n      return inputs.map(name => getTensor(name, tensorMap, context));\n    }\n    const tensor =\n        getTensor(node.inputNames.slice(start)[0], tensorMap, context);\n    const data = tensor.dataSync();\n    return inputParam.type === 'number' ?\n        data[0] :\n        tfc.util.toNestedArray(tensor.shape, data);\n  }\n  const attrParam = node.attrParams[paramName];\n  return attrParam && attrParam.value;\n}\n\n/**\n * Retrieve the tensor based on input name by extracting the node name and\n * output index information.\n * @param name Node input name\n * @param tensorsMap Tensors map keyed by the node\n */\nexport function getTensor(\n    name: string, tensorsMap: NamedTensorsMap,\n    context: ExecutionContext): tfc.Tensor {\n  const [nodeName, index] = parseNodeName(name);\n  const contextId = context.currentContextIds.find(contextId => {\n    return !!tensorsMap[getNodeNameWithContextId(nodeName, contextId)];\n  });\n\n  return contextId !== undefined ?\n      tensorsMap[getNodeNameWithContextId(nodeName, contextId)][index] :\n      undefined;\n}\n\n/**\n * Retrieve the tensors based on input name for current context.\n * @param name Node input name\n * @param tensorsMap Tensors map keyed by the node\n */\nexport function getTensorsForCurrentContenxt(\n    name: string, tensorsMap: NamedTensorsMap,\n    context: ExecutionContext): tfc.Tensor[] {\n  return tensorsMap[getNodeNameWithContextId(name, context.currentContextId)];\n}\n\n/**\n * Returns the node name and index from the Node input name.\n * @param inputName The input name of the node, in format of\n * node_name:output_index, i.e. MatMul:0, if the output_index is not set, it is\n * default to 0.\n */\nexport function getNodeNameAndIndex(\n    inputName: string, context?: ExecutionContext): [string, number] {\n  const [nodeName, index] = parseNodeName(inputName);\n\n  return [\n    getNodeNameWithContextId(nodeName, context && context.currentContextId),\n    index\n  ];\n}\n\nfunction getNodeNameWithContextId(name: string, contextId?: string): string {\n  return !!contextId ? `${name}-${contextId}` : name;\n}\n\nexport function parseNodeName(name: string): [string, number] {\n  const parts = name.split(':');\n  if (parts.length === 1) {\n    return [name, 0];\n  }\n\n  const nodeName = parts[0];\n  return [nodeName, Number(parts[parts.length - 1])];\n}\n\nexport function split(arr: number[], size: number) {\n  const res = [];\n  for (let i = 0; i < arr.length; i += size) {\n    res.push(arr.slice(i, i + size));\n  }\n  return res;\n}\nexport function getPadding(\n    node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext): ValueType {\n  let pad = getParamValue('pad', node, tensorMap, context);\n  if (pad === 'explicit') {\n    // This is 1d array, we need to convert it to 2d array\n    pad = getParamValue('explicitPaddings', node, tensorMap, context);\n    const explicitPadding: [\n      [number, number], [number, number], [number, number], [number, number]\n    ] = [[0, 0], [0, 0], [0, 0], [0, 0]];\n    for (let i = 0; i < 4; i++) {\n      explicitPadding[i][0] = (pad as number[])[i * 2];\n      explicitPadding[i][1] = (pad as number[])[i * 2 + 1];\n    }\n    return explicitPadding;\n  }\n  return pad;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Add',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'AddV2',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'AddN',\n    'category': 'arithmetic',\n    'inputs': [{'start': 0, 'end': 0, 'name': 'tensors', 'type': 'tensors'}]\n  },\n  {\n    'tfOpName': 'BiasAdd',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sub',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'RealDiv',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Div',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'DivNoNan',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'FloorDiv',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Mul',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Maximum',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'}\n    ]\n  },\n  {\n    'tfOpName': 'Minimum',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'}\n    ]\n  },\n  {\n    'tfOpName': 'Pow',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'SquaredDifference',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Mod',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'FloorMod',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Abs',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Acos',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Asin',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Atan',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Atan2',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'y', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Ceil',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'ClipByValue',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'clip_value_min', 'name': 'clipValueMin', 'type': 'number'},\n      {'tfName': 'clip_value_max', 'name': 'clipValueMax', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'Complex',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'real', 'type': 'tensor'},\n      {'start': 1, 'name': 'imag', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'ComplexAbs',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Cos',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Cosh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Elu',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Exp',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Floor',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Log',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Imag',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'Tout',\n        'name': 'outputType',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Neg',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Real',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'Tout',\n        'name': 'outputType',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Prelu',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'alpha', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Relu',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Relu6',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'clipValueMin',\n        'name': 'clipValueMin',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'clipValueMax',\n        'name': 'clipValueMax',\n        'type': 'number',\n        'defaultValue': 6\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Selu',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sigmoid',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sin',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sinh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sqrt',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Rsqrt',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Square',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Tan',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Tanh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sign',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Round',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Expm1',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Log1p',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Reciprocal',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Softplus',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Asinh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Acosh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Atanh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Erf',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Prod',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axes', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'keep_dims',\n        'name': 'keepDims',\n        'type': 'bool',\n        'notSupported': true\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'LeakyRelu',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'alpha',\n        'name': 'alpha',\n        'type': 'number',\n        'defaultValue': 0.2\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'LoopCond',\n    'category': 'control',\n    'inputs': [{'start': 0, 'name': 'pred', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'Switch',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'data', 'type': 'tensor'},\n      {'start': 1, 'name': 'pred', 'type': 'tensor'}\n    ]\n  },\n  {\n    'tfOpName': 'Merge',\n    'category': 'control',\n    'inputs': [{'start': 0, 'end': 0, 'name': 'tensors', 'type': 'tensors'}]\n  },\n  {\n    'tfOpName': 'Enter',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true},\n      {'tfName': 'frame_name', 'name': 'frameName', 'type': 'string'},\n      {'tfName': 'is_constant', 'name': 'isConstant', 'type': 'bool'}\n    ]\n  },\n  {\n    'tfOpName': 'Exit',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'NextIteration',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'size', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'},\n      {'tfName': 'element_shape', 'name': 'elementShape', 'type': 'shape'},\n      {'tfName': 'dynamic_size', 'name': 'dynamicSize', 'type': 'bool'},\n      {'tfName': 'clear_after_read', 'name': 'clearAfterRead', 'type': 'bool'},\n      {\n        'tfName': 'identical_element_shapes',\n        'name': 'identicalElementShapes',\n        'type': 'bool'\n      },\n      {'tfName': 'tensor_array_name', 'name': 'name', 'type': 'string'}\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayWriteV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'tensor'},\n      {'start': 1, 'name': 'index', 'type': 'number'},\n      {'start': 2, 'name': 'tensor', 'type': 'tensor'},\n      {'start': 3, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayReadV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'tensor'},\n      {'start': 1, 'name': 'index', 'type': 'number'},\n      {'start': 2, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [{\n      'tfName': 'dtype',\n      'name': 'dtype',\n      'type': 'dtype',\n      'notSupported': true\n    }]\n  },\n  {\n    'tfOpName': 'TensorArrayGatherV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'number[]'},\n      {'start': 2, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'},\n      {'tfName': 'element_shape', 'name': 'elementShape', 'type': 'shape'}\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayScatterV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'number[]'},\n      {'start': 2, 'name': 'tensor', 'type': 'tensor'},\n      {'start': 3, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorArrayConcatV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'tensor'},\n      {'start': 1, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'}, {\n        'tfName': 'element_shape_except0',\n        'name': 'elementShapeExcept0',\n        'type': 'shape',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArraySplitV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'tensor'},\n      {'start': 1, 'name': 'tensor', 'type': 'tensor'},\n      {'start': 2, 'name': 'lengths', 'type': 'number[]'},\n      {'start': 3, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorArraySizeV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'tensor'},\n      {'start': 1, 'name': 'flowIn', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayCloseV3',\n    'category': 'control',\n    'inputs': [{'start': 0, 'name': 'tensorArrayId', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'StatelessIf',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'cond', 'type': 'tensor'},\n      {'start': 1, 'end': 0, 'name': 'args', 'type': 'tensors'}\n    ],\n    'attrs': [\n      {'tfName': 'then_branch', 'name': 'thenBranch', 'type': 'func'},\n      {'tfName': 'else_branch', 'name': 'elseBranch', 'type': 'func'}\n    ]\n  },\n  {\n    'tfOpName': 'If',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'cond', 'type': 'tensor'},\n      {'start': 1, 'end': 0, 'name': 'args', 'type': 'tensors'}\n    ],\n    'attrs': [\n      {'tfName': 'then_branch', 'name': 'thenBranch', 'type': 'func'},\n      {'tfName': 'else_branch', 'name': 'elseBranch', 'type': 'func'}\n    ]\n  },\n  {\n    'tfOpName': 'StatelessWhile',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'end': 0, 'name': 'args', 'type': 'tensors'},\n    ],\n    'attrs': [\n      {'tfName': 'cond', 'name': 'cond', 'type': 'func'},\n      {'tfName': 'body', 'name': 'body', 'type': 'func'}\n    ]\n  },\n  {\n    'tfOpName': 'While',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'end': 0, 'name': 'args', 'type': 'tensors'},\n    ],\n    'attrs': [\n      {'tfName': 'cond', 'name': 'cond', 'type': 'func'},\n      {'tfName': 'body', 'name': 'body', 'type': 'func'}\n    ]\n  },\n  {\n    'tfOpName': 'TensorListScatter',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'number[]'},\n      {'start': 2, 'name': 'elementShape', 'type': 'shape'}\n    ],\n    'attrs':\n        [{'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorListScatterV2',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'number[]'},\n      {'start': 2, 'name': 'elementShape', 'type': 'shape'},\n      {'start': 3, 'name': 'numElements', 'type': 'number'},\n    ],\n    'attrs':\n        [{'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorListGather',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorListId', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'number[]'},\n      {'start': 2, 'name': 'elementShape', 'type': 'shape'},\n    ],\n    'attrs':\n        [{'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorListGetItem',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorListId', 'type': 'tensor'},\n      {'start': 1, 'name': 'index', 'type': 'number'},\n      {'start': 2, 'name': 'elementShape', 'type': 'shape'},\n    ],\n    'attrs':\n        [{'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorListSetItem',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorListId', 'type': 'tensor'},\n      {'start': 1, 'name': 'index', 'type': 'number'},\n      {'start': 2, 'name': 'tensor', 'type': 'tensor'},\n    ],\n    'attrs':\n        [{'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorListReserve',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'elementShape', 'type': 'shape'},\n      {'start': 1, 'name': 'numElements', 'type': 'number'},\n    ],\n    'attrs':\n        [{'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorListFromTensor',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n      {'start': 1, 'name': 'elementShape', 'type': 'shape'}\n    ],\n    'attrs':\n        [{'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorListStack',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorListId', 'type': 'tensor'},\n      {'start': 1, 'name': 'elementShape', 'type': 'shape'},\n    ],\n    'attrs': [\n      {'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'},\n      {'tfName': 'num_elements', 'name': 'numElements', 'type': 'dtype'}\n    ]\n  },\n  {\n    'tfOpName': 'TensorListSplit',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n      {'start': 1, 'name': 'elementShape', 'type': 'shape'},\n      {'start': 2, 'name': 'lengths', 'type': 'number[]'},\n    ],\n    'attrs':\n        [{'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorListConcat',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorListId', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'element_shape', 'name': 'elementShape', 'type': 'shape'},\n      {'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}\n    ]\n  },\n  {\n    'tfOpName': 'TensorListPopBack',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorListId', 'type': 'tensor'},\n      {'start': 1, 'name': 'elementShape', 'type': 'shape'},\n    ],\n    'attrs':\n        [{'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorListPushBack',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorListId', 'type': 'tensor'},\n      {'start': 1, 'name': 'tensor', 'type': 'tensor'},\n    ],\n    'attrs':\n        [{'tfName': 'element_dtype', 'name': 'elementDType', 'type': 'dtype'}]\n  },\n];\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'AvgPool',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {'tfName': 'ksize', 'name': 'kernelSize', 'type': 'number[]'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'MaxPool',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {'tfName': 'ksize', 'name': 'kernelSize', 'type': 'number[]'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'MaxPoolWithArgmax',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'},\n      {'tfName': 'ksize', 'name': 'kernelSize', 'type': 'number[]'}, {\n        'tfName': 'include_batch_in_index',\n        'name': 'includeBatchInIndex',\n        'type': 'bool'\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'AvgPool3D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {'tfName': 'ksize', 'name': 'kernelSize', 'type': 'number[]'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'MaxPool3D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {'tfName': 'ksize', 'name': 'kernelSize', 'type': 'number[]'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Conv1D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'stride', 'name': 'stride', 'type': 'number'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NWC'\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'dilation',\n        'name': 'dilation',\n        'type': 'number',\n        'defaultValue': 1\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Conv2D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true},\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'},\n      {'tfName': 'useCudnnOnGpu', 'name': 'useCudnnOnGpu', 'type': 'bool'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      },\n      {'tfName': 'dilations', 'name': 'dilations', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': '_FusedConv2D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n      {'start': 2, end: 0, 'name': 'args', 'type': 'tensors'},\n    ],\n    'attrs': [\n      {'tfName': 'num_args', 'name': 'numArgs', 'type': 'number'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true},\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'},\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'use_cudnn_on_gpu',\n        'name': 'useCudnnOnGpu',\n        'type': 'bool',\n        'defaultValue': true\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'dilations',\n        'name': 'dilations',\n        'type': 'number[]',\n        'defaultValue': [1, 1, 1, 1]\n      },\n      {\n        'tfName': 'fused_ops',\n        'name': 'fusedOps',\n        'type': 'string[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.0001\n      },\n    ]\n  },\n  {\n    'tfOpName': 'Conv2DBackpropInput',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 2, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n      {'start': 0, 'name': 'outputShape', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'},\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      },\n    ]\n  },\n  {\n    'tfOpName': 'DepthwiseConv2d',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'input', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      },\n      {'tfName': 'dilations', 'name': 'dilations', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'DepthwiseConv2dNative',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'input', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      },\n      {'tfName': 'dilations', 'name': 'dilations', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'FusedDepthwiseConv2dNative',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n      {'start': 2, end: 0, 'name': 'args', 'type': 'tensors'},\n    ],\n    'attrs': [\n      {'tfName': 'num_args', 'name': 'numArgs', 'type': 'number'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true},\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'dilations',\n        'name': 'dilations',\n        'type': 'number[]',\n        'defaultValue': [1, 1, 1, 1]\n      },\n      {\n        'tfName': 'fused_ops',\n        'name': 'fusedOps',\n        'type': 'string[]',\n        'defaultValue': []\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Conv3D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {'tfName': 'dilations', 'name': 'dilations', 'type': 'number[]'}\n    ],\n  },\n  {\n    'tfOpName': 'Dilation2D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'rates', 'name': 'dilations', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Fill',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'shape', 'type': 'number[]'},\n      {'start': 1, 'name': 'value', 'type': 'number'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'LinSpace',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'start', 'type': 'number'},\n      {'start': 1, 'name': 'stop', 'type': 'number'},\n      {'start': 2, 'name': 'num', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'OneHot',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'indices', 'type': 'tensor'},\n      {'start': 1, 'name': 'depth', 'type': 'number'},\n      {'start': 2, 'name': 'onValue', 'type': 'number', 'defaultValue': 1},\n      {'start': 3, 'name': 'offValue', 'type': 'number', 'defaultValue': 0},\n    ],\n    'attrs': [\n      {\n        'tfName': 'axis',\n        'name': 'axis',\n        'type': 'number',\n        'notSupported': true\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Ones',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'shape', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'OnesLike',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [{'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'RandomUniform',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'shape', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'minval',\n        'name': 'minval',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'maxval',\n        'name': 'maxval',\n        'type': 'number',\n        'defaultValue': 1\n      },\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'},\n      {'tfName': 'seed', 'name': 'seed', 'type': 'number', 'defaultValue': 0}, {\n        'tfName': 'seed2',\n        'name': 'seed2',\n        'type': 'number',\n        'defaultValue': 0,\n        'notSupported': true\n      },\n      {'tfName': 'T', 'name': 'T', 'type': 'number', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Range',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'start', 'type': 'number'},\n      {'start': 1, 'name': 'stop', 'type': 'number'},\n      {'start': 2, 'name': 'step', 'type': 'number', 'defaultValue': 0},\n    ],\n    'attrs': [{'tfName': 'Tidx', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TruncatedNormal',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'shape', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'means',\n        'name': 'mean',\n        'type': 'number',\n        'defaultValue': 0.0\n      },\n      {\n        'tfName': 'stddev',\n        'name': 'stdDev',\n        'type': 'number',\n        'defaultValue': 1.0\n      },\n      {'tfName': 'seed', 'name': 'seed', 'type': 'number'}, {\n        'tfName': 'seed2',\n        'name': 'seed2',\n        'type': 'number',\n        'defaultValue': 0,\n        'notSupported': true\n      },\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'},\n      {'tfName': 'T', 'name': 'T', 'type': 'number', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Zeros',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'shape', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'ZerosLike',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'Multinomial',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'logits', 'type': 'tensor'},\n      {'start': 1, 'name': 'numSamples', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'seed', 'name': 'seed', 'type': 'number'},\n      {'tfName': 'seed2', 'name': 'seed2', 'type': 'number'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype'},\n      {'tfName': 'output_dtype', 'name': 'output_dtype', 'type': 'dtype'}\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'NonMaxSuppressionV2',\n    'category': 'dynamic',\n    'inputs': [\n      {'start': 0, 'name': 'boxes', 'type': 'tensor'},\n      {'start': 1, 'name': 'scores', 'type': 'tensor'},\n      {'start': 2, 'name': 'maxOutputSize', 'type': 'number'},\n      {'start': 3, 'name': 'iouThreshold', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'NonMaxSuppressionV3',\n    'category': 'dynamic',\n    'inputs': [\n      {'start': 0, 'name': 'boxes', 'type': 'tensor'},\n      {'start': 1, 'name': 'scores', 'type': 'tensor'},\n      {'start': 2, 'name': 'maxOutputSize', 'type': 'number'},\n      {'start': 3, 'name': 'iouThreshold', 'type': 'number'},\n      {'start': 4, 'name': 'scoreThreshold', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'NonMaxSuppressionV4',\n    'category': 'dynamic',\n    'inputs': [\n      {'start': 0, 'name': 'boxes', 'type': 'tensor'},\n      {'start': 1, 'name': 'scores', 'type': 'tensor'},\n      {'start': 2, 'name': 'maxOutputSize', 'type': 'number'},\n      {'start': 3, 'name': 'iouThreshold', 'type': 'number'},\n      {'start': 4, 'name': 'scoreThreshold', 'type': 'number'}\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'T_threshold',\n        'name': 'threshold',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'pad_to_max_output_size',\n        'name': 'padToMaxOutputSize',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'NonMaxSuppressionV5',\n    'category': 'dynamic',\n    'inputs': [\n      {'start': 0, 'name': 'boxes', 'type': 'tensor'},\n      {'start': 1, 'name': 'scores', 'type': 'tensor'},\n      {'start': 2, 'name': 'maxOutputSize', 'type': 'number'},\n      {'start': 3, 'name': 'iouThreshold', 'type': 'number'},\n      {'start': 4, 'name': 'scoreThreshold', 'type': 'number'},\n      {'start': 5, 'name': 'softNmsSigma', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'Where',\n    'category': 'dynamic',\n    'inputs': [\n      {'start': 0, 'name': 'condition', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'ListDiff',\n    'category': 'dynamic',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'y', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'T',\n      'name': 'dtype',\n      'type': 'dtype',\n      'notSupported': true\n    }]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [{\n  'tfOpName': 'TopKV2',\n  'category': 'evaluation',\n  'inputs': [\n    {'start': 0, 'name': 'x', 'type': 'tensor'},\n    {'start': 1, 'name': 'k', 'type': 'number'},\n  ],\n  'attrs': [{'tfName': 'sorted', 'name': 'sorted', 'type': 'bool'}]\n}];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'PlaceholderWithDefault',\n    'category': 'graph',\n    'inputs': [\n      {'start': 0, 'name': 'default', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'shape', 'name': 'shape', 'type': 'shape'},\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'}\n    ]\n  },\n  {\n    'tfOpName': 'Placeholder',\n    'category': 'graph',\n    'attrs': [\n      {'tfName': 'shape', 'name': 'shape', 'type': 'shape'},\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'}\n    ]\n  },\n  {'tfOpName': 'Const', 'category': 'graph'}, {\n    'tfOpName': 'Identity',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'IdentityN',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'end': 0, 'name': 'x', 'type': 'tensors'}]\n  },\n  {\n    'tfOpName': 'Snapshot',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'Rank',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'Size',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'Shape',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'ShapeN',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'end': 0, 'name': 'x', 'type': 'tensors'}]\n  },\n  {\n    'tfOpName': 'Print',\n    'category': 'graph',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'data', 'type': 'tensors'},\n    ],\n    'attrs': [\n      {'tfName': 'message', 'name': 'message', 'type': 'string'}, {\n        'tfName': 'first_n',\n        'name': 'firstN',\n        'type': 'number',\n        'notSupported': true\n      },\n      {\n        'tfName': 'summarize',\n        'name': 'summarize',\n        'type': 'number',\n        'defaultValue': 3\n      }\n    ]\n  },\n  {'tfOpName': 'NoOp', 'category': 'graph', 'inputs': []}, {\n    'tfOpName': 'StopGradient',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'FakeQuantWithMinMaxVars',\n    'category': 'graph',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'min', 'name': 'min', 'type': 'number'},\n      {'tfName': 'max', 'name': 'max', 'type': 'number'}\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'ResizeBilinear',\n    'category': 'image',\n    'inputs': [\n      {'start': 0, 'name': 'images', 'type': 'tensor'},\n      {'start': 1, 'name': 'size', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {'tfName': 'align_corners', 'name': 'alignCorners', 'type': 'bool'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'ResizeNearestNeighbor',\n    'category': 'image',\n    'inputs': [\n      {'start': 0, 'name': 'images', 'type': 'tensor'},\n      {'start': 1, 'name': 'size', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {'tfName': 'align_corners', 'name': 'alignCorners', 'type': 'bool'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'CropAndResize',\n    'category': 'image',\n    'inputs': [\n      {'start': 0, 'name': 'image', 'type': 'tensor'},\n      {'start': 1, 'name': 'boxes', 'type': 'tensor'},\n      {'start': 2, 'name': 'boxInd', 'type': 'tensor'},\n      {'start': 3, 'name': 'cropSize', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {'tfName': 'method', 'name': 'method', 'type': 'string'}, {\n        'tfName': 'extrapolation_value',\n        'name': 'extrapolationValue',\n        'type': 'number'\n      }\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Equal',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'NotEqual',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Greater',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'GreaterEqual',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Less',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'LessEqual',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'LogicalAnd',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'LogicalNot',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'LogicalOr',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Select',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'condition', 'type': 'tensor'},\n      {'start': 1, 'name': 'a', 'type': 'tensor'},\n      {'start': 2, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'SelectV2',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'condition', 'type': 'tensor'},\n      {'start': 1, 'name': 'a', 'type': 'tensor'},\n      {'start': 2, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'T',\n      'name': 'dtype',\n      'type': 'dtype',\n      'notSupported': true\n    }]\n  }\n];\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': '_FusedMatMul',\n    'category': 'matrices',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n      {'start': 2, end: 0, 'name': 'args', 'type': 'tensors'},\n    ],\n    'attrs': [\n      {'tfName': 'num_args', 'name': 'numArgs', 'type': 'number'}, {\n        'tfName': 'fused_ops',\n        'name': 'fusedOps',\n        'type': 'string[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.0001\n      },\n      {\n        'tfName': 'transpose_a',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'transpose_b',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'MatMul',\n    'category': 'matrices',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'transpose_a',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'transpose_b',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'BatchMatMul',\n    'category': 'matrices',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'adj_x',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'adj_y',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'BatchMatMulV2',\n    'category': 'matrices',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'adj_x',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'adj_y',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Transpose',\n    'category': 'matrices',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'perm', 'type': 'number[]'},\n    ],\n    'attrs': [{\n      'tfName': 'T',\n      'name': 'dtype',\n      'type': 'dtype',\n      'notSupported': true\n    }]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'FusedBatchNorm',\n    'category': 'normalization',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'scale', 'type': 'tensor'},\n      {'start': 2, 'name': 'offset', 'type': 'tensor'},\n      {'start': 3, 'name': 'mean', 'type': 'tensor'},\n      {'start': 4, 'name': 'variance', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.001\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FusedBatchNormV2',\n    'category': 'normalization',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'scale', 'type': 'tensor'},\n      {'start': 2, 'name': 'offset', 'type': 'tensor'},\n      {'start': 3, 'name': 'mean', 'type': 'tensor'},\n      {'start': 4, 'name': 'variance', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.001\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FusedBatchNormV3',\n    'category': 'normalization',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'scale', 'type': 'tensor'},\n      {'start': 2, 'name': 'offset', 'type': 'tensor'},\n      {'start': 3, 'name': 'mean', 'type': 'tensor'},\n      {'start': 4, 'name': 'variance', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.001\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LRN',\n    'category': 'normalization',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'depth_radius',\n        'name': 'radius',\n        'type': 'number',\n        'defaultValue': 5\n      },\n      {'tfName': 'bias', 'name': 'bias', 'type': 'number', 'defaultValue': 1.0},\n      {\n        'tfName': 'alpha',\n        'name': 'alpha',\n        'type': 'number',\n        'defaultValue': 1.0\n      },\n      {\n        'tfName': 'beta',\n        'name': 'beta',\n        'type': 'number',\n        'defaultValue': 0.5\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Softmax',\n    'category': 'normalization',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'LogSoftmax',\n    'category': 'normalization',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'SparseToDense',\n    'category': 'normalization',\n    'inputs': [\n      {'start': 0, 'name': 'sparseIndices', 'type': 'tensor'},\n      {'start': 1, 'name': 'outputShape', 'type': 'number[]'},\n      {'start': 2, 'name': 'sparseValues', 'type': 'tensor'},\n      {'start': 3, 'name': 'defaultValue', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'validate_indices',\n      'name': 'validateIndices',\n      'type': 'bool',\n      'defaultValue': true,\n      'notSupported': true\n    }]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Max',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'Mean',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'Min',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'Sum',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'All',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'Any',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'ArgMax',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'ArgMin',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'Prod',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'Cumsum',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'exclusive', 'name': 'exclusive', 'type': 'bool'},\n      {'tfName': 'reverse', 'name': 'reverse', 'type': 'bool'}\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'ConcatV2',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'end': -1, 'name': 'tensors', 'type': 'tensors'},\n      {'start': -1, 'name': 'axis', 'type': 'number'}\n    ],\n    'attrs':\n        [{'tfName': 'N', 'name': 'n', 'type': 'number', 'defaultValue': 2}]\n  },\n  {\n    'tfOpName': 'Concat',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 1, 'end': 0, 'name': 'tensors', 'type': 'tensors'},\n      {'start': 0, 'name': 'axis', 'type': 'number'}\n    ],\n    'attrs': [{'tfName': 'N', 'name': 'n', 'type': 'number', 'defaultValue': 2}]\n\n  },\n  {\n    'tfOpName': 'GatherV2',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'tensor'},\n      {'start': 2, 'name': 'axis', 'type': 'number', 'defaultValue': 0}\n    ]\n  },\n  {\n    'tfOpName': 'Gather',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'axis', 'name': 'axis', 'type': 'number', 'defaultValue': 0}, {\n        'tfName': 'validate_indices',\n        'name': 'validateIndices',\n        'type': 'bool',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Reverse',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'dims', 'type': 'bool', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'ReverseV2',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'Slice',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'begin', 'type': 'number[]'},\n      {'start': 2, 'name': 'size', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'StridedSlice',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'begin', 'type': 'number[]'},\n      {'start': 2, 'name': 'end', 'type': 'number[]'},\n      {'start': 3, 'name': 'strides', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'begin_mask',\n        'name': 'beginMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'end_mask',\n        'name': 'endMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'new_axis_mask',\n        'name': 'newAxisMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'ellipsis_mask',\n        'name': 'ellipsisMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'shrink_axis_mask',\n        'name': 'shrinkAxisMask',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Pack',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'end': 0, 'name': 'tensors', 'type': 'tensors'},\n    ],\n    'attrs': [\n      {'tfName': 'axis', 'name': 'axis', 'type': 'number', 'defaultValue': 0}\n    ]\n  },\n  {\n    'tfOpName': 'Unpack',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'axis', 'name': 'axis', 'type': 'number', 'defaultValue': 0}, {\n        'tfName': 'num',\n        'name': 'num',\n        'type': 'number',\n        'defaultValue': 0,\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Tile',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'reps', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'Split',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'axis', 'type': 'number', 'defaultValue': 0},\n      {'start': 1, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'num_split',\n      'name': 'numOrSizeSplits',\n      'type': 'number',\n      'defaultValue': 1\n    }]\n  },\n  {\n    'tfOpName': 'SplitV',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'numOrSizeSplits', 'type': 'number[]'},\n      {'start': 2, 'name': 'axis', 'type': 'number', 'defaultValue': 0}\n    ]\n  },\n  {\n    'tfOpName': 'ScatterNd',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'indices', 'type': 'tensor'},\n      {'start': 1, 'name': 'values', 'type': 'tensor'},\n      {'start': 2, 'name': 'shape', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'GatherNd',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'tensor'}\n    ]\n  },\n  {\n    'tfOpName': 'SparseToDense',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'sparseIndices', 'type': 'tensor'},\n      {'start': 1, 'name': 'outputShape', 'type': 'number[]'},\n      {'start': 2, 'name': 'sparseValues', 'type': 'tensor'},\n      {'start': 3, 'name': 'defaultValue', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'validate_indices',\n      'name': 'validateIndices',\n      'type': 'bool',\n      'defaultValue': false,\n      'notSupported': true\n    }]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'FFT',\n    'category': 'spectral',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'IFFT',\n    'category': 'spectral',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'RFFT',\n    'category': 'spectral',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'}, {\n        'start': 1,\n        'name': 'fft_length',\n        'type': 'number',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'IRFFT',\n    'category': 'spectral',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'}, {\n        'start': 1,\n        'name': 'fft_length',\n        'type': 'number',\n        'notSupported': true\n      }\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Cast',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'SrcT',\n        'name': 'sdtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {'tfName': 'DstT', 'name': 'dtype', 'type': 'dtype'}\n    ]\n  },\n  {\n    'tfOpName': 'ExpandDims',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'Pad',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'padding', 'type': 'number[]'},\n    ],\n    'attrs': [{\n      'tfName': 'constant_value',\n      'name': 'constantValue',\n      'type': 'number',\n      'defaultValue': 0\n    }]\n  },\n  {\n    'tfOpName': 'PadV2',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'padding', 'type': 'number[]'}, {\n        'start': 2,\n        'name': 'constantValue',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Reshape',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'shape', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'Squeeze',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'axis',\n      'tfDeprecatedName': 'squeeze_dims',\n      'name': 'axis',\n      'type': 'number[]'\n    }]\n  },\n  {\n    'tfOpName': 'SpaceToBatchND',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'blockShape', 'type': 'number[]'},\n      {'start': 2, 'name': 'paddings', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'BatchToSpaceND',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'blockShape', 'type': 'number[]'},\n      {'start': 2, 'name': 'crops', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'DepthToSpace',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'block_size', 'name': 'blockSize', 'type': 'number'},\n      {'tfName': 'data_format', 'name': 'dataFormat', 'type': 'string'}\n    ]\n  },\n  {\n    'tfOpName': 'BroadcastTo',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'shape', 'type': 'number[]'},\n    ],\n    'attrs': []\n  }\n];\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, env} from '@tensorflow/tfjs-core';\n\nimport * as tensorflow from '../data/compiled_api';\nimport {getRegisteredOp} from './custom_op/register';\n\nimport {getNodeNameAndIndex} from './executors/utils';\nimport * as arithmetic from './op_list/arithmetic';\nimport * as basicMath from './op_list/basic_math';\nimport * as control from './op_list/control';\nimport * as convolution from './op_list/convolution';\nimport * as creation from './op_list/creation';\nimport * as dynamic from './op_list/dynamic';\nimport * as evaluation from './op_list/evaluation';\nimport * as graph from './op_list/graph';\nimport * as image from './op_list/image';\nimport * as logical from './op_list/logical';\nimport * as matrices from './op_list/matrices';\nimport * as normalization from './op_list/normalization';\nimport * as reduction from './op_list/reduction';\nimport * as sliceJoin from './op_list/slice_join';\nimport * as spectral from './op_list/spectral';\nimport * as transformation from './op_list/transformation';\nimport {Graph, InputParamValue, Node, OpMapper, ParamValue} from './types';\n\nexport class OperationMapper {\n  private static _instance: OperationMapper;\n\n  private opMappers: {[key: string]: OpMapper};\n\n  // Singleton instance for the mapper\n  public static get Instance() {\n    return this._instance || (this._instance = new this());\n  }\n\n  // Loads the op mapping from the JSON file.\n  private constructor() {\n    const ops = [\n      arithmetic, basicMath, control, convolution, creation, dynamic,\n      evaluation, logical, image, graph, matrices, normalization, reduction,\n      sliceJoin, spectral, transformation\n    ];\n    const mappersJson: OpMapper[] = [].concat(...ops.map(op => op.json));\n\n    this.opMappers = mappersJson.reduce<{[key: string]: OpMapper}>(\n        (map, mapper: OpMapper) => {\n          map[mapper.tfOpName] = mapper;\n          return map;\n        },\n        {});\n  }\n\n  // Converts the model from Tensorflow GraphDef to local representation for\n  // TensorFlow.js API\n  transformGraph(\n      graph: tensorflow.IGraphDef,\n      signature: tensorflow.ISignatureDef = {}): Graph {\n    const tfNodes = graph.node;\n    const placeholders: Node[] = [];\n    const weights: Node[] = [];\n    const nodes = tfNodes.reduce<{[key: string]: Node}>((map, node) => {\n      map[node.name] = this.mapNode(node);\n      if (node.op.startsWith('Placeholder')) {\n        placeholders.push(map[node.name]);\n      }\n      if (node.op === 'Const') {\n        weights.push(map[node.name]);\n      }\n      return map;\n    }, {});\n\n    let inputs: Node[] = [];\n    const outputs: Node[] = [];\n    let inputNodeNameToKey: {[key: string]: string} = {};\n    let outputNodeNameToKey: {[key: string]: string} = {};\n    if (signature != null) {\n      inputNodeNameToKey = this.mapSignatureEntries(signature.inputs);\n      outputNodeNameToKey = this.mapSignatureEntries(signature.outputs);\n    }\n    const allNodes = Object.keys(nodes);\n    allNodes.forEach(key => {\n      const node = nodes[key];\n      node.inputNames.forEach(name => {\n        const [nodeName, ] = getNodeNameAndIndex(name);\n        node.inputs.push(nodes[nodeName]);\n        nodes[nodeName].children.push(node);\n      });\n    });\n\n    // if signature has not outputs set, add any node that does not have\n    // outputs.\n    if (Object.keys(outputNodeNameToKey).length === 0) {\n      allNodes.forEach(key => {\n        const node = nodes[key];\n        if (node.children.length === 0) {\n          outputs.push(node);\n        }\n      });\n    } else {\n      Object.keys(outputNodeNameToKey).forEach(name => {\n        const [nodeName, ] = getNodeNameAndIndex(name);\n        const node = nodes[nodeName];\n        if (node != null) {\n          node.signatureKey = outputNodeNameToKey[name];\n          outputs.push(node);\n        }\n      });\n    }\n\n    if (Object.keys(inputNodeNameToKey).length > 0) {\n      Object.keys(inputNodeNameToKey).forEach(name => {\n        const [nodeName, ] = getNodeNameAndIndex(name);\n        const node = nodes[nodeName];\n        if (node) {\n          node.signatureKey = inputNodeNameToKey[name];\n          inputs.push(node);\n        }\n      });\n    } else {\n      inputs = placeholders;\n    }\n\n    let functions = {};\n    if (graph.library != null && graph.library.function != null) {\n      functions = graph.library.function.reduce((functions, func) => {\n        functions[func.signature.name] = this.mapFunction(func);\n        return functions;\n      }, {} as {[key: string]: Graph});\n    }\n\n    return {\n      nodes,\n      inputs,\n      outputs,\n      weights,\n      placeholders,\n      signature,\n      functions\n    };\n  }\n\n  private mapSignatureEntries(entries: {[k: string]: tensorflow.ITensorInfo}) {\n    return Object.keys(entries || {})\n        .reduce<{[key: string]: string}>((prev, curr) => {\n          prev[entries[curr].name] = curr;\n          return prev;\n        }, {});\n  }\n\n  private mapNode(node: tensorflow.INodeDef): Node {\n    // Unsupported ops will cause an error at run-time (not parse time), since\n    // they may not be used by the actual execution subgraph.\n    const mapper =\n        getRegisteredOp(node.op) || this.opMappers[node.op] || {} as OpMapper;\n    if (node.attr == null) {\n      node.attr = {};\n    }\n\n    const newNode: Node = {\n      name: node.name,\n      op: node.op,\n      category: mapper.category,\n      inputNames:\n          (node.input ||\n           []).map(input => input.startsWith('^') ? input.substr(1) : input),\n      inputs: [],\n      children: [],\n      inputParams: {},\n      attrParams: {},\n      rawAttrs: node.attr\n    };\n\n    if (mapper.inputs != null) {\n      newNode.inputParams =\n          mapper.inputs.reduce<{[key: string]: InputParamValue}>(\n              (map, param) => {\n                map[param.name] = {\n                  type: param.type,\n                  inputIndexStart: param.start,\n                  inputIndexEnd: param.end\n                };\n                return map;\n              },\n              {});\n    }\n    if (mapper.attrs != null) {\n      newNode.attrParams =\n          mapper.attrs.reduce<{[key: string]: ParamValue}>((map, param) => {\n            const type = param.type;\n            let value = undefined;\n            switch (param.type) {\n              case 'string':\n                value = getStringParam(\n                    node.attr, param.tfName, param.defaultValue as string);\n\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getStringParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as string);\n                }\n                break;\n              case 'string[]':\n                value = getStringArrayParam(\n                    node.attr, param.tfName, param.defaultValue as string[]);\n\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getStringArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as string[]);\n                }\n                break;\n              case 'number':\n                value = getNumberParam(\n                    node.attr, param.tfName,\n                    (param.defaultValue || 0) as number);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getNumberParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number);\n                }\n                break;\n              case 'number[]':\n                value = getNumericArrayParam(\n                    node.attr, param.tfName, param.defaultValue as number[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getNumericArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number[]);\n                }\n                break;\n              case 'bool':\n                value = getBoolParam(\n                    node.attr, param.tfName, param.defaultValue as boolean);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getBoolParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as boolean);\n                }\n                break;\n              case 'bool[]':\n                value = getBoolArrayParam(\n                    node.attr, param.tfName, param.defaultValue as boolean[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getBoolArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as boolean[]);\n                }\n                break;\n              case 'shape':\n                value = getTensorShapeParam(\n                    node.attr, param.tfName, param.defaultValue as number[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getTensorShapeParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number[]);\n                }\n                break;\n              case 'shape[]':\n                value = getTensorShapeArrayParam(\n                    node.attr, param.tfName, param.defaultValue as number[][]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getTensorShapeArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number[][]);\n                }\n                break;\n              case 'dtype':\n                value = getDtypeParam(\n                    node.attr, param.tfName, param.defaultValue as DataType);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getDtypeParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as DataType);\n                }\n                break;\n              case 'dtype[]':\n                value = getDtypeArrayParam(\n                    node.attr, param.tfName, param.defaultValue as DataType[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getDtypeArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as DataType[]);\n                }\n                break;\n              case 'func':\n                value = getFuncParam(\n                    node.attr, param.tfName, param.defaultValue as string);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getFuncParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as string);\n                }\n                break;\n              case 'tensor':\n              case 'tensors':\n                break;\n              default:\n                throw new Error(\n                    `Unsupported param type: ${param.type} for op: ${node.op}`);\n            }\n            map[param.name] = {value, type};\n            return map;\n          }, {});\n    }\n    return newNode;\n  }\n\n  // map the TFunctionDef to TFJS graph object\n  private mapFunction(functionDef: tensorflow.IFunctionDef): Graph {\n    const tfNodes = functionDef.nodeDef;\n    const placeholders: Node[] = [];\n    const weights: Node[] = [];\n    let nodes: {[key: string]: Node} = {};\n    if (tfNodes != null) {\n      nodes = tfNodes.reduce<{[key: string]: Node}>((map, node) => {\n        map[node.name] = this.mapNode(node);\n        if (node.op === 'Const') {\n          weights.push(map[node.name]);\n        }\n        return map;\n      }, {});\n    }\n    const inputs: Node[] = [];\n    const outputs: Node[] = [];\n\n    functionDef.signature.inputArg.forEach(arg => {\n      const [nodeName, ] = getNodeNameAndIndex(arg.name);\n      const node: Node = {\n        name: nodeName,\n        op: 'Placeholder',\n        inputs: [],\n        inputNames: [],\n        category: 'graph',\n        inputParams: {},\n        attrParams: {dtype: {value: parseDtypeParam(arg.type), type: 'dtype'}},\n        children: []\n      };\n      node.signatureKey = arg.name;\n      inputs.push(node);\n      nodes[nodeName] = node;\n    });\n\n    const allNodes = Object.keys(nodes);\n    allNodes.forEach(key => {\n      const node = nodes[key];\n      node.inputNames.forEach(name => {\n        const [nodeName, ] = getNodeNameAndIndex(name);\n        node.inputs.push(nodes[nodeName]);\n        nodes[nodeName].children.push(node);\n      });\n    });\n\n    const returnNodeMap = functionDef.ret;\n\n    functionDef.signature.outputArg.forEach(output => {\n      const [nodeName, index] = getNodeNameAndIndex(returnNodeMap[output.name]);\n      const node = nodes[nodeName];\n      if (node != null) {\n        node.defaultOutput = index;\n        outputs.push(node);\n      }\n    });\n\n    const signature = this.mapArgsToSignature(functionDef);\n    return {nodes, inputs, outputs, weights, placeholders, signature};\n  }\n\n  private mapArgsToSignature(functionDef: tensorflow.IFunctionDef):\n      tensorflow.ISignatureDef {\n    return {\n      methodName: functionDef.signature.name,\n      inputs: functionDef.signature.inputArg.reduce(\n          (map, arg) => {\n            map[arg.name] = this.mapArgToTensorInfo(arg);\n            return map;\n          },\n          {} as {[key: string]: tensorflow.ITensorInfo}),\n      outputs: functionDef.signature.outputArg.reduce(\n          (map, arg) => {\n            map[arg.name] = this.mapArgToTensorInfo(arg, functionDef.ret);\n            return map;\n          },\n          {} as {[key: string]: tensorflow.ITensorInfo}),\n    };\n  }\n\n  private mapArgToTensorInfo(\n      arg: tensorflow.OpDef.IArgDef,\n      nameMap?: {[key: string]: string}): tensorflow.ITensorInfo {\n    let name = arg.name;\n    if (nameMap != null) {\n      name = nameMap[name];\n    }\n    return {name, dtype: arg.type};\n  }\n}\n\nexport function decodeBase64(text: string): string {\n  const global = env().global;\n  if (typeof global.atob !== 'undefined') {\n    return global.atob(text);\n  } else if (typeof Buffer !== 'undefined') {\n    return new Buffer(text, 'base64').toString();\n  } else {\n    throw new Error(\n        'Unable to decode base64 in this environment. ' +\n        'Missing built-in atob() or Buffer()');\n  }\n}\n\nexport function parseStringParam(s: []|string, keepCase: boolean): string {\n  const value =\n      Array.isArray(s) ? String.fromCharCode.apply(null, s) : decodeBase64(s);\n  return keepCase ? value : value.toLowerCase();\n}\n\nexport function getStringParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string, def: string,\n    keepCase = false): string {\n  const param = attrs[name];\n  if (param != null) {\n    return parseStringParam(param.s, keepCase);\n  }\n  return def;\n}\n\nexport function getBoolParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: boolean): boolean {\n  const param = attrs[name];\n  return param ? param.b : def;\n}\n\nexport function getNumberParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: number): number {\n  const param = attrs[name] || {};\n  const value =\n      param['i'] != null ? param['i'] : (param['f'] != null ? param['f'] : def);\n  return (typeof value === 'number') ? value : parseInt(value, 10);\n}\n\nexport function parseDtypeParam(value: string|tensorflow.DataType): DataType {\n  if (typeof (value) === 'string') {\n    // tslint:disable-next-line:no-any\n    value = tensorflow.DataType[value as any];\n  }\n  switch (value) {\n    case tensorflow.DataType.DT_FLOAT:\n      return 'float32';\n    case tensorflow.DataType.DT_INT32:\n    case tensorflow.DataType.DT_INT64:\n    case tensorflow.DataType.DT_INT8:\n    case tensorflow.DataType.DT_UINT8:\n      return 'int32';\n    case tensorflow.DataType.DT_BOOL:\n      return 'bool';\n    case tensorflow.DataType.DT_DOUBLE:\n      return 'float32';\n    case tensorflow.DataType.DT_STRING:\n      return 'string';\n    default:\n      // Unknown dtype error will happen at runtime (instead of parse time),\n      // since these nodes might not be used by the actual subgraph execution.\n      return null;\n  }\n}\n\nexport function getFuncParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: string): string {\n  const param = attrs[name];\n  if (param && param.func) {\n    return param.func.name;\n  }\n  return def;\n}\n\nexport function getDtypeParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: DataType): DataType {\n  const param = attrs[name];\n  if (param && param.type) {\n    return parseDtypeParam(param.type);\n  }\n  return def;\n}\n\nexport function getDtypeArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: DataType[]): DataType[] {\n  const param = attrs[name];\n  if (param && param.list && param.list.type) {\n    return param.list.type.map(v => parseDtypeParam(v));\n  }\n  return def;\n}\n\nexport function parseTensorShapeParam(shape: tensorflow.ITensorShape): number[]|\n    undefined {\n  if (shape.unknownRank) {\n    return undefined;\n  }\n  if (shape.dim != null) {\n    return shape.dim.map(\n        dim =>\n            (typeof dim.size === 'number') ? dim.size : parseInt(dim.size, 10));\n  }\n  return [];\n}\n\nexport function getTensorShapeParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def?: number[]): number[]|undefined {\n  const param = attrs[name];\n  if (param && param.shape) {\n    return parseTensorShapeParam(param.shape);\n  }\n  return def;\n}\n\nexport function getNumericArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: number[]): number[] {\n  const param = attrs[name];\n  if (param) {\n    return ((param.list.f && param.list.f.length ? param.list.f :\n                                                   param.list.i) ||\n            [])\n        .map(v => (typeof v === 'number') ? v : parseInt(v, 10));\n  }\n  return def;\n}\n\nexport function getStringArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string, def: string[],\n    keepCase = false): string[] {\n  const param = attrs[name];\n  if (param && param.list && param.list.s) {\n    return param.list.s.map((v) => {\n      return parseStringParam(v, keepCase);\n    });\n  }\n  return def;\n}\n\nexport function getTensorShapeArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: number[][]): number[][] {\n  const param = attrs[name];\n  if (param && param.list && param.list.shape) {\n    return param.list.shape.map((v) => {\n      return parseTensorShapeParam(v);\n    });\n  }\n  return def;\n}\n\nexport function getBoolArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: boolean[]): boolean[] {\n  const param = attrs[name];\n  if (param && param.list && param.list.b) {\n    return param.list.b;\n  }\n  return def;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, Tensor} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {getTensor} from '../executors/utils';\nimport {getBoolArrayParam, getBoolParam, getDtypeArrayParam, getDtypeParam, getNumberParam, getNumericArrayParam, getStringArrayParam, getStringParam, getTensorShapeArrayParam, getTensorShapeParam} from '../operation_mapper';\nimport {GraphNode, Node, ValueType} from '../types';\n\n/**\n * Helper class for lookup inputs and params for nodes in the model graph.\n */\nexport class NodeValueImpl implements GraphNode {\n  public readonly inputs: Tensor[] = [];\n  public readonly attrs: {[key: string]: ValueType} = {};\n  constructor(\n      private node: Node, private tensorMap: NamedTensorsMap,\n      private context: ExecutionContext) {\n    this.inputs = node.inputNames.map(name => this.getInput(name));\n    if (node.rawAttrs != null) {\n      this.attrs = Object.keys(node.rawAttrs)\n                       .reduce((attrs: {[key: string]: ValueType}, key) => {\n                         attrs[key] = this.getAttr(key);\n                         return attrs;\n                       }, {});\n    }\n  }\n\n  /**\n   * Return the value of the attribute or input param.\n   * @param name String: name of attribute or input param.\n   */\n  private getInput(name: string): Tensor {\n    return getTensor(name, this.tensorMap, this.context);\n  }\n\n  /**\n   * Return the value of the attribute or input param.\n   * @param name String: name of attribute or input param.\n   */\n  private getAttr(name: string, defaultValue?: ValueType): ValueType {\n    const value = this.node.rawAttrs[name];\n    if (value.tensor != null) {\n      return getTensor(name, this.tensorMap, this.context);\n    }\n    if (value.i != null || value.f != null) {\n      return getNumberParam(this.node.rawAttrs, name, defaultValue as number);\n    }\n    if (value.s != null) {\n      return getStringParam(this.node.rawAttrs, name, defaultValue as string);\n    }\n    if (value.b != null) {\n      return getBoolParam(this.node.rawAttrs, name, defaultValue as boolean);\n    }\n    if (value.shape != null) {\n      return getTensorShapeParam(\n          this.node.rawAttrs, name, defaultValue as number[]);\n    }\n    if (value.type != null) {\n      return getDtypeParam(this.node.rawAttrs, name, defaultValue as DataType);\n    }\n    if (value.list != null) {\n      if (value.list.i != null || value.list.f != null) {\n        return getNumericArrayParam(\n            this.node.rawAttrs, name, defaultValue as number[]);\n      }\n      if (value.list.s != null) {\n        return getStringArrayParam(\n            this.node.rawAttrs, name, defaultValue as string[]);\n      }\n      if (value.list.shape != null) {\n        return getTensorShapeArrayParam(\n            this.node.rawAttrs, name, defaultValue as number[][]);\n      }\n      if (value.list.b != null) {\n        return getBoolArrayParam(\n            this.node.rawAttrs, name, defaultValue as boolean[]);\n      }\n      if (value.list.type != null) {\n        return getDtypeArrayParam(\n            this.node.rawAttrs, name, defaultValue as DataType[]);\n      }\n    }\n\n    return defaultValue;\n  }\n}\n","\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * This differs from util.assertShapesMatch in that it allows values of\n * negative one, an undefined size of a dimensinon, in a shape to match\n * anything.\n */\n\nimport {util} from '@tensorflow/tfjs-core';\n\nexport function assertShapesMatchAllowUndefinedSize(\n    shapeA: number[], shapeB: number[], errorMessagePrefix = ''): void {\n  util.assert(\n      shapesEqualAllowUndefinedSize(shapeA, shapeB),\n      () => errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);\n}\n\nexport function shapesEqualAllowUndefinedSize(n1: number[], n2: number[]) {\n  if (n1.length !== n2.length) {\n    return false;\n  }\n  for (let i = 0; i < n1.length; i++) {\n    if (n1[i] !== -1 && n2[i] !== -1 && n1[i] !== n2[i]) {\n      return false;\n    }\n  }\n  return true;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {concat, DataType, keep, scalar, slice, stack, Tensor, tensor, tidy, unstack} from '@tensorflow/tfjs-core';\n\nimport {assertShapesMatchAllowUndefinedSize} from './tensor_utils';\n\nexport interface TensorWithState {\n  tensor?: Tensor;\n  written?: boolean;\n  read?: boolean;\n  cleared?: boolean;\n}\n/**\n * The TensorArray object keeps an array of Tensors.  It\n * allows reading from the array and writing to the array.\n */\nexport class TensorArray {\n  private tensors: TensorWithState[] = [];\n  private closed_ = false;\n  readonly idTensor: Tensor;\n  constructor(\n      readonly name: string, readonly dtype: DataType, private maxSize: number,\n      private elementShape: number[], readonly identicalElementShapes: boolean,\n      readonly dynamicSize: boolean, readonly clearAfterRead: boolean) {\n    this.idTensor = scalar(0);\n    keep(this.idTensor);\n  }\n\n  get id() {\n    return this.idTensor.id;\n  }\n\n  get closed() {\n    return this.closed_;\n  }\n\n  /**\n   * Dispose the tensors and idTensor and mark the TensoryArray as closed.\n   */\n  clearAndClose() {\n    this.tensors.forEach(tensor => tensor.tensor.dispose());\n    this.tensors = [];\n    this.closed_ = true;\n    this.idTensor.dispose();\n  }\n\n  size(): number {\n    return this.tensors.length;\n  }\n\n  /**\n   * Read the value at location index in the TensorArray.\n   * @param index Number the index to read from.\n   */\n  read(index: number): Tensor {\n    if (this.closed_) {\n      throw new Error(`TensorArray ${this.name} has already been closed.`);\n    }\n\n    if (index < 0 || index >= this.size()) {\n      throw new Error(`Tried to read from index ${index}, but array size is: ${\n          this.size()}`);\n    }\n\n    const tensorWithState = this.tensors[index];\n    if (tensorWithState.cleared) {\n      throw new Error(\n          `TensorArray ${this.name}: Could not read index ${\n              index} twice because it was cleared after a previous read ` +\n          `(perhaps try setting clear_after_read = false?).`);\n    }\n\n    if (this.clearAfterRead) {\n      tensorWithState.cleared = true;\n    }\n\n    tensorWithState.read = true;\n    return tensorWithState.tensor;\n  }\n\n  /**\n   * Helper method to read multiple tensors from the specified indices.\n   */\n  readMany(indices: number[]): Tensor[] {\n    return indices.map(index => this.read(index));\n  }\n\n  /**\n   * Write value into the index of the TensorArray.\n   * @param index number the index to write to.\n   * @param tensor\n   */\n  write(index: number, tensor: Tensor) {\n    if (this.closed_) {\n      throw new Error(`TensorArray ${this.name} has already been closed.`);\n    }\n\n    if (index < 0 || !this.dynamicSize && index >= this.maxSize) {\n      throw new Error(`Tried to write to index ${\n          index}, but array is not resizeable and size is: ${this.maxSize}`);\n    }\n\n    const t = this.tensors[index] || {};\n\n    if (tensor.dtype !== this.dtype) {\n      throw new Error(`TensorArray ${\n          this.name}: Could not write to TensorArray index ${index},\n          because the value dtype is ${\n          tensor.dtype}, but TensorArray dtype is ${this.dtype}.`);\n    }\n\n    // Set the shape for the first time write to unknow shape tensor array\n    if (this.size() === 0 &&\n        (this.elementShape == null || this.elementShape.length === 0)) {\n      this.elementShape = tensor.shape;\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensor.shape,\n        `TensorArray ${this.name}: Could not write to TensorArray index ${\n            index}.`);\n\n    if (t.read) {\n      throw new Error(\n          `TensorArray ${this.name}: Could not write to TensorArray index ${\n              index}, because it has already been read.`);\n    }\n\n    if (t.written) {\n      throw new Error(\n          `TensorArray ${this.name}: Could not write to TensorArray index ${\n              index}, because it has already been written.`);\n    }\n\n    t.tensor = tensor;\n    keep(tensor);\n    t.written = true;\n\n    this.tensors[index] = t;\n  }\n\n  /**\n   * Helper method to write multiple tensors to the specified indices.\n   */\n  writeMany(indices: number[], tensors: Tensor[]) {\n    if (indices.length !== tensors.length) {\n      throw new Error(\n          `TensorArray ${this.name}: could not write multiple tensors,` +\n          `because the index size: ${\n              indices.length} is not the same as tensors size: ${\n              tensors.length}.`);\n    }\n\n    indices.forEach((i, index) => this.write(i, tensors[index]));\n  }\n\n  /**\n   * Return selected values in the TensorArray as a packed Tensor. All of\n   * selected values must have been written and their shapes must all match.\n   * @param [indices] number[] Optional. Taking values in [0, max_value). If the\n   *    TensorArray is not dynamic, max_value=size(). If not specified returns\n   *    all tensors in the original order.\n   * @param [dtype]\n   */\n  gather(indices?: number[], dtype?: DataType): Tensor {\n    if (!!dtype && dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but gather requested dtype ${dtype}`);\n    }\n\n    if (!indices) {\n      indices = [];\n      for (let i = 0; i < this.size(); i++) {\n        indices.push(i);\n      }\n    } else {\n      indices = indices.slice(0, this.size());\n    }\n\n    if (indices.length === 0) {\n      return tensor([], [0].concat(this.elementShape));\n    }\n\n    // Read all the PersistentTensors into a vector to keep track of\n    // their memory.\n    const tensors = this.readMany(indices);\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensors[0].shape, 'TensorArray shape mismatch: ');\n\n    return stack(tensors, 0);\n  }\n\n  /**\n   * Return the values in the TensorArray as a concatenated Tensor.\n   */\n  concat(dtype?: DataType): Tensor {\n    if (!!dtype && dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but concat requested dtype ${dtype}`);\n    }\n\n    if (this.size() === 0) {\n      return tensor([], [0].concat(this.elementShape));\n    }\n\n    const indices = [];\n    for (let i = 0; i < this.size(); i++) {\n      indices.push(i);\n    }\n    // Collect all the tensors from the tensors array.\n    const tensors = this.readMany(indices);\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensors[0].shape,\n        `TensorArray shape mismatch: tensor array shape (${\n            this.elementShape}) vs first tensor shape (${tensors[0].shape})`);\n\n    return concat(tensors, 0);\n  }\n\n  /**\n   * Scatter the values of a Tensor in specific indices of a TensorArray.\n   * @param indices nummber[] values in [0, max_value). If the\n   *    TensorArray is not dynamic, max_value=size().\n   * @param tensor Tensor input tensor.\n   */\n  scatter(indices: number[], tensor: Tensor) {\n    if (tensor.dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but tensor has dtype ${tensor.dtype}`);\n    }\n\n    if (indices.length !== tensor.shape[0]) {\n      throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${\n          indices.length} vs. ${tensor.shape[0]}`);\n    }\n\n    const maxIndex = Math.max(...indices);\n\n    if (!this.dynamicSize && maxIndex >= this.maxSize) {\n      throw new Error(\n          `Max index must be < array size (${maxIndex}  vs. ${this.maxSize})`);\n    }\n\n    this.writeMany(indices, unstack(tensor, 0));\n  }\n\n  /**\n   * Split the values of a Tensor into the TensorArray.\n   * @param length number[] with the lengths to use when splitting value along\n   *    its first dimension.\n   * @param tensor Tensor, the tensor to split.\n   */\n  split(length: number[], tensor: Tensor) {\n    if (tensor.dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but tensor has dtype ${tensor.dtype}`);\n    }\n    let totalLength = 0;\n    const cumulativeLengths = length.map(len => {\n      totalLength += len;\n      return totalLength;\n    });\n\n    if (totalLength !== tensor.shape[0]) {\n      throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${totalLength}, and tensor's shape is: ${tensor.shape}`);\n    }\n\n    if (!this.dynamicSize && length.length !== this.maxSize) {\n      throw new Error(\n          `TensorArray's size is not equal to the size of lengths (${\n              this.maxSize} vs. ${length.length}), ` +\n          'and the TensorArray is not marked as dynamically resizeable');\n    }\n\n    const elementPerRow = totalLength === 0 ? 0 : tensor.size / totalLength;\n    const tensors: Tensor[] = [];\n    tidy(() => {\n      tensor = tensor.reshape([1, totalLength, elementPerRow]);\n      for (let i = 0; i < length.length; ++i) {\n        const previousLength = (i === 0) ? 0 : cumulativeLengths[i - 1];\n        const indices = [0, previousLength, 0];\n        const sizes = [1, length[i], elementPerRow];\n        tensors[i] = slice(tensor, indices, sizes).reshape(this.elementShape);\n      }\n      return tensors;\n    });\n    const indices = [];\n    for (let i = 0; i < length.length; i++) {\n      indices[i] = i;\n    }\n    this.writeMany(indices, tensors);\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {concat, DataType, keep, scalar, slice, stack, Tensor, tensor, tidy, unstack} from '@tensorflow/tfjs-core';\n\nimport {assertShapesMatchAllowUndefinedSize} from './tensor_utils';\n\n/**\n * TensorList stores a container of `tf.Tensor` objects, which are accessible\n * via tensors field.\n *\n * In order to get a copy of the underlying list, use the copy method:\n * ```\n *    TensorList b = a.copy();\n *    b.tensors().pushBack(t);  // This does not modify a.tensors().\n * ```\n *\n * Note that this is not a deep copy: the memory locations of the underlying\n * tensors will still point to the same locations of the corresponding tensors\n * in the original.\n */\n\nexport class TensorList {\n  readonly idTensor: Tensor;\n  maxNumElements: number;\n\n  get id() {\n    return this.idTensor.id;\n  }\n  /**\n   *\n   * @param tensors list of tensors\n   * @param elementShape shape of each tensor\n   * @param elementDtype data type of each tensor\n   * @param maxNumElements The maximum allowed size of `tensors`. Defaults to -1\n   *   meaning that the size of `tensors` is unbounded.\n   */\n  constructor(\n      readonly tensors: Tensor[], readonly elementShape: number[],\n      readonly elementDtype: DataType, maxNumElements = -1) {\n    if (tensors != null) {\n      tensors.forEach(tensor => {\n        if (elementDtype !== tensor.dtype) {\n          throw new Error(`Invalid data types; op elements ${\n              elementDtype}, but list elements ${tensor.dtype}`);\n        }\n        assertShapesMatchAllowUndefinedSize(\n            elementShape, tensor.shape, 'TensorList shape mismatch: ');\n\n        keep(tensor);\n      });\n    }\n    this.idTensor = scalar(0);\n    this.maxNumElements = maxNumElements;\n    keep(this.idTensor);\n  }\n\n  /**\n   * Get a new TensorList containing a copy of the underlying tensor container.\n   */\n  copy(): TensorList {\n    return new TensorList(\n        [...this.tensors], this.elementShape, this.elementDtype);\n  }\n\n  /**\n   * Dispose the tensors and idTensor and clear the tensor list.\n   */\n  clearAndClose() {\n    this.tensors.forEach(tensor => tensor.dispose());\n    this.tensors.length = 0;\n    this.idTensor.dispose();\n  }\n  /**\n   * The size of the tensors in the tensor list.\n   */\n  size() {\n    return this.tensors.length;\n  }\n\n  /**\n   * Return a tensor that stacks a list of rank-R tf.Tensors into one rank-(R+1)\n   * tf.Tensor.\n   * @param elementShape shape of each tensor\n   * @param elementDtype data type of each tensor\n   * @param numElements the number of elements to stack\n   */\n  stack(elementShape: number[], elementDtype: DataType, numElements = -1):\n      Tensor {\n    if (elementDtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          elementDtype}, but list elements ${this.elementDtype}`);\n    }\n    if (numElements !== -1 && this.tensors.length !== numElements) {\n      throw new Error(`Operation expected a list with ${\n          numElements} elements but got a list with ${\n          this.tensors.length} elements.`);\n    }\n    assertShapesMatchAllowUndefinedSize(\n        elementShape, this.elementShape, 'TensorList shape mismatch: ');\n    return tidy(() => {\n      const reshapedTensors =\n          this.tensors.map(tensor => tensor.reshape(elementShape));\n      return stack(reshapedTensors, 0);\n    });\n  }\n\n  /**\n   * Pop a tensor from the end of the list.\n   * @param elementShape shape of the tensor\n   * @param elementDtype data type of the tensor\n   */\n  popBack(elementShape: number[], elementDtype: DataType): Tensor {\n    if (elementDtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          elementDtype}, but list elements ${this.elementDtype}`);\n    }\n\n    if (this.size() === 0) {\n      throw new Error('Trying to pop from an empty list.');\n    }\n\n    const tensor = this.tensors.pop();\n    assertShapesMatchAllowUndefinedSize(\n        tensor.shape, elementShape, 'TensorList shape mismatch: ');\n    return tensor.reshape(elementShape);\n  }\n\n  /**\n   * Push a tensor to the end of the list.\n   * @param tensor Tensor to be pushed.\n   */\n  pushBack(tensor: Tensor) {\n    if (tensor.dtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          tensor.dtype}, but list elements ${this.elementDtype}`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        tensor.shape, this.elementShape, 'TensorList shape mismatch: ');\n\n    if (this.maxNumElements === this.size()) {\n      throw new Error(`Trying to push element into a full list.`);\n    }\n    keep(tensor);\n    this.tensors.push(tensor);\n  }\n\n  /**\n   * Update the size of the list.\n   * @param size the new size of the list.\n   */\n  resize(size: number) {\n    if (size < 0) {\n      throw new Error(\n          `TensorListResize expects size to be non-negative. Got: ${size}`);\n    }\n\n    if (this.maxNumElements !== -1 && size > this.maxNumElements) {\n      throw new Error(`TensorListResize input size ${\n          size} is greater maxNumElement ${this.maxNumElements}.`);\n    }\n    this.tensors.length = size;\n  }\n\n  /**\n   * Retrieve the element at the provided index\n   * @param elementShape shape of the tensor\n   * @param elementDtype dtype of the tensor\n   * @param elementIndex index of the tensor\n   */\n  getItem(elementIndex: number, elementShape: number[], elementDtype: DataType):\n      Tensor {\n    if (elementDtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          elementDtype}, but list elements ${this.elementDtype}`);\n    }\n    if (elementIndex < 0 || elementIndex > this.tensors.length) {\n      throw new Error(`Trying to access element ${\n          elementIndex} in a list with ${this.tensors.length} elements.`);\n    }\n\n    if (this.tensors[elementIndex] == null) {\n      throw new Error(`element at index ${elementIndex} is null.`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.tensors[elementIndex].shape, elementShape,\n        'TensorList shape mismatch: ');\n\n    return this.tensors[elementIndex];\n  }\n\n  /**\n   * Set the tensor at the index\n   * @param elementIndex index of the tensor\n   * @param tensor the tensor to be inserted into the list\n   */\n  setItem(elementIndex: number, tensor: Tensor) {\n    if (tensor.dtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          tensor.dtype}, but list elements ${this.elementDtype}`);\n    }\n\n    if (elementIndex < 0 ||\n        this.maxNumElements !== -1 && elementIndex >= this.maxNumElements) {\n      throw new Error(`Trying to set element ${\n          elementIndex} in a list with max ${this.maxNumElements} elements.`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensor.shape, 'TensorList shape mismatch: ');\n    keep(tensor);\n    this.tensors[elementIndex] = tensor;\n  }\n\n  /**\n   * Return selected values in the TensorList as a stacked Tensor. All of\n   * selected values must have been written and their shapes must all match.\n   * @param indices indices of tensors to gather\n   * @param elementDtype output tensor dtype\n   * @param elementShape output tensor element shape\n   */\n  gather(indices: number[], elementDtype: DataType, elementShape: number[]):\n      Tensor {\n    if (elementDtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          elementDtype}, but list elements ${this.elementDtype}`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, elementShape, 'TensorList shape mismatch: ');\n\n    // When indices is greater than the size of the list, indices beyond the\n    // size of the list are ignored.\n    indices = indices.slice(0, this.size());\n\n    if (indices.length === 0) {\n      return tensor([], [0].concat(this.elementShape));\n    }\n\n    return tidy(() => {\n      const tensors = indices.map(i => this.tensors[i].reshape(elementShape));\n      return stack(tensors, 0);\n    });\n  }\n\n  /**\n   * Return the values in the TensorList as a concatenated Tensor.\n   * @param elementDtype output tensor dtype\n   * @param elementShape output tensor element shape\n   */\n  concat(elementDtype: DataType, elementShape: number[]): Tensor {\n    if (!!elementDtype && elementDtype !== this.elementDtype) {\n      throw new Error(`TensorList dtype is ${\n          this.elementDtype} but concat requested dtype ${elementDtype}`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, elementShape, 'TensorList shape mismatch: ');\n\n    if (this.size() === 0) {\n      return tensor([], [0].concat(this.elementShape));\n    }\n\n    return tidy(() => {\n      const tensors = this.tensors.map(t => t.reshape(elementShape));\n      return concat(tensors, 0);\n    });\n  }\n}\n\n/**\n * Creates a TensorList which, when stacked, has the value of tensor.\n * @param tensor from tensor\n * @param elementShape output tensor element shape\n */\nexport function fromTensor(\n    tensor: Tensor, elementShape: number[], elementDtype: DataType) {\n  const dtype = tensor.dtype;\n  if (tensor.shape.length < 1) {\n    throw new Error(\n        `Tensor must be at least a vector, but saw shape: ${tensor.shape}`);\n  }\n  if (tensor.dtype !== elementDtype) {\n    throw new Error(`Invalid data types; op elements ${\n        tensor.dtype}, but list elements ${elementDtype}`);\n  }\n  const outputShape = tensor.shape.slice(1);\n  assertShapesMatchAllowUndefinedSize(\n      outputShape, elementShape, 'TensorList shape mismatch: ');\n\n  const tensorList: Tensor[] = tensor.unstack();\n  return new TensorList(tensorList, elementShape, dtype);\n}\n\n/**\n * Return a TensorList of the given size with empty elements.\n * @param elementShape the shape of the future elements of the list\n * @param elementDtype the desired type of elements in the list\n * @param numElements the number of elements to reserve\n */\nexport function reserve(\n    elementShape: number[], elementDtype: DataType, numElements: number) {\n  return new TensorList([], elementShape, elementDtype, numElements);\n}\n\n/**\n * Put tensors at specific indices of a stacked tensor into a TensorList.\n * @param indices list of indices on how to scatter the tensor.\n * @param tensor input tensor.\n * @param elementShape the shape of the future elements of the list\n * @param numElements the number of elements to scatter\n */\nexport function scatter(\n    tensor: Tensor, indices: number[], elementShape: number[],\n    numElements?: number): TensorList {\n  if (indices.length !== tensor.shape[0]) {\n    throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${\n        indices.length} vs. ${tensor.shape[0]}`);\n  }\n\n  const maxIndex = Math.max(...indices);\n\n  if (numElements != null && numElements !== -1 && maxIndex >= numElements) {\n    throw new Error(\n        `Max index must be < array size (${maxIndex}  vs. ${numElements})`);\n  }\n\n  const list = new TensorList([], elementShape, tensor.dtype, numElements);\n  const tensors = unstack(tensor, 0);\n  indices.forEach((value, index) => {\n    list.setItem(value, tensors[index]);\n  });\n  return list;\n}\n\n/**\n * Split the values of a Tensor into a TensorList.\n * @param length the lengths to use when splitting value along\n *    its first dimension.\n * @param tensor the tensor to split.\n * @param elementShape the shape of the future elements of the list\n */\nexport function split(\n    tensor: Tensor, length: number[], elementShape: number[]) {\n  let totalLength = 0;\n  const cumulativeLengths = length.map(len => {\n    totalLength += len;\n    return totalLength;\n  });\n\n  if (totalLength !== tensor.shape[0]) {\n    throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${totalLength}, and tensor's shape is: ${tensor.shape}`);\n  }\n\n  const elementPerRow = totalLength === 0 ? 0 : tensor.size / totalLength;\n  const tensors: Tensor[] = tidy(() => {\n    const tensors = [];\n    tensor = tensor.reshape([1, totalLength, elementPerRow]);\n    for (let i = 0; i < length.length; ++i) {\n      const previousLength = (i === 0) ? 0 : cumulativeLengths[i - 1];\n      const indices = [0, previousLength, 0];\n      const sizes = [1, length[i], elementPerRow];\n      tensors[i] = slice(tensor, indices, sizes).reshape(elementShape);\n    }\n    tensor.dispose();\n    return tensors;\n  });\n\n  const list = new TensorList([], elementShape, tensor.dtype, length.length);\n\n  for (let i = 0; i < tensors.length; i++) {\n    list.setItem(i, tensors[i]);\n  }\n  return list;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {scalar} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {TensorArray} from '../../executor/tensor_array';\nimport {fromTensor, reserve, scatter, split} from '../../executor/tensor_list';\nimport {InternalOpAsyncExecutor, Node} from '../types';\n\nimport {getParamValue, getTensor} from './utils';\n\nexport const executeOp: InternalOpAsyncExecutor = async(\n    node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext): Promise<tfc.Tensor[]> => {\n  switch (node.op) {\n    case 'If':\n    case 'StatelessIf': {\n      const thenFunc =\n          getParamValue('thenBranch', node, tensorMap, context) as string;\n      const elseFunc =\n          getParamValue('elseBranch', node, tensorMap, context) as string;\n      const cond =\n          getParamValue('cond', node, tensorMap, context) as tfc.Tensor;\n      const args =\n          getParamValue('args', node, tensorMap, context) as tfc.Tensor[];\n      const condValue = await cond.data();\n      if (condValue[0]) {\n        return context.functionMap[thenFunc].executeFunctionAsync(\n            args, context.tensorArrayMap, context.tensorListMap);\n      } else {\n        return context.functionMap[elseFunc].executeFunctionAsync(\n            args, context.tensorArrayMap, context.tensorListMap);\n      }\n    }\n    case 'While':\n    case 'StatelessWhile': {\n      const bodyFunc =\n          getParamValue('body', node, tensorMap, context) as string;\n      const condFunc =\n          getParamValue('cond', node, tensorMap, context) as string;\n      const args =\n          getParamValue('args', node, tensorMap, context) as tfc.Tensor[];\n\n      // Calculate the condition of the loop\n      const condResult =\n          (await context.functionMap[condFunc].executeFunctionAsync(\n              args, context.tensorArrayMap, context.tensorListMap));\n      const argIds = args.map(tensor => tensor.id);\n      let condValue = await condResult[0].data();\n      // Dispose the intermediate tensors for condition function\n      condResult.forEach(tensor => {\n        if (!tensor.kept && argIds.indexOf(tensor.id) === -1) {\n          tensor.dispose();\n        }\n      });\n\n      let result: tfc.Tensor[] = args;\n\n      while (condValue[0]) {\n        // Record the previous result for intermediate tensor tracking\n        const origResult = result;\n        // Execution the body of the loop\n        result = await context.functionMap[bodyFunc].executeFunctionAsync(\n            result, context.tensorArrayMap, context.tensorListMap);\n        const resultIds = result.map(tensor => tensor.id);\n\n        // Dispose the intermediate tensor for body function that is not global\n        // kept, not input/output of the body function\n        origResult.forEach(tensor => {\n          if (!tensor.kept && argIds.indexOf(tensor.id) === -1 &&\n              resultIds.indexOf(tensor.id) === -1) {\n            tensor.dispose();\n          }\n        });\n\n        // Recalcuate the condition of the loop using the latest results.\n        const condResult =\n            (await context.functionMap[condFunc].executeFunctionAsync(\n                result, context.tensorArrayMap, context.tensorListMap));\n        condValue = await condResult[0].data();\n        // Dispose the intermediate tensors for condition function\n        condResult.forEach(tensor => {\n          if (!tensor.kept && argIds.indexOf(tensor.id) === -1 &&\n              resultIds.indexOf(tensor.id) === -1) {\n            tensor.dispose();\n          }\n        });\n      }\n      return result;\n    }\n    case 'LoopCond': {\n      return [\n        (getParamValue('pred', node, tensorMap, context) as tfc.Tensor).clone()\n      ];\n    }\n    case 'Switch': {\n      const pred =\n          getParamValue('pred', node, tensorMap, context) as tfc.Tensor;\n      const data =\n          getParamValue('data', node, tensorMap, context) as tfc.Tensor;\n      // Outputs nodes :0 => false, :1 => true\n      return (await pred.data())[0] ? [undefined, data.clone()] :\n                                      [data.clone(), undefined];\n    }\n    case 'Merge': {\n      const inputName = node.inputNames.find(\n          name => getTensor(name, tensorMap, context) !== undefined);\n      return inputName ? [getTensor(inputName, tensorMap, context).clone()] :\n                         undefined;\n    }\n    case 'Enter': {\n      const frameId =\n          getParamValue('frameName', node, tensorMap, context) as string;\n      const data =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      context.enterFrame(frameId);\n      return [data.clone()];\n    }\n    case 'Exit': {\n      const tensor =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      context.exitFrame();\n      return [tensor.clone()];\n    }\n    case 'NextIteration': {\n      const input =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      context.nextIteration();\n      return [input.clone()];\n    }\n    case 'TensorArrayV3': {\n      const size = getParamValue('size', node, tensorMap, context) as number;\n      const dtype =\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const dynamicSize =\n          getParamValue('dynamicSize', node, tensorMap, context) as boolean;\n      const clearAfterRead =\n          getParamValue('clearAfterRead', node, tensorMap, context) as boolean;\n      const identicalElementShapes =\n          getParamValue('identicalElementShapes', node, tensorMap, context) as\n          boolean;\n      const name = getParamValue('name', node, tensorMap, context) as string;\n      const tensorArray = new TensorArray(\n          name, dtype, size, elementShape, identicalElementShapes, dynamicSize,\n          clearAfterRead);\n      context.addTensorArray(tensorArray);\n      return [tensorArray.idTensor, scalar(1.0)];\n    }\n    case 'TensorArrayWriteV3': {\n      const id = getParamValue('tensorArrayId', node, tensorMap, context) as\n          tfc.Tensor;\n      const index = getParamValue('index', node, tensorMap, context) as number;\n      const writeTensor =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      const writeTensorArray = context.getTensorArray(id.id);\n      writeTensorArray.write(index, writeTensor);\n      return [writeTensorArray.idTensor];\n    }\n    case 'TensorArrayReadV3': {\n      const readId = getParamValue('tensorArrayId', node, tensorMap, context) as\n          tfc.Tensor;\n      const readIndex =\n          getParamValue('index', node, tensorMap, context) as number;\n      const readTensorArray = context.getTensorArray(readId.id);\n      return [readTensorArray.read(readIndex)];\n    }\n    case 'TensorArrayGatherV3': {\n      const gatherId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as\n          tfc.Tensor;\n      const gatherIndices =\n          getParamValue('indices', node, tensorMap, context) as number[];\n      const gatherDtype =\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType;\n      const gatherTensorArray = context.getTensorArray(gatherId.id);\n      return [gatherTensorArray.gather(gatherIndices, gatherDtype)];\n    }\n    case 'TensorArrayScatterV3': {\n      const scatterId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as\n          tfc.Tensor;\n      const scatterIndices =\n          getParamValue('indices', node, tensorMap, context) as number[];\n      const scatterTensor =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      const scatterTensorArray = context.getTensorArray(scatterId.id);\n      scatterTensorArray.scatter(scatterIndices, scatterTensor);\n      return [scatterTensorArray.idTensor];\n    }\n    case 'TensorArrayConcatV3': {\n      const concatId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as\n          tfc.Tensor;\n      const concatTensorArray = context.getTensorArray(concatId.id);\n      const concatDtype =\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType;\n      return [concatTensorArray.concat(concatDtype)];\n    }\n    case 'TensorArraySplitV3': {\n      const splitId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as\n          tfc.Tensor;\n      const splitTensor =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      const lengths =\n          getParamValue('lengths', node, tensorMap, context) as number[];\n      const splitTensorArray = context.getTensorArray(splitId.id);\n      splitTensorArray.split(lengths, splitTensor);\n      return [splitTensorArray.idTensor];\n    }\n    case 'TensorArraySizeV3': {\n      const sizeId = getParamValue('tensorArrayId', node, tensorMap, context) as\n          tfc.Tensor;\n      const sizeTensorArray = context.getTensorArray(sizeId.id);\n      return [scalar(sizeTensorArray.size(), 'int32')];\n    }\n    case 'TensorArrayCloseV3': {\n      const closeId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as\n          tfc.Tensor;\n      const closeTensorArray = context.getTensorArray(closeId.id);\n      closeTensorArray.clearAndClose();\n      return [closeTensorArray.idTensor];\n    }\n    case 'TensorListSetItem': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as tfc.Tensor;\n      const index = getParamValue('index', node, tensorMap, context) as number;\n      const writeTensor =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      const tensorList = context.getTensorList(idTensor.id);\n      tensorList.setItem(index, writeTensor);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListGetItem': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as tfc.Tensor;\n      const readIndex =\n          getParamValue('index', node, tensorMap, context) as number;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n\n      const elementDType =\n          getParamValue('elementDType', node, tensorMap, context) as\n          tfc.DataType;\n      const tensorList = context.getTensorList(idTensor.id);\n      return [tensorList.getItem(readIndex, elementShape, elementDType)];\n    }\n    case 'TensorListScatterV2':\n    case 'TensorListScatter': {\n      const scatterIndices =\n          getParamValue('indices', node, tensorMap, context) as number[];\n      const scatterTensor =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const numElements =\n          getParamValue('numElements', node, tensorMap, context) as number;\n      const tensorList =\n          scatter(scatterTensor, scatterIndices, elementShape, numElements);\n      context.addTensorList(tensorList);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListReserve': {\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const elementDtype =\n          getParamValue('elementDType', node, tensorMap, context) as\n          tfc.DataType;\n      const numElements =\n          getParamValue('numElements', node, tensorMap, context) as number;\n      const tensorList = reserve(elementShape, elementDtype, numElements);\n      context.addTensorList(tensorList);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListGather': {\n      const gatherId =\n          getParamValue('tensorListId', node, tensorMap, context) as tfc.Tensor;\n      const gatherIndices =\n          getParamValue('indices', node, tensorMap, context) as number[];\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const elementDtype =\n          getParamValue('elementDType', node, tensorMap, context) as\n          tfc.DataType;\n      const tensorList = context.getTensorList(gatherId.id);\n      return [tensorList.gather(gatherIndices, elementDtype, elementShape)];\n    }\n    case 'TensorListStack': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as tfc.Tensor;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const elementDtype =\n          getParamValue('elementDType', node, tensorMap, context) as\n          tfc.DataType;\n      const numElements =\n          getParamValue('numElements', node, tensorMap, context) as number;\n      const tensorList = context.getTensorList(idTensor.id);\n      return [tensorList.stack(elementShape, elementDtype, numElements)];\n    }\n    case 'TensorListFromTensor': {\n      const tensor =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const elementDtype =\n          getParamValue('elementDType', node, tensorMap, context) as\n          tfc.DataType;\n      const tensorList = fromTensor(tensor, elementShape, elementDtype);\n      context.addTensorList(tensorList);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListConcat': {\n      const concatId =\n          getParamValue('tensorListId', node, tensorMap, context) as tfc.Tensor;\n      const tensorList = context.getTensorList(concatId.id);\n      const concatDtype =\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      return [tensorList.concat(concatDtype, elementShape)];\n    }\n    case 'TensorListPushBack': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as tfc.Tensor;\n      const writeTensor =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      const tensorList = context.getTensorList(idTensor.id);\n      tensorList.pushBack(writeTensor);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListPopBack': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as tfc.Tensor;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const elementDType =\n          getParamValue('elementDType', node, tensorMap, context) as\n          tfc.DataType;\n      const tensorList = context.getTensorList(idTensor.id);\n      return [tensorList.popBack(elementShape, elementDType)];\n    }\n    case 'TensorListSplit': {\n      const splitTensor =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const lengths =\n          getParamValue('lengths', node, tensorMap, context) as number[];\n\n      const tensorList = split(splitTensor, lengths, elementShape);\n      context.addTensorList(tensorList);\n      return [tensorList.idTensor];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'control';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../data/types';\nimport {ExecutionContext} from '../executor/execution_context';\n\nimport {NodeValueImpl} from './custom_op/node_value_impl';\nimport {getRegisteredOp} from './custom_op/register';\nimport * as arithmetic from './executors/arithmetic_executor';\nimport * as basicMath from './executors/basic_math_executor';\nimport * as control from './executors/control_executor';\nimport * as convolution from './executors/convolution_executor';\nimport * as creation from './executors/creation_executor';\nimport * as dynamic from './executors/dynamic_executor';\nimport * as evaluation from './executors/evaluation_executor';\nimport * as graph from './executors/graph_executor';\nimport * as image from './executors/image_executor';\nimport * as logical from './executors/logical_executor';\nimport * as matrices from './executors/matrices_executor';\nimport * as normalization from './executors/normalization_executor';\nimport * as reduction from './executors/reduction_executor';\nimport * as sliceJoin from './executors/slice_join_executor';\nimport * as spectral from './executors/spectral_executor';\nimport * as transformation from './executors/transformation_executor';\nimport {Node} from './types';\n\n/**\n * Executes the op defined by the node object.\n * @param node\n * @param tensorMap contains tensors for executed nodes and weights\n */\nexport function executeOp(\n    node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext): tfc.Tensor[]|Promise<tfc.Tensor[]> {\n  const value =\n      ((node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext) => {\n        switch (node.category) {\n          case 'arithmetic':\n            return tfc.tidy(\n                () => arithmetic.executeOp(node, tensorMap, context));\n          case 'basic_math':\n            return tfc.tidy(\n                () => basicMath.executeOp(node, tensorMap, context));\n          case 'control':\n            return control.executeOp(node, tensorMap, context);\n          case 'convolution':\n            return tfc.tidy(\n                () => convolution.executeOp(node, tensorMap, context));\n          case 'creation':\n            return tfc.tidy(() => creation.executeOp(node, tensorMap, context));\n          case 'dynamic':\n            return dynamic.executeOp(node, tensorMap, context);\n          case 'evaluation':\n            return tfc.tidy(\n                () => evaluation.executeOp(node, tensorMap, context));\n          case 'image':\n            return tfc.tidy(() => image.executeOp(node, tensorMap, context));\n          case 'graph':\n            return tfc.tidy(() => graph.executeOp(node, tensorMap, context));\n          case 'logical':\n            return tfc.tidy(() => logical.executeOp(node, tensorMap, context));\n          case 'matrices':\n            return tfc.tidy(() => matrices.executeOp(node, tensorMap, context));\n          case 'normalization':\n            return tfc.tidy(\n                () => normalization.executeOp(node, tensorMap, context));\n          case 'reduction':\n            return tfc.tidy(\n                () => reduction.executeOp(node, tensorMap, context));\n          case 'slice_join':\n            return tfc.tidy(\n                () => sliceJoin.executeOp(node, tensorMap, context));\n          case 'spectral':\n            return tfc.tidy(() => spectral.executeOp(node, tensorMap, context));\n          case 'transformation':\n            return tfc.tidy(\n                () => transformation.executeOp(node, tensorMap, context));\n          case 'custom':\n            const opMapper = getRegisteredOp(node.op);\n            if (opMapper && opMapper.customExecutor) {\n              return opMapper.customExecutor(\n                  new NodeValueImpl(node, tensorMap, context));\n            } else {\n              throw TypeError(`Custom op ${node.op} is not registered.`);\n            }\n          default:\n            throw TypeError(\n                `Unknown op '${node.op}'. File an issue at ` +\n                `https://github.com/tensorflow/tfjs/issues so we can add it` +\n                `, or register a custom execution with tf.registerOp()`);\n        }\n      })(node, tensorMap, context);\n  if (value instanceof Promise) {\n    return value.then((data) => [].concat(data));\n  }\n  return [].concat(value);\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'BiasAdd':\n    case 'AddV2':\n    case 'Add': {\n      return [tfc.add(\n          (getParamValue('a', node, tensorMap, context) as tfc.Tensor),\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'AddN': {\n      return [tfc.addN((\n          getParamValue('tensors', node, tensorMap, context) as tfc.Tensor[]))];\n    }\n    case 'FloorMod':\n    case 'Mod':\n      return [tfc.mod(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    case 'Mul':\n      return [tfc.mul(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    case 'RealDiv':\n    case 'Div': {\n      return [tfc.div(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'DivNoNan': {\n      return [tfc.divNoNan(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'FloorDiv': {\n      return [tfc.floorDiv(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Sub': {\n      return [tfc.sub(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Minimum': {\n      return [tfc.minimum(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Maximum': {\n      return [tfc.maximum(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Pow': {\n      return [tfc.pow(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'SquaredDifference': {\n      return [tfc.squaredDifference(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'arithmetic';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue, getTensor} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'Abs':\n    case 'ComplexAbs':\n      return [tfc.abs(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Acos':\n      return [tfc.acos(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Acosh':\n      return [tfc.acosh(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Asin':\n      return [tfc.asin(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Asinh':\n      return [tfc.asinh(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Atan':\n      return [tfc.atan(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Atan2':\n      return [tfc.atan2(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('y', node, tensorMap, context) as tfc.Tensor)];\n    case 'Atanh':\n      return [tfc.atanh(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Ceil':\n      return [tfc.ceil(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Complex':\n      return [tfc.complex(\n          getParamValue('real', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('imag', node, tensorMap, context) as tfc.Tensor)];\n    case 'Cos':\n      return [tfc.cos(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Cosh':\n      return [tfc.cosh(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Elu':\n      return [tfc.elu(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Erf':\n      return [tfc.erf(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Exp':\n      return [tfc.exp(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Expm1': {\n      return [tfc.expm1(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Floor':\n      return [tfc.floor(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Log':\n      return [tfc.log(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Log1p': {\n      return [tfc.log1p(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Imag':\n      return [tfc.imag(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n\n    case 'Neg':\n      return [tfc.neg(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Reciprocal': {\n      return [tfc.reciprocal(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Real':\n      return [tfc.real(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Relu':\n      return [tfc.relu(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Round': {\n      return [tfc.round(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Selu':\n      return [tfc.selu(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Sigmoid':\n      return [tfc.sigmoid(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Sin':\n      return [tfc.sin(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Sign': {\n      return [tfc.sign(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Sinh': {\n      return [tfc.sinh(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Softplus': {\n      return [tfc.softplus(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Sqrt': {\n      return [tfc.sqrt(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Square': {\n      return [tfc.square(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Tanh': {\n      return [tfc.tanh(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Tan':\n      return [tfc.tan(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Relu6':\n    case 'ClipByValue':\n      return [tfc.clipByValue(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('clipValueMin', node, tensorMap, context) as number,\n          getParamValue('clipValueMax', node, tensorMap, context) as number)];\n    case 'Rsqrt':\n      return [tfc.rsqrt(getTensor(node.inputNames[0], tensorMap, context))];\n    case 'Prod':\n      return [tfc.prod(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('axes', node, tensorMap, context) as number[])];\n    case 'LeakyRelu':\n      return [tfc.leakyRelu(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('alpha', node, tensorMap, context) as number)];\n    case 'Prelu':\n      return [tfc.prelu(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('alpha', node, tensorMap, context) as tfc.Tensor)];\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'basic_math';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getPadding, getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                              tensorMap: NamedTensorsMap,\n                                              context: ExecutionContext):\n                                                 tfc.Tensor[] => {\n  switch (node.op) {\n    case 'Conv1D': {\n      const stride =\n          getParamValue('stride', node, tensorMap, context) as number;\n      const pad = getParamValue('pad', node, tensorMap, context);\n      const dataFormat =\n          (getParamValue('dataFormat', node, tensorMap, context) as string)\n              .toUpperCase();\n      const dilation =\n          getParamValue('dilation', node, tensorMap, context) as number;\n      return [tfc.conv1d(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor3D,\n          getParamValue('filter', node, tensorMap, context) as tfc.Tensor3D,\n          stride, pad as 'valid' | 'same', dataFormat as 'NWC' | 'NCW',\n          dilation)];\n    }\n    case 'Conv2D': {\n      const stride =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const pad = getPadding(node, tensorMap, context);\n      const dataFormat =\n          (getParamValue('dataFormat', node, tensorMap, context) as string)\n              .toUpperCase();\n      const dilations =\n          getParamValue('dilations', node, tensorMap, context) as number[];\n      return [tfc.conv2d(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor3D |\n              tfc.Tensor4D,\n          getParamValue('filter', node, tensorMap, context) as tfc.Tensor4D,\n          [stride[1], stride[2]], pad as 'valid' | 'same',\n          dataFormat as 'NHWC' | 'NCHW', [dilations[1], dilations[2]])];\n    }\n    case '_FusedConv2D':\n    case 'FusedDepthwiseConv2dNative': {\n      const [extraOp, activationFunc] =\n          (getParamValue('fusedOps', node, tensorMap, context) as string[]);\n\n      const isBiasAdd = extraOp === 'biasadd';\n      const isPrelu = activationFunc === 'prelu';\n      const isBatchNorm = extraOp === 'fusedbatchnorm';\n\n      const numArgs =\n          (getParamValue('numArgs', node, tensorMap, context) as number);\n      if (isBiasAdd) {\n        if (isPrelu && numArgs !== 2) {\n          throw new Error(\n              'FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu ' +\n              'must have two extra arguments: bias and alpha.');\n        }\n        if (!isPrelu && numArgs !== 1) {\n          throw new Error(\n              'FusedConv2d and DepthwiseConv2d with BiasAdd must have ' +\n              'one extra argument: bias.');\n        }\n      }\n      if (isBatchNorm) {\n        throw new Error(\n            'FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported.');\n      }\n      const stride =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const pad = getPadding(node, tensorMap, context);\n      const dataFormat =\n          (getParamValue('dataFormat', node, tensorMap, context) as string)\n              .toUpperCase();\n      const dilations =\n          getParamValue('dilations', node, tensorMap, context) as number[];\n      const [biasArg, preluArg] =\n          getParamValue('args', node, tensorMap, context) as tfc.Tensor[];\n      const kernelMethod = node.op === '_FusedConv2D' ?\n          tfc.fused.conv2d :\n          tfc.fused.depthwiseConv2d;\n      return [kernelMethod({\n        x: getParamValue('x', node, tensorMap, context) as tfc.Tensor3D |\n            tfc.Tensor4D,\n        filter: getParamValue('filter', node, tensorMap, context) as\n            tfc.Tensor4D,\n        strides: [stride[1], stride[2]],\n        pad: pad as 'valid' | 'same',\n        dataFormat: dataFormat as 'NHWC' | 'NCHW',\n        dilations: [dilations[1], dilations[2]],\n        bias: biasArg,\n        activation: activationFunc as tfc.fused.Activation,\n        preluActivationWeights: preluArg\n      })];\n    }\n    case 'Conv2DBackpropInput':\n    case 'Conv2dTranspose': {\n      const shape = getParamValue(\n                        'outputShape', node, tensorMap,\n                        context) as [number, number, number] |\n          [number, number, number, number];\n      const stride =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const pad = getPadding(node, tensorMap, context);\n      return [tfc.conv2dTranspose(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor3D |\n              tfc.Tensor4D,\n          getParamValue('filter', node, tensorMap, context) as tfc.Tensor4D,\n          shape, [stride[1], stride[2]], pad as 'valid' | 'same')];\n    }\n    case 'DepthwiseConv2dNative':\n    case 'DepthwiseConv2d': {\n      const stride =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const pad = getPadding(node, tensorMap, context);\n      const dilations =\n          getParamValue('dilations', node, tensorMap, context) as number[];\n      const dataFormat =\n          (getParamValue('dataFormat', node, tensorMap, context) as string)\n              .toUpperCase();\n\n      return [tfc.depthwiseConv2d(\n          getParamValue('input', node, tensorMap, context) as tfc.Tensor3D |\n              tfc.Tensor4D,\n          getParamValue('filter', node, tensorMap, context) as tfc.Tensor4D,\n          [stride[1], stride[2]], pad as 'valid' | 'same',\n          dataFormat as 'NHWC' | 'NCHW', [dilations[1], dilations[2]])];\n    }\n    case 'Conv3D': {\n      const stride =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const pad = getParamValue('pad', node, tensorMap, context);\n      const dataFormat =\n          (getParamValue('dataFormat', node, tensorMap, context) as string)\n              .toUpperCase();\n      const dilations =\n          getParamValue('dilations', node, tensorMap, context) as number[];\n      return [tfc.conv3d(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor4D |\n              tfc.Tensor<tfc.Rank.R5>,\n          getParamValue('filter', node, tensorMap, context) as\n              tfc.Tensor<tfc.Rank.R5>,\n          [stride[1], stride[2], stride[3]], pad as 'valid' | 'same',\n          dataFormat as 'NDHWC' | 'NCDHW',\n          [dilations[1], dilations[2], dilations[3]])];\n    }\n    case 'AvgPool': {\n      const stride =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const pad = getParamValue('pad', node, tensorMap, context);\n      const kernelSize =\n          getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n      return [tfc.avgPool(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor3D |\n              tfc.Tensor4D,\n          [kernelSize[1], kernelSize[2]], [stride[1], stride[2]],\n          pad as 'valid' | 'same')];\n    }\n    case 'MaxPool': {\n      const stride =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const pad = getParamValue('pad', node, tensorMap, context);\n      const kernelSize =\n          getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n      return [tfc.maxPool(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor3D |\n              tfc.Tensor4D,\n          [kernelSize[1], kernelSize[2]], [stride[1], stride[2]],\n          pad as 'valid' | 'same')];\n    }\n    case 'MaxPoolWithArgmax': {\n      const stride =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const pad = getParamValue('pad', node, tensorMap, context);\n      const kernelSize =\n          getParamValue('kernelSize', node, tensorMap, context) as number[];\n      const includeBatchInIndex =\n          getParamValue('includeBatchInIndex', node, tensorMap, context) as\n          boolean;\n      const {result, indexes} = tfc.maxPoolWithArgmax(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor4D,\n          [kernelSize[1], kernelSize[2]], [stride[1], stride[2]],\n          pad as 'valid' | 'same', includeBatchInIndex);\n      return [result, indexes];\n    }\n    case 'AvgPool3D': {\n      const stride =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const pad = getParamValue('pad', node, tensorMap, context);\n      const kernelSize =\n          getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n      return [tfc.avgPool3d(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor5D,\n          [kernelSize[1], kernelSize[2], kernelSize[3]],\n          [stride[1], stride[2], stride[3]], pad as 'valid' | 'same')];\n    }\n\n    case 'MaxPool3D': {\n      const stride =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const pad = getParamValue('pad', node, tensorMap, context);\n      const kernelSize =\n          getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n      return [tfc.maxPool3d(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor5D,\n          [kernelSize[1], kernelSize[2], kernelSize[3]],\n          [stride[1], stride[2], stride[3]], pad as 'valid' | 'same')];\n    }\n\n    case 'Dilation2D': {\n      const strides =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const pad = getParamValue('pad', node, tensorMap, context);\n      const dilations =\n          getParamValue('dilations', node, tensorMap, context) as number[];\n\n      // strides: [1, stride_height, stride_width, 1].\n      const strideHeight = strides[1];\n      const strideWidth = strides[2];\n\n      // dilations: [1, dilation_height, dilation_width, 1].\n      const dilationHeight = dilations[1];\n      const dilationWidth = dilations[2];\n\n      return [tfc.dilation2d(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor3D |\n              tfc.Tensor4D,\n          getParamValue('filter', node, tensorMap, context) as tfc.Tensor3D,\n          [strideHeight, strideWidth], pad as 'valid' | 'same',\n          [dilationHeight, dilationWidth], 'NHWC' /* dataFormat */)];\n    }\n\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'convolution';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'Fill': {\n      const shape =\n          getParamValue('shape', node, tensorMap, context) as number[];\n      const dtype =\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType;\n      const value = getParamValue('value', node, tensorMap, context) as number;\n      return [tfc.fill(shape, value, dtype)];\n    }\n    case 'LinSpace': {\n      const start = getParamValue('start', node, tensorMap, context) as number;\n      const stop = getParamValue('stop', node, tensorMap, context) as number;\n      const num = getParamValue('num', node, tensorMap, context) as number;\n      return [tfc.linspace(start, stop, num)];\n    }\n    case 'Multinomial': {\n      const logits =\n          getParamValue('logits', node, tensorMap, context) as tfc.Tensor1D;\n      const numSamples =\n          getParamValue('numSamples', node, tensorMap, context) as number;\n      const seed = getParamValue('seed', node, tensorMap, context) as number;\n      return [tfc.multinomial(logits, numSamples, seed)];\n    }\n    case 'OneHot': {\n      const indices =\n          getParamValue('indices', node, tensorMap, context) as tfc.Tensor1D;\n      const depth = getParamValue('depth', node, tensorMap, context) as number;\n      const onValue =\n          getParamValue('onValue', node, tensorMap, context) as number;\n      const offValue =\n          getParamValue('offValue', node, tensorMap, context) as number;\n      return [tfc.oneHot(indices, depth, onValue, offValue)];\n    }\n    case 'Ones': {\n      return [tfc.ones(\n          getParamValue('shape', node, tensorMap, context) as number[],\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType)];\n    }\n    case 'OnesLike': {\n      return [tfc.onesLike(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'RandomUniform': {\n      return [tfc.randomUniform(\n          // tslint:disable-next-line:no-any\n          getParamValue('shape', node, tensorMap, context) as any,\n          getParamValue('minval', node, tensorMap, context) as number,\n          getParamValue('maxval', node, tensorMap, context) as number,\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType)];\n    }\n    case 'Range': {\n      const start = getParamValue('start', node, tensorMap, context) as number;\n      const stop = getParamValue('stop', node, tensorMap, context) as number;\n      const step = getParamValue('step', node, tensorMap, context) as number;\n      return [tfc.range(\n          start, stop, step,\n          getParamValue('dtype', node, tensorMap, context) as 'float32' |\n              'int32')];\n    }\n    case 'TruncatedNormal': {\n      const shape =\n          getParamValue('shape', node, tensorMap, context) as number[];\n      const mean = getParamValue('mean', node, tensorMap, context) as number;\n      const stdDev =\n          getParamValue('stdDev', node, tensorMap, context) as number;\n      const seed = getParamValue('seed', node, tensorMap, context) as number;\n      return [tfc.truncatedNormal(\n          shape, mean, stdDev,\n          getParamValue('dtype', node, tensorMap, context) as 'float32' |\n              'int32',\n          seed)];\n    }\n    case 'Zeros': {\n      return [tfc.zeros(\n          getParamValue('shape', node, tensorMap, context) as number[],\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType)];\n    }\n    case 'ZerosLike': {\n      return [tfc.zerosLike(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'creation';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpAsyncExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpAsyncExecutor = async(\n    node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext): Promise<tfc.Tensor[]> => {\n  switch (node.op) {\n    case 'NonMaxSuppressionV5':\n    case 'NonMaxSuppressionV4':\n    case 'NonMaxSuppressionV3':\n    case 'NonMaxSuppressionV2': {\n      const boxes =\n          getParamValue('boxes', node, tensorMap, context) as tfc.Tensor;\n      const scores =\n          getParamValue('scores', node, tensorMap, context) as tfc.Tensor;\n      const maxOutputSize =\n          getParamValue('maxOutputSize', node, tensorMap, context) as number;\n      const iouThreshold =\n          getParamValue('iouThreshold', node, tensorMap, context) as number;\n      const scoreThreshold =\n          getParamValue('scoreThreshold', node, tensorMap, context) as number;\n\n      if (node.op === 'NonMaxSuppressionV5') {\n        const softNmsSigma =\n            getParamValue('softNmsSigma', node, tensorMap, context) as number;\n\n        const result = await tfc.image.nonMaxSuppressionWithScoreAsync(\n            boxes as tfc.Tensor2D, scores as tfc.Tensor1D, maxOutputSize,\n            iouThreshold, scoreThreshold, softNmsSigma);\n\n        return [result.selectedIndices, result.selectedScores];\n      }\n\n      if (node.op === 'NonMaxSuppressionV4') {\n        const padToMaxOutputSize =\n            getParamValue('padToMaxOutputSize', node, tensorMap, context) as\n            boolean;\n\n        const result = await tfc.image.nonMaxSuppressionPaddedAsync(\n            boxes as tfc.Tensor2D, scores as tfc.Tensor1D, maxOutputSize,\n            iouThreshold, scoreThreshold, padToMaxOutputSize);\n\n        return [result.selectedIndices, result.validOutputs];\n      }\n\n      return [await tfc.image.nonMaxSuppressionAsync(\n          boxes as tfc.Tensor2D, scores as tfc.Tensor1D, maxOutputSize,\n          iouThreshold, scoreThreshold)];\n    }\n    case 'Where': {\n      const condition =\n          (getParamValue('condition', node, tensorMap, context) as tfc.Tensor)\n              .asType('bool');\n      const result = [await tfc.whereAsync(condition)];\n      condition.dispose();\n      return result;\n    }\n    case 'ListDiff': {\n      return tfc.setdiff1dAsync(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('y', node, tensorMap, context) as tfc.Tensor);\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'dynamic';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext): tfc.Tensor[] => {\n      switch (node.op) {\n        case 'TopKV2': {\n          const x = getParamValue('x', node, tensorMap, context) as tfc.Tensor;\n          const k = getParamValue('k', node, tensorMap, context) as number;\n          const sorted =\n              getParamValue('sorted', node, tensorMap, context) as boolean;\n          const result = tfc.topk(x, k, sorted);\n          return [result.values, result.indices];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'evaluation';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                              tensorMap: NamedTensorsMap,\n                                              context: ExecutionContext):\n                                                 tfc.Tensor[] => {\n  switch (node.op) {\n    case 'ResizeBilinear': {\n      const images =\n          getParamValue('images', node, tensorMap, context) as tfc.Tensor;\n      const size = getParamValue('size', node, tensorMap, context) as number[];\n      const alignCorners =\n          getParamValue('alignCorners', node, tensorMap, context) as boolean;\n      return [tfc.image.resizeBilinear(\n          images as tfc.Tensor3D | tfc.Tensor4D, [size[0], size[1]],\n          alignCorners)];\n    }\n    case 'ResizeNearestNeighbor': {\n      const images =\n          getParamValue('images', node, tensorMap, context) as tfc.Tensor;\n      const size = getParamValue('size', node, tensorMap, context) as number[];\n      const alignCorners =\n          getParamValue('alignCorners', node, tensorMap, context) as boolean;\n      return [tfc.image.resizeNearestNeighbor(\n          images as tfc.Tensor3D | tfc.Tensor4D, [size[0], size[1]],\n          alignCorners)];\n    }\n    case 'CropAndResize': {\n      const image =\n          getParamValue('image', node, tensorMap, context) as tfc.Tensor;\n      const boxes =\n          getParamValue('boxes', node, tensorMap, context) as tfc.Tensor;\n      const boxInd =\n          getParamValue('boxInd', node, tensorMap, context) as tfc.Tensor;\n      const cropSize =\n          getParamValue('cropSize', node, tensorMap, context) as number[];\n      const method =\n          getParamValue('method', node, tensorMap, context) as string;\n      const extrapolationValue =\n          getParamValue('extrapolationValue', node, tensorMap, context) as\n          number;\n      return [tfc.image.cropAndResize(\n          image as tfc.Tensor4D, boxes as tfc.Tensor2D, boxInd as tfc.Tensor1D,\n          cropSize as [number, number], method as 'bilinear' | 'nearest',\n          extrapolationValue)];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'image';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue, getTensor} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'Const': {\n      return tensorMap[node.name];\n    }\n    case 'PlaceholderWithDefault':\n      const def =\n          getParamValue('default', node, tensorMap, context) as tfc.Tensor;\n      return [getTensor(node.name, tensorMap, context) || def];\n    case 'Placeholder':\n      return [getTensor(node.name, tensorMap, context)];\n    case 'Identity':\n    case 'StopGradient':\n    case 'FakeQuantWithMinMaxVars':  // This op is currently ignored.\n      return [\n        (getParamValue('x', node, tensorMap, context) as tfc.Tensor).clone()\n      ];\n    case 'IdentityN':\n      return (getParamValue('x', node, tensorMap, context) as tfc.Tensor[])\n          .map((t: tfc.Tensor) => t.clone());\n    case 'Snapshot':\n      const snapshot =\n          (getParamValue('x', node, tensorMap, context) as tfc.Tensor);\n      return [snapshot.clone()];\n    case 'Shape':\n      return [tfc.tensor1d(\n          (getParamValue('x', node, tensorMap, context) as tfc.Tensor).shape,\n          'int32')];\n    case 'ShapeN':\n      return (getParamValue('x', node, tensorMap, context) as tfc.Tensor[])\n          .map((t: tfc.Tensor) => tfc.tensor1d(t.shape));\n    case 'Size':\n      return [tfc.scalar(\n          (getParamValue('x', node, tensorMap, context) as tfc.Tensor).size,\n          'int32')];\n    case 'Rank':\n      return [tfc.scalar(\n          (getParamValue('x', node, tensorMap, context) as tfc.Tensor).rank,\n          'int32')];\n    case 'NoOp':\n      return [tfc.scalar(1)];\n    case 'Print':\n      const input = getParamValue('x', node, tensorMap, context) as tfc.Tensor;\n      const data =\n          getParamValue('data', node, tensorMap, context) as tfc.Tensor[];\n      const message =\n          getParamValue('message', node, tensorMap, context) as string;\n      const summarize =\n          getParamValue('summarize', node, tensorMap, context) as number;\n      console.warn(\n          'The graph has a tf.print() operation,' +\n          'usually used for debugging, which slows down performance.');\n      console.log(message);\n      for (let i = 0; i < data.length; i++) {\n        console.log(\n            Array.prototype.slice.call(data[i].dataSync()).slice(0, summarize));\n      }\n      return [input];\n\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'graph';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                              tensorMap: NamedTensorsMap,\n                                              context: ExecutionContext):\n                                                 tfc.Tensor[] => {\n  switch (node.op) {\n    case 'Equal': {\n      return [tfc.equal(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'NotEqual': {\n      return [tfc.notEqual(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Greater': {\n      return [tfc.greater(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'GreaterEqual': {\n      return [tfc.greaterEqual(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Less': {\n      return [tfc.less(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'LessEqual': {\n      return [tfc.lessEqual(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'LogicalAnd': {\n      return [tfc.logicalAnd(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'LogicalNot': {\n      return [tfc.logicalNot(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'LogicalOr': {\n      return [tfc.logicalOr(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Select':\n    case 'SelectV2': {\n      return [tfc.where(\n          getParamValue('condition', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'logical';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'BatchMatMul':\n    case 'BatchMatMulV2':\n    case 'MatMul':\n      return [tfc.matMul(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor2D,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor2D,\n          getParamValue('transposeA', node, tensorMap, context) as boolean,\n          getParamValue('transposeB', node, tensorMap, context) as boolean)];\n\n    case 'Transpose':\n      return [tfc.transpose(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('perm', node, tensorMap, context) as number[])];\n\n    case '_FusedMatMul':\n      const [extraOp, activationFunc] =\n          (getParamValue('fusedOps', node, tensorMap, context) as string[]);\n\n      const isBiasAdd = extraOp === 'biasadd';\n      const isPrelu = activationFunc === 'prelu';\n\n      const numArgs =\n          (getParamValue('numArgs', node, tensorMap, context) as number);\n      if (isBiasAdd) {\n        if (isPrelu && numArgs !== 2) {\n          throw new Error(\n              'Fused MatMul with BiasAdd and Prelu must have two ' +\n              'extra arguments: bias and alpha.');\n        }\n        if (!isPrelu && numArgs !== 1) {\n          throw new Error(\n              'Fused MatMul with BiasAdd must have one extra argument: bias.');\n        }\n      }\n      const [biasArg, preluArg] =\n          getParamValue('args', node, tensorMap, context) as tfc.Tensor[];\n      return [tfc.fused.matMul({\n        a: getParamValue('a', node, tensorMap, context) as tfc.Tensor2D,\n        b: getParamValue('b', node, tensorMap, context) as tfc.Tensor2D,\n        transposeA: getParamValue('transposeA', node, tensorMap, context) as\n            boolean,\n        transposeB: getParamValue('transposeB', node, tensorMap, context) as\n            boolean,\n        bias: biasArg,\n        activation: activationFunc as tfc.fused.Activation,\n        preluActivationWeights: preluArg\n      })];\n\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'matrices';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'FusedBatchNorm':\n    case 'FusedBatchNormV2': {\n      return [tfc.batchNorm(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('mean', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('variance', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('offset', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('scale', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('epsilon', node, tensorMap, context) as number)];\n    }\n    case 'FusedBatchNormV3': {\n      return [tfc.batchNorm(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('mean', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('variance', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('offset', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('scale', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('epsilon', node, tensorMap, context) as number)];\n    }\n    case 'LRN': {\n      return [tfc.localResponseNormalization(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor3D |\n              tfc.Tensor4D,\n          getParamValue('radius', node, tensorMap, context) as number,\n          getParamValue('bias', node, tensorMap, context) as number,\n          getParamValue('alpha', node, tensorMap, context) as number,\n          getParamValue('beta', node, tensorMap, context) as number)];\n    }\n    case 'Softmax': {\n      return [tfc.softmax(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'LogSoftmax': {\n      return [tfc.logSoftmax(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'SparseToDense': {\n      return [tfc.sparseToDense(\n          getParamValue('sparseIndices', node, tensorMap, context) as\n              tfc.Tensor,\n          getParamValue('outputShape', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('sparseValues', node, tensorMap, context) as number[],\n          getParamValue('defaultValue', node, tensorMap, context) as\n              tfc.Scalar)];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'normalization';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                              tensorMap: NamedTensorsMap,\n                                              context: ExecutionContext):\n                                                 tfc.Tensor[] => {\n  switch (node.op) {\n    case 'Max': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const keepDims =\n          getParamValue('keepDims', node, tensorMap, context) as boolean;\n      return [tfc.max(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          keepDims)];\n    }\n    case 'Mean': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const keepDims =\n          getParamValue('keepDims', node, tensorMap, context) as boolean;\n      return [tfc.mean(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          keepDims)];\n    }\n    case 'Min': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const keepDims =\n          getParamValue('keepDims', node, tensorMap, context) as boolean;\n      return [tfc.min(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          keepDims)];\n    }\n    case 'Sum': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const keepDims =\n          getParamValue('keepDims', node, tensorMap, context) as boolean;\n      return [tfc.sum(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          keepDims)];\n    }\n    case 'All': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const keepDims =\n          getParamValue('keepDims', node, tensorMap, context) as boolean;\n      return [tfc.all(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          keepDims)];\n    }\n    case 'Any': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const keepDims =\n          getParamValue('keepDims', node, tensorMap, context) as boolean;\n      return [tfc.any(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          keepDims)];\n    }\n    case 'ArgMax': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number;\n      return [tfc.argMax(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis)];\n    }\n    case 'ArgMin': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number;\n      return [tfc.argMin(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis)];\n    }\n    case 'Prod': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const keepDims =\n          getParamValue('keepDims', node, tensorMap, context) as boolean;\n      return [tfc.prod(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          keepDims)];\n    }\n    case 'Cumsum': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number;\n      const exclusive =\n          getParamValue('exclusive', node, tensorMap, context) as boolean;\n      const reverse =\n          getParamValue('reverse', node, tensorMap, context) as boolean;\n      return [tfc.cumsum(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          exclusive, reverse)];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'reduction';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                              tensorMap: NamedTensorsMap,\n                                              context: ExecutionContext):\n                                                 tfc.Tensor[] => {\n  switch (node.op) {\n    case 'ConcatV2':\n    case 'Concat': {\n      const n = getParamValue('n', node, tensorMap, context) as number;\n      const axis = getParamValue('axis', node, tensorMap, context) as number;\n      let inputs =\n          getParamValue('tensors', node, tensorMap, context) as tfc.Tensor[];\n      inputs = inputs.slice(0, n);\n      return [tfc.concat(inputs, axis)];\n    }\n    case 'GatherV2':\n    case 'Gather': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number;\n      const input = getParamValue('x', node, tensorMap, context) as tfc.Tensor;\n      const indices =\n          getParamValue('indices', node, tensorMap, context) as tfc.Tensor1D;\n      return [tfc.gather(input, indices.asType('int32'), axis)];\n    }\n    case 'ReverseV2':\n    case 'Reverse': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const input = getParamValue('x', node, tensorMap, context) as tfc.Tensor;\n      return [tfc.reverse(input, axis)];\n    }\n    case 'Slice': {\n      // tslint:disable-next-line:no-any\n      const begin = getParamValue('begin', node, tensorMap, context) as any;\n      // tslint:disable-next-line:no-any\n      const size = getParamValue('size', node, tensorMap, context) as any;\n      return [tfc.slice(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, begin,\n          size)];\n    }\n    case 'StridedSlice': {\n      const begin =\n          getParamValue('begin', node, tensorMap, context) as number[];\n      const end = getParamValue('end', node, tensorMap, context) as number[];\n      const strides =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const beginMask =\n          getParamValue('beginMask', node, tensorMap, context) as number;\n      const endMask =\n          getParamValue('endMask', node, tensorMap, context) as number;\n      const ellipsisMask =\n          getParamValue('ellipsisMask', node, tensorMap, context) as number;\n      const newAxisMask =\n          getParamValue('newAxisMask', node, tensorMap, context) as number;\n      const shrinkAxisMask =\n          getParamValue('shrinkAxisMask', node, tensorMap, context) as number;\n      const tensor = getParamValue('x', node, tensorMap, context) as tfc.Tensor;\n\n      return [tfc.stridedSlice(\n          tensor, begin, end, strides, beginMask, endMask, ellipsisMask,\n          newAxisMask, shrinkAxisMask)];\n    }\n    case 'Pack': {\n      return tfc.tidy(() => {\n        const axis = getParamValue('axis', node, tensorMap, context) as number;\n        const tensors =\n            getParamValue('tensors', node, tensorMap, context) as tfc.Tensor[];\n        // Reshape the tensors to the first tensor's shape if they don't match.\n        const shape = tensors[0].shape;\n        const squeezedShape = tensors[0].squeeze().shape;\n        const mapped = tensors.map(tensor => {\n          const sameShape = tfc.util.arraysEqual(tensor.shape, shape);\n          if (!sameShape &&\n              !tfc.util.arraysEqual(tensor.squeeze().shape, squeezedShape)) {\n            throw new Error('the input tensors shape does not match');\n          }\n          return sameShape ? tensor : tensor.reshape(shape);\n        });\n        return [tfc.stack(mapped, axis)];\n      });\n    }\n    case 'Unpack': {\n      return tfc.tidy(() => {\n        const axis = getParamValue('axis', node, tensorMap, context) as number;\n        const tensor =\n            getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n        return tfc.unstack(tensor, axis);\n      });\n    }\n    case 'Tile': {\n      const reps = getParamValue('reps', node, tensorMap, context) as number[];\n      return [tfc.tile(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, reps)];\n    }\n    case 'Split':\n    case 'SplitV': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number;\n      const numOrSizeSplits =\n          getParamValue('numOrSizeSplits', node, tensorMap, context) as number |\n          number[];\n      const tensor = getParamValue('x', node, tensorMap, context) as tfc.Tensor;\n\n      return tfc.split(tensor, numOrSizeSplits, axis);\n    }\n    case 'ScatterNd': {\n      const indices =\n          getParamValue('indices', node, tensorMap, context) as tfc.Tensor;\n      const values =\n          getParamValue('values', node, tensorMap, context) as tfc.Tensor;\n      const shape =\n          getParamValue('shape', node, tensorMap, context) as number[];\n      return [tfc.scatterND(indices, values, shape)];\n    }\n    case 'GatherNd': {\n      const x = getParamValue('x', node, tensorMap, context) as tfc.Tensor;\n      const indices =\n          getParamValue('indices', node, tensorMap, context) as tfc.Tensor;\n      return [tfc.gatherND(x, indices)];\n    }\n    case 'SparseToDense': {\n      const indices =\n          getParamValue('sparseIndices', node, tensorMap, context) as\n          tfc.Tensor;\n      const shape =\n          getParamValue('outputShape', node, tensorMap, context) as number[];\n      const sparseValues =\n          getParamValue('sparseValues', node, tensorMap, context) as tfc.Tensor;\n      const defaultValue =\n          getParamValue('defaultValue', node, tensorMap, context) as tfc.Scalar;\n      return [tfc.sparseToDense(\n          indices, sparseValues, shape,\n          sparseValues.dtype === defaultValue.dtype ?\n              defaultValue :\n              defaultValue.asType(sparseValues.dtype))];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'slice_join';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext): tfc.Tensor[] => {\n      switch (node.op) {\n        case 'FFT': {\n          return [tfc.fft(\n              getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n        }\n        case 'IFFT': {\n          return [tfc.ifft(\n              getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n        }\n        case 'RFFT': {\n          return [tfc.rfft(\n              getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n        }\n        case 'IRFFT': {\n          return [tfc.irfft(\n              getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'spectral';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                              tensorMap: NamedTensorsMap,\n                                              context: ExecutionContext):\n                                                 tfc.Tensor[] => {\n  switch (node.op) {\n    case 'Cast': {\n      return [tfc.cast(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('dtype', node, tensorMap, context) as 'int32' |\n              'float32' | 'bool')];\n    }\n    case 'ExpandDims': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number;\n      return [tfc.expandDims(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis)];\n    }\n    case 'Squeeze': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      return [tfc.squeeze(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis)];\n    }\n\n    case 'Reshape': {\n      return [tfc.reshape(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('shape', node, tensorMap, context) as number[])];\n    }\n    case 'PadV2':\n    case 'Pad': {\n      return [tfc.pad(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('padding', node, tensorMap, context) as\n              Array<[number, number]>,\n          getParamValue('constantValue', node, tensorMap, context) as number)];\n    }\n    case 'SpaceToBatchND': {\n      const blockShape =\n          getParamValue('blockShape', node, tensorMap, context) as number[];\n      const paddings =\n          getParamValue('paddings', node, tensorMap, context) as number[][];\n      return [tfc.spaceToBatchND(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          blockShape, paddings)];\n    }\n    case 'BatchToSpaceND': {\n      const blockShape =\n          getParamValue('blockShape', node, tensorMap, context) as number[];\n      const crops =\n          getParamValue('crops', node, tensorMap, context) as number[][];\n      return [tfc.batchToSpaceND(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          blockShape, crops)];\n    }\n    case 'DepthToSpace': {\n      const blockSize =\n          getParamValue('blockSize', node, tensorMap, context) as number;\n      const dataFormat =\n          (getParamValue('dataFormat', node, tensorMap, context) as\n           string).toUpperCase() as 'NHWC' |\n          'NCHW';\n      return [tfc.depthToSpace(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor4D,\n          blockSize, dataFormat)];\n    }\n    case 'BroadcastTo': {\n      return [tfc.broadcastTo(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('shape', node, tensorMap, context) as number[])];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'transformation';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap, TensorArrayMap, TensorListMap} from '../data/types';\n\nimport {TensorArray} from './tensor_array';\nimport {TensorList} from './tensor_list';\nimport {FunctionExecutor} from './types';\n\nexport interface ExecutionContextInfo {\n  id: number;           // the unique id of the context info\n  frameName: string;    // The frame name of the loop, this comes from\n                        // the TensorFlow NodeDef.\n  iterationId: number;  // The iteration id of the loop\n}\n\n/**\n * ExecutionContext captures the runtime environment of the node. It keeps\n * track of the current frame and iteration for the control flow ops.\n *\n * For example, typical Dynamic RNN model may contain loops, for which\n * TensorFlow will generate graphs with Enter/Exit nodes to control the\n * current execution frame, and NextIteration Nodes for iteration id increment.\n * For model with branch logic, TensorFLow will generate Switch/Merge ops.\n */\nexport class ExecutionContext {\n  private rootContext = {id: 0, frameName: '', iterationId: 0};\n  private contexts: ExecutionContextInfo[] = [this.rootContext];\n  private lastId = 0;\n  private _currentContextIds: string[];\n\n  constructor(\n      readonly weightMap: NamedTensorsMap = {},\n      readonly tensorArrayMap: TensorArrayMap = {},\n      readonly tensorListMap: TensorListMap = {},\n      readonly functionMap: {[key: string]: FunctionExecutor} = {}) {\n    this.generateCurrentContextIds();\n  }\n\n  private newFrame(id: number, frameName: string) {\n    return {id, frameName, iterationId: 0};\n  }\n\n  /**\n   * Set the current context\n   * @param contexts: ExecutionContextInfo[] the current path of execution\n   * frames\n   */\n  set currentContext(contexts: ExecutionContextInfo[]) {\n    if (this.contexts !== contexts) {\n      this.contexts = contexts;\n      this.generateCurrentContextIds();\n    }\n  }\n\n  get currentContext(): ExecutionContextInfo[] {\n    return this.contexts;\n  }\n\n  /**\n   * Returns the current context in string format.\n   */\n  get currentContextId(): string {\n    return this._currentContextIds[0];\n  }\n\n  /**\n   * Returns the current context and all parent contexts in string format.\n   * This allow access to the nodes in the current and parent frames.\n   */\n  get currentContextIds(): string[] {\n    return this._currentContextIds;\n  }\n\n  private generateCurrentContextIds() {\n    const names = [];\n    for (let i = 0; i < this.contexts.length - 1; i++) {\n      const contexts = this.contexts.slice(0, this.contexts.length - i);\n      names.push(this.contextIdforContexts(contexts));\n    }\n    names.push('');\n    this._currentContextIds = names;\n  }\n\n  private contextIdforContexts(contexts: ExecutionContextInfo[]) {\n    return contexts ?\n        contexts\n            .map(\n                context => (context.id === 0 && context.iterationId === 0) ?\n                    '' :\n                    `${context.frameName}-${context.iterationId}`)\n            .join('/') :\n        '';\n  }\n\n  /**\n   * Enter a new frame, a new context is pushed on the current context list.\n   * @param frameId new frame id\n   */\n  enterFrame(frameId: string) {\n    if (this.contexts) {\n      this.lastId++;\n      this.contexts = this.contexts.slice();\n      this.contexts.push(this.newFrame(this.lastId, frameId));\n      this._currentContextIds.unshift(this.contextIdforContexts(this.contexts));\n    }\n  }\n\n  /**\n   * Exit the current frame, the last context is removed from the current\n   * context list.\n   */\n  exitFrame() {\n    if (this.contexts && this.contexts.length > 1) {\n      this.contexts = this.contexts.slice();\n      this.contexts.splice(-1);\n      this.currentContextIds.shift();\n    } else {\n      throw new Error('Cannot exit frame, the context is empty');\n    }\n  }\n\n  /**\n   * Enter the next iteration of a loop, the iteration id of last context is\n   * increased.\n   */\n  nextIteration() {\n    if (this.contexts && this.contexts.length > 0) {\n      this.contexts = this.contexts.slice();\n      this.lastId++;\n      const context =\n          Object.assign({}, this.contexts[this.contexts.length - 1]);\n      context.iterationId += 1;\n      context.id = this.lastId;\n      this.contexts.splice(-1, 1, context);\n      this._currentContextIds.splice(\n          0, 1, this.contextIdforContexts(this.contexts));\n    } else {\n      throw new Error('Cannot increase frame iteration, the context is empty');\n    }\n  }\n\n  getWeight(name: string): Tensor[] {\n    return this.weightMap[name];\n  }\n\n  addTensorArray(tensorArray: TensorArray) {\n    this.tensorArrayMap[tensorArray.id] = tensorArray;\n  }\n\n  getTensorArray(id: number): TensorArray {\n    return this.tensorArrayMap[id];\n  }\n\n  addTensorList(tensorList: TensorList) {\n    this.tensorListMap[tensorList.id] = tensorList;\n  }\n\n  getTensorList(id: number): TensorList {\n    return this.tensorListMap[id];\n  }\n\n  dispose() {\n    for (const key in this.tensorArrayMap) {\n      this.tensorArrayMap[key].clearAndClose();\n    }\n\n    for (const key in this.tensorListMap) {\n      this.tensorListMap[key].clearAndClose();\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NamedTensorMap} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../data/types';\nimport {parseNodeName} from '../operations/executors/utils';\nimport {Graph, Node} from '../operations/types';\n\nexport interface ExecutionInfo {\n  inputs: NamedTensorMap;\n  outputs: Node[];\n  usedNodes: Set<string>;\n  missingInputs: string[];\n  dynamicNode: Node;\n  syncInputs: string[];\n}\n\n/**\n * Given graph inputs and desired outputs, find the minimal set of nodes\n * to execute in order to compute the outputs. In addition return other useful\n * info such:\n * - Missing inputs needed to compute the output.\n * - Whether the subgraph contains dynamic ops (control flow, dynamic shape).\n * - Alternative inputs in order to avoid async (dynamic op) execution.\n */\nexport function getExecutionSubgraph(\n    inputs: NamedTensorMap, outputs: Node[],\n    weightMap: NamedTensorsMap): ExecutionInfo {\n  const usedNodes = new Set<string>();\n  const missingInputs: string[] = [];\n  let dynamicNode: Node = null;\n  let syncInputs: string[] = null;\n\n  // Start with the outputs, going backwards and find all the nodes that are\n  // needed to compute those outputs.\n  const seen = new Set<string>();\n  const inputNodeNames =\n      Object.keys(inputs).map(name => parseNodeName(name)[0]);\n  const frontier = [...outputs];\n  while (frontier.length > 0) {\n    const node = frontier.pop();\n    if (isControlFlow(node) || isDynamicShape(node)) {\n      if (dynamicNode == null) {\n        dynamicNode = node;\n        syncInputs = dynamicNode.children.map(child => child.name)\n                         .filter(name => usedNodes.has(name));\n      }\n    }\n    usedNodes.add(node.name);\n\n    // Weights are dead end since we already have their values.\n    if (weightMap[node.name] != null) {\n      continue;\n    }\n    // This node is a dead end since it's one of the user-provided inputs.\n\n    if (inputNodeNames.indexOf(node.name) !== -1) {\n      continue;\n    }\n    if (node.inputs.length === 0) {\n      missingInputs.push(node.name);\n      continue;\n    }\n    node.inputs.forEach(input => {\n      // Don't add to the frontier if it is already there.\n      if (seen.has(input.name)) {\n        return;\n      }\n      seen.add(input.name);\n      frontier.push(input);\n    });\n  }\n  return {inputs, outputs, usedNodes, missingInputs, dynamicNode, syncInputs};\n}\n\n/**\n * Given the execution info, return a list of nodes in topological order that\n * need to be executed to compute the output.\n */\nexport function getNodesInTopologicalOrder(\n    graph: Graph, weightMap: NamedTensorsMap,\n    executionInfo: ExecutionInfo): Node[] {\n  const {usedNodes, inputs} = executionInfo;\n  const frontier: Node[] = [];\n  const inputNodes = Object.keys(inputs)\n                         .map(name => parseNodeName(name)[0])\n                         .map(name => graph.nodes[name]);\n  inputNodes.forEach(input => {\n    if (usedNodes.has(input.name)) {\n      frontier.push(input);\n    }\n  });\n  graph.weights.forEach(weight => {\n    if (usedNodes.has(weight.name)) {\n      frontier.push(weight);\n    }\n  });\n  const seen = new Set<string>();\n  const orderedNodes: Node[] = [];\n  while (frontier.length > 0) {\n    const node = frontier.pop();\n    seen.add(node.name);\n    if (!weightMap[node.name]) {\n      orderedNodes.push(node);\n    }\n    node.children.forEach(child => {\n      if (!seen.has(child.name) && usedNodes.has(child.name) &&\n          child.inputs.every(input => seen.has(input.name))) {\n        frontier.push(child);\n      }\n    });\n  }\n  return orderedNodes;\n}\n\nconst CONTROL_FLOW_OPS = [\n  'Switch', 'Merge', 'Enter', 'Exit', 'NextIteration', 'StatelessIf',\n  'StatelessWhile', 'if', 'While'\n];\nconst DYNAMIC_SHAPE_OPS = [\n  'NonMaxSuppressionV2', 'NonMaxSuppressionV3', 'NonMaxSuppressionV5', 'Where'\n];\n\nexport function isControlFlow(node: Node) {\n  return CONTROL_FLOW_OPS.indexOf(node.op) >= 0;\n}\n\nexport function isDynamicShape(node: Node) {\n  return DYNAMIC_SHAPE_OPS.indexOf(node.op) >= 0;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NamedTensorMap, Tensor, tidy, util} from '@tensorflow/tfjs-core';\n\nimport {ISignatureDef} from '../data/compiled_api';\nimport {NamedTensorsMap, TensorArrayMap, TensorInfo, TensorListMap} from '../data/types';\nimport {getNodeNameAndIndex, getParamValue, getTensor, getTensorsForCurrentContenxt, parseNodeName} from '../operations/executors/utils';\nimport {executeOp} from '../operations/operation_executor';\nimport {Graph, Node} from '../operations/types';\n\nimport {ExecutionContext, ExecutionContextInfo} from './execution_context';\nimport {getExecutionSubgraph, getNodesInTopologicalOrder, isControlFlow} from './model_analysis';\nimport {FunctionExecutor} from './types';\n\ninterface NodeWithContexts {\n  contexts: ExecutionContextInfo[];\n  node: Node;\n}\n\nexport class GraphExecutor implements FunctionExecutor {\n  private compiledMap: Map<string, Node[]> = new Map();\n  private _weightMap: NamedTensorsMap = {};\n  private _weightIds: number[];\n  private _signature: ISignatureDef;\n  private _inputs: Node[];\n  private _outputs: Node[];\n  private SEPERATOR = ',';\n  private _functions: {[key: string]: Graph} = {};\n  private _functionExecutorMap: {[key: string]: FunctionExecutor} = {};\n\n  get weightIds(): number[] {\n    return this.parent ? this.parent.weightIds : this._weightIds;\n  }\n\n  get functionExecutorMap(): {[key: string]: FunctionExecutor} {\n    return this.parent ? this.parent.functionExecutorMap :\n                         this._functionExecutorMap;\n  }\n\n  get weightMap(): NamedTensorsMap {\n    return this.parent ? this.parent.weightMap : this._weightMap;\n  }\n\n  set weightMap(weightMap: NamedTensorsMap) {\n    const weightIds = Object.keys(weightMap).map(\n        key => weightMap[key].map(tensor => tensor.id));\n    this._weightIds = [].concat(...weightIds);\n    this._weightMap = weightMap;\n  }\n\n  get inputs(): TensorInfo[] {\n    return this._inputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ?\n            node.attrParams['shape'].value as number[] :\n            undefined,\n        dtype: node.attrParams['dtype'] ?\n            node.attrParams['dtype'].value as DataType :\n            undefined\n      };\n    });\n  }\n\n  get outputs(): TensorInfo[] {\n    return this._outputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ?\n            node.attrParams['shape'].value as number[] :\n            undefined,\n        dtype: node.attrParams['dtype'] ?\n            node.attrParams['dtype'].value as DataType :\n            undefined\n      };\n    });\n  }\n\n  get inputNodes(): string[] {\n    return this._inputs.map(node => node.signatureKey || node.name);\n  }\n\n  get outputNodes(): string[] {\n    return this._outputs.map((node) => {\n      const name = node.signatureKey || node.name;\n      return node.defaultOutput ? (`${name}:${node.defaultOutput}`) : name;\n    });\n  }\n\n  get functions(): {[key: string]: ISignatureDef} {\n    return Object.keys(this._functions).reduce((map, key) => {\n      map[key] = this._functions[key].signature;\n      return map;\n    }, {} as {[key: string]: ISignatureDef});\n  }\n\n  /**\n   *\n   * @param graph Graph the model or function graph to be executed.\n   * @param parent When building function exector you need to set the parent\n   * executor. Since the weights and function executor maps are set at parant\n   * level, that function executor can access the function maps and weight maps\n   * through the parent.\n   */\n  constructor(private graph: Graph, private parent?: GraphExecutor) {\n    this._outputs = graph.outputs;\n    this._inputs = graph.inputs;\n    this._signature = graph.signature;\n    this._functions = graph.functions;\n    // create sub-graph executors\n    if (graph.functions != null) {\n      Object.keys(graph.functions).forEach(name => {\n        this._functionExecutorMap[name] =\n            new GraphExecutor(graph.functions[name], this);\n      });\n    }\n  }\n\n  private getCompilationKey(inputs: Node[], outputs: Node[]): string {\n    const sortedInputs = inputs.map(node => node.name).sort();\n    const sortedOutputs = outputs.map(node => node.name).sort();\n    return sortedInputs.join(this.SEPERATOR) + '--' +\n        sortedOutputs.join(this.SEPERATOR);\n  }\n\n  /**\n   * Compiles the inference graph and returns the minimal set of nodes that are\n   * required for execution, in the correct execution order.\n   */\n  private compile(inputs: NamedTensorMap, outputs: Node[]): Node[] {\n    const executionInfo = getExecutionSubgraph(inputs, outputs, this.weightMap);\n    const {missingInputs, dynamicNode, syncInputs} = executionInfo;\n    if (dynamicNode != null) {\n      throw new Error(\n          `This execution contains the node '${dynamicNode.name}', which has ` +\n          `the dynamic op '${dynamicNode.op}'. Please use ` +\n          `model.executeAsync() instead. Alternatively, to avoid the ` +\n          `dynamic ops, specify the inputs [${syncInputs}]`);\n    }\n\n    if (missingInputs.length > 0) {\n      const outNames = outputs.map(n => n.name);\n      const inNames = Object.keys(inputs);\n      throw new Error(\n          `Cannot compute the outputs [${outNames}] from the provided inputs ` +\n          `[${inNames}]. Missing the following inputs: [${missingInputs}]`);\n    }\n\n    return getNodesInTopologicalOrder(\n        this.graph, this.weightMap, executionInfo);\n  }\n\n  /**\n   * Executes the inference for given input tensors.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   */\n  execute(inputs: NamedTensorMap, outputs: string[]): Tensor[] {\n    inputs = this.mapInputs(inputs);\n    const names = Object.keys(inputs).sort();\n    this.checkInputs(inputs);\n    this.checkInputShapeAndType(inputs);\n    outputs = this.mapOutputs(outputs);\n    this.checkOutputs(outputs);\n    const inputNodes =\n        names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodes =\n        outputs.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const compilationKey = this.getCompilationKey(inputNodes, outputNodes);\n    // Do nothing if the compiled graph cache contains the input.\n    let orderedNodes = this.compiledMap.get(compilationKey);\n    if (orderedNodes == null) {\n      orderedNodes = this.compile(inputs, outputNodes);\n      this.compiledMap.set(compilationKey, orderedNodes);\n    }\n    const tensorArrayMap: TensorArrayMap = {};\n    const tensorListMap: TensorListMap = {};\n    return tidy(() => {\n      const context = new ExecutionContext(\n          this.weightMap, tensorArrayMap, tensorListMap,\n          this.functionExecutorMap);\n      const tensorsMap: NamedTensorsMap = {...this.weightMap};\n      Object.keys(inputs).forEach(name => {\n        const [nodeName, index] = parseNodeName(name);\n        const tensors: Tensor[] = [];\n        tensors[index] = inputs[name];\n        tensorsMap[nodeName] = tensors;\n      });\n      const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n      const intermediateTensorConsumerCount: {[key: number]: number} = {};\n      for (let i = 0; i < orderedNodes.length; i++) {\n        const node = orderedNodes[i];\n        if (!tensorsMap[node.name]) {\n          const tensors = executeOp(node, tensorsMap, context) as Tensor[];\n          if (tensors instanceof Promise) {\n            throw new Error(\n                `The execution of the op '${node.op}' returned a promise. ` +\n                `Please use model.executeAsync() instead.`);\n          }\n          tensorsMap[node.name] = tensors;\n          this.checkTensorForDisposal(\n              node.name, node, tensorsMap, context, tensorsToKeep, outputs,\n              intermediateTensorConsumerCount);\n        }\n      }\n      // dispose the context for the root executor\n      if (this.parent == null) {\n        context.dispose();\n      }\n      return outputs.map(name => getTensor(name, tensorsMap, context));\n    });\n  }\n\n  private getFrozenTensorIds(tensorMap: NamedTensorsMap): Set<number> {\n    const ids = [].concat.apply(\n        [],\n        Object.keys(tensorMap)\n            .map(key => tensorMap[key])\n            .map(tensors => tensors.map(tensor => tensor.id)));\n    return new Set(ids);\n  }\n  private checkTensorForDisposal(\n      nodeName: string, node: Node, tensorMap: NamedTensorsMap,\n      context: ExecutionContext, tensorsToKeep: Set<number>,\n      outputNames: string[],\n      intermediateTensorConsumerCount: {[key: string]: number}) {\n    // Skip output nodes and any control flow nodes, since its dependency is\n    // tricky to track correctly.\n    if (node.category === 'control' || outputNames.indexOf(nodeName) !== -1) {\n      return;\n    }\n\n    tensorMap[nodeName].forEach(tensor => {\n      if (tensor != null) {\n        intermediateTensorConsumerCount[tensor.id] =\n            (intermediateTensorConsumerCount[tensor.id] || 0) +\n            node.children.length;\n      }\n    });\n    node.inputs.forEach(input => {\n      // Skip any control flow nodes, since its dependency is tricky to track\n      // correctly.\n      if (input.category !== 'control') {\n        const tensors =\n            getTensorsForCurrentContenxt(input.name, tensorMap, context);\n        if (tensors != null) {\n          tensors.forEach(tensor => {\n            if (tensor && !tensorsToKeep.has(tensor.id)) {\n              const count = intermediateTensorConsumerCount[tensor.id];\n              if (count === 1) {\n                tensor.dispose();\n                delete intermediateTensorConsumerCount[tensor.id];\n              } else if (count != null) {\n                // only intermediate nodes has count set, inputs and weights are\n                // not.\n                intermediateTensorConsumerCount[tensor.id]--;\n              }\n            }\n          });\n        }\n      }\n    });\n  }\n\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   */\n  async executeAsync(inputs: NamedTensorMap, outputs: string[]):\n      Promise<Tensor[]> {\n    return this._executeAsync(inputs, outputs);\n  }\n\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   * @param isFunctionExecution Flag for executing a function.\n   * @param tensorArrayMap Optional, global TensorArray map by id. Used for\n   * function execution.\n   * @param tensorArrayMap Optinal global TensorList map by id. Used for\n   * function execution.\n   */\n  private async _executeAsync(\n      inputs: NamedTensorMap, outputs: string[], isFunctionExecution = false,\n      tensorArrayMap: TensorArrayMap = {},\n      tensorListMap: TensorListMap = {}): Promise<Tensor[]> {\n    if (!isFunctionExecution) {\n      inputs = this.mapInputs(inputs);\n      this.checkInputs(inputs);\n      this.checkInputShapeAndType(inputs);\n      outputs = this.mapOutputs(outputs);\n      this.checkOutputs(outputs);\n    }\n\n    const context = new ExecutionContext(\n        this.weightMap, tensorArrayMap, tensorListMap,\n        this.functionExecutorMap);\n\n    // Graph with control flow op requires runtime evaluation of the execution\n    // order, while without control flow the execution order is pre-determined\n    // in the compile method.\n    const tensorMap = await this.executeWithControlFlow(\n        inputs, context, outputs, isFunctionExecution);\n    const results = outputs.map(name => getTensor(name, tensorMap, context));\n\n    // dispose all the intermediate tensors\n    const outputIds = new Set<number>(results.map(t => t.id));\n    const inputIds =\n        new Set<number>(Object.keys(inputs).map(name => inputs[name].id));\n    Object.keys(tensorMap).forEach(key => {\n      const tensorArray = tensorMap[key];\n      tensorArray.forEach(tensor => {\n        if (tensor && !tensor.isDisposed && !outputIds.has(tensor.id) &&\n            !inputIds.has(tensor.id) &&\n            this.weightIds.indexOf(tensor.id) === -1) {\n          tensor.dispose();\n        }\n      });\n    });\n    // dispose the context for the root executor\n    if (this.parent == null) {\n      context.dispose();\n    }\n\n    return results;\n  }\n\n  async executeFunctionAsync(\n      inputs: Tensor[], tensorArrayMap: TensorArrayMap,\n      tensorListMap: TensorListMap): Promise<Tensor[]> {\n    const mappedInputs = inputs.reduce((map, tensor, index) => {\n      map[this.inputs[index].name] = tensor;\n      return map;\n    }, {} as NamedTensorMap);\n\n    return this._executeAsync(\n        mappedInputs, this.outputNodes, true, tensorArrayMap, tensorListMap);\n  }\n  /**\n   * When there are control flow nodes in the graph, the graph execution use\n   * ExecutionContext to keep track of the frames and loop iterators.\n   * @param inputs placeholder tensors for the graph.\n   * @param context the execution context object for current execution.\n   * @param isFunctionExecution Flag for executing a function.\n   */\n  private async executeWithControlFlow(\n      inputs: NamedTensorMap, context: ExecutionContext, outputNames: string[],\n      isFunctionExecution: boolean): Promise<NamedTensorsMap> {\n    const names = Object.keys(inputs);\n    const inputNodes =\n        names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodes =\n        outputNames.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const {usedNodes, missingInputs, dynamicNode, syncInputs} =\n        getExecutionSubgraph(inputs, outputNodes, this.weightMap);\n\n    const stack: NodeWithContexts[] =\n        [...inputNodes, ...this.graph.weights].map(node => {\n          return {node, contexts: context.currentContext};\n        });\n    const tensorsMap: NamedTensorsMap = {...this.weightMap};\n    Object.keys(inputs).forEach(name => {\n      const [nodeName, index] = parseNodeName(name);\n      const tensors: Tensor[] = [];\n      tensors[index] = inputs[name];\n      tensorsMap[nodeName] = tensors;\n    });\n    const intermediateTensorConsumerCount: {[key: number]: number} = {};\n    const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n    const added: {[key: string]: boolean} = {};\n    while (stack.length > 0) {\n      const promises = this.processStack(\n          inputNodes, stack, context, tensorsMap, added, tensorsToKeep,\n          outputNames, intermediateTensorConsumerCount, usedNodes);\n      await Promise.all(promises);\n    }\n    if (dynamicNode == null && !isFunctionExecution) {\n      console.warn(\n          `This model execution did not contain any nodes with control flow ` +\n          `or dynamic output shapes. You can use model.execute() instead.`);\n    }\n    const missingOutputs =\n        outputNodes\n            .filter(\n                node => !isControlFlow(node) &&\n                    !getTensor(node.name, tensorsMap, context))\n            .map(node => node.name);\n    if (missingOutputs.length > 0) {\n      let alternativeMsg = '';\n      if (dynamicNode != null) {\n        alternativeMsg =\n            `Alternatively, to avoid the dynamic ops, use model.execute() ` +\n            `and specify the inputs [${syncInputs}]`;\n      }\n      throw new Error(\n          `Cannot compute the outputs [${missingOutputs}] from the provided ` +\n          `inputs [${names}]. Consider providing the following inputs: ` +\n          `[${missingInputs}]. ${alternativeMsg}`);\n    }\n    return tensorsMap;\n  }\n\n  private processStack(\n      inputNodes: Node[], stack: NodeWithContexts[], context: ExecutionContext,\n      tensorMap: NamedTensorsMap, added: {[key: string]: boolean},\n      tensorsToKeep: Set<number>, outputNames: string[],\n      intermediateTensorConsumerCount: {[key: number]: number},\n      usedNodes: Set<string>) {\n    const promises: Array<Promise<Tensor[]>> = [];\n    while (stack.length > 0) {\n      const item = stack.pop();\n      context.currentContext = item.contexts;\n      let nodeName = '';\n      // The tensor of the Enter op with isConstant set should be set\n      // in the parent scope, so it will be available as constant for the\n      // whole loop.\n      if (item.node.op === 'Enter' &&\n          getParamValue('isConstant', item.node, tensorMap, context)) {\n        [nodeName] = getNodeNameAndIndex(item.node.name, context);\n      }\n\n      // only process nodes that are not provided as input nodes.\n      if (inputNodes.indexOf(item.node) === -1) {\n        const tensors = executeOp(item.node, tensorMap, context);\n        if (!nodeName) {\n          [nodeName] = getNodeNameAndIndex(item.node.name, context);\n        }\n        const currentContext = context.currentContext;\n        if (tensors instanceof Promise) {\n          promises.push(tensors.then(t => {\n            tensorMap[nodeName] = t;\n            context.currentContext = currentContext;\n            this.checkTensorForDisposal(\n                nodeName, item.node, tensorMap, context, tensorsToKeep,\n                outputNames, intermediateTensorConsumerCount);\n            this.processChildNodes(\n                item.node, stack, context, tensorMap, added, usedNodes);\n            return t;\n          }));\n        } else {\n          tensorMap[nodeName] = tensors;\n          this.checkTensorForDisposal(\n              nodeName, item.node, tensorMap, context, tensorsToKeep,\n              outputNames, intermediateTensorConsumerCount);\n          this.processChildNodes(\n              item.node, stack, context, tensorMap, added, usedNodes);\n        }\n      } else {\n        this.processChildNodes(\n            item.node, stack, context, tensorMap, added, usedNodes);\n      }\n    }\n    return promises;\n  }\n\n  private processChildNodes(\n      node: Node, stack: NodeWithContexts[], context: ExecutionContext,\n      tensorMap: NamedTensorsMap, added: {[key: string]: boolean},\n      usedNodes: Set<string>) {\n    node.children.forEach((childNode) => {\n      const [nodeName, ] = getNodeNameAndIndex(childNode.name, context);\n      if (added[nodeName] || !usedNodes.has(childNode.name)) {\n        return;\n      }\n      // Merge op can be pushed if any of its inputs has value.\n      if (childNode.op === 'Merge') {\n        if (childNode.inputNames.some(name => {\n              return !!getTensor(name, tensorMap, context);\n            })) {\n          added[nodeName] = true;\n          stack.push({contexts: context.currentContext, node: childNode});\n        }\n      } else  // Otherwise all inputs must to have value.\n          if (childNode.inputNames.every(name => {\n                return !!getTensor(name, tensorMap, context);\n              })) {\n        added[nodeName] = true;\n        stack.push({contexts: context.currentContext, node: childNode});\n      }\n    });\n  }\n\n  /**\n   * Releases the memory used by the weight tensors.\n   */\n  dispose() {\n    Object.keys(this.weightMap)\n        .forEach(\n            key => this.weightMap[key].forEach(tensor => tensor.dispose()));\n  }\n\n  private checkInputShapeAndType(inputs: NamedTensorMap) {\n    Object.keys(inputs).forEach(name => {\n      const input = inputs[name];\n      const [nodeName, ] = parseNodeName(name);\n      const node = this.graph.nodes[nodeName];\n      if (node.attrParams['shape'] && node.attrParams['shape'].value) {\n        const shape = node.attrParams['shape'].value as number[];\n        const match = shape.length === input.shape.length &&\n            input.shape.every(\n                (dim, index) => shape[index] === -1 || shape[index] === dim);\n        util.assert(\n            match,\n            () => `The shape of dict['${node.name}'] provided in ` +\n                `model.execute(dict) must be [${shape}], but was ` +\n                `[${input.shape}]`);\n      }\n      if (node.attrParams['dtype'] && node.attrParams['dtype'].value) {\n        util.assert(\n            input.dtype === node.attrParams['dtype'].value as string,\n            () => `The dtype of dict['${node.name}'] provided in ` +\n                `model.execute(dict) must be ` +\n                `${node.attrParams['dtype'].value}, but was ${input.dtype}`);\n      }\n    });\n  }\n\n  private mapInputs(inputs: NamedTensorMap) {\n    const result: NamedTensorMap = {};\n    for (const inputName in inputs) {\n      if (this._signature != null && this._signature.inputs != null &&\n          this._signature.inputs[inputName] != null) {\n        const tensor = this._signature.inputs[inputName];\n        result[tensor.name] = inputs[inputName];\n      } else {\n        result[inputName] = inputs[inputName];\n      }\n    }\n    return result;\n  }\n\n  private checkInputs(inputs: NamedTensorMap) {\n    const notInGraph = Object.keys(inputs).filter(name => {\n      const [nodeName] = parseNodeName(name);\n      return this.graph.nodes[nodeName] == null;\n    });\n    if (notInGraph.length > 0) {\n      throw new Error(\n          `The dict provided in model.execute(dict) has ` +\n          `keys: [${notInGraph}] that are not part of graph`);\n    }\n  }\n\n  private mapOutputs(outputs: string[]) {\n    return outputs.map(name => {\n      if (this._signature != null && this._signature.outputs != null &&\n          this._signature.outputs[name] != null) {\n        const tensor = this._signature.outputs[name];\n        return tensor.name;\n      }\n      return name;\n    }, {});\n  }\n  private checkOutputs(outputs: string[]): void {\n    outputs.forEach(name => {\n      const [normalizedName] = parseNodeName(name);\n      if (!this.graph.nodes[normalizedName]) {\n        throw new Error(`The output '${name}' is not found in the graph`);\n      }\n    });\n  }\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {InferenceModel, io, ModelPredictConfig, NamedTensorMap, Tensor} from '@tensorflow/tfjs-core';\n\nimport * as tensorflow from '../data/compiled_api';\nimport {NamedTensorsMap, TensorInfo} from '../data/types';\nimport {OperationMapper} from '../operations/operation_mapper';\n\nimport {GraphExecutor} from './graph_executor';\n\nexport const TFHUB_SEARCH_PARAM = '?tfjs-format=file';\nexport const DEFAULT_MODEL_NAME = 'model.json';\n/**\n * A `tf.GraphModel` is a directed, acyclic graph built from a\n * SavedModel GraphDef and allows inference execution.\n *\n * A `tf.GraphModel` can only be created by loading from a model converted from\n * a [TensorFlow SavedModel](https://www.tensorflow.org/guide/saved_model) using\n * the command line converter tool and loaded via `tf.loadGraphModel`.\n */\n/** @doc {heading: 'Models', subheading: 'Classes'} */\nexport class GraphModel implements InferenceModel {\n  private executor: GraphExecutor;\n  private version = 'n/a';\n  private handler: io.IOHandler;\n  private artifacts: io.ModelArtifacts;\n  // Returns the version information for the tensorflow model GraphDef.\n  get modelVersion(): string {\n    return this.version;\n  }\n\n  get inputNodes(): string[] {\n    return this.executor.inputNodes;\n  }\n\n  get outputNodes(): string[] {\n    return this.executor.outputNodes;\n  }\n\n  get inputs(): TensorInfo[] {\n    return this.executor.inputs;\n  }\n\n  get outputs(): TensorInfo[] {\n    return this.executor.outputs;\n  }\n\n  get weights(): NamedTensorsMap {\n    return this.executor.weightMap;\n  }\n\n  /**\n   * @param modelUrl url for the model, or an `io.IOHandler`.\n   * @param weightManifestUrl url for the weight file generated by\n   * scripts/convert.py script.\n   * @param requestOption options for Request, which allows to send credentials\n   * and custom headers.\n   * @param onProgress Optional, progress callback function, fired periodically\n   * before the load is completed.\n   */\n  constructor(\n      private modelUrl: string|io.IOHandler,\n      private loadOptions: io.LoadOptions = {}) {\n    if (loadOptions == null) {\n      this.loadOptions = {};\n    }\n  }\n\n  private findIOHandler() {\n    const path = this.modelUrl;\n    if ((path as io.IOHandler).load != null) {\n      // Path is an IO Handler.\n      this.handler = path as io.IOHandler;\n    } else if (this.loadOptions.requestInit != null) {\n      this.handler = io.browserHTTPRequest(path as string, this.loadOptions);\n    } else {\n      const handlers = io.getLoadHandlers(path as string, this.loadOptions);\n      if (handlers.length === 0) {\n        // For backward compatibility: if no load handler can be found,\n        // assume it is a relative http path.\n        handlers.push(io.browserHTTPRequest(path as string, this.loadOptions));\n      } else if (handlers.length > 1) {\n        throw new Error(\n            `Found more than one (${handlers.length}) load handlers for ` +\n            `URL '${[path]}'`);\n      }\n      this.handler = handlers[0];\n    }\n  }\n\n  /**\n   * Loads the model and weight files, construct the in memory weight map and\n   * compile the inference graph.\n   */\n  async load(): Promise<boolean> {\n    this.findIOHandler();\n    if (this.handler.load == null) {\n      throw new Error(\n          'Cannot proceed with model loading because the IOHandler provided ' +\n          'does not have the `load` method implemented.');\n    }\n    const artifacts = await this.handler.load();\n\n    return this.loadSync(artifacts);\n  }\n\n  /**\n   * Synchronously construct the in memory weight map and\n   * compile the inference graph.\n   */\n  /** @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true} */\n  loadSync(artifacts:io.ModelArtifacts) {\n    this.artifacts = artifacts;\n    const graph = this.artifacts.modelTopology as tensorflow.IGraphDef;\n    let signature = {};\n    if (this.artifacts.userDefinedMetadata != null) {\n      signature =  // tslint:disable-next-line:no-any\n          (this.artifacts.userDefinedMetadata as any).signature as\n          tensorflow.ISignatureDef;\n    }\n\n    this.version = `${graph.versions.producer}.${graph.versions.minConsumer}`;\n    const weightMap =\n        io.decodeWeights(this.artifacts.weightData, this.artifacts.weightSpecs);\n    this.executor = new GraphExecutor(\n        OperationMapper.Instance.transformGraph(graph, signature));\n    this.executor.weightMap = this.convertTensorMapToTensorsMap(weightMap);\n    return true;\n  }\n\n  /**\n   * Save the configuration and/or weights of the GraphModel.\n   *\n   * An `IOHandler` is an object that has a `save` method of the proper\n   * signature defined. The `save` method manages the storing or\n   * transmission of serialized data (\"artifacts\") that represent the\n   * model's topology and weights onto or via a specific medium, such as\n   * file downloads, local storage, IndexedDB in the web browser and HTTP\n   * requests to a server. TensorFlow.js provides `IOHandler`\n   * implementations for a number of frequently used saving mediums, such as\n   * `tf.io.browserDownloads` and `tf.io.browserLocalStorage`. See `tf.io`\n   * for more details.\n   *\n   * This method also allows you to refer to certain types of `IOHandler`s\n   * as URL-like string shortcuts, such as 'localstorage://' and\n   * 'indexeddb://'.\n   *\n   * Example 1: Save `model`'s topology and weights to browser [local\n   * storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage);\n   * then load it back.\n   *\n   * ```js\n   * const modelUrl =\n   *    'https://storage.googleapis.com/tfjs-models/savedmodel/mobilenet_v2_1.0_224/model.json';\n   * const model = await tf.loadGraphModel(modelUrl);\n   * const zeros = tf.zeros([1, 224, 224, 3]);\n   * model.predict(zeros).print();\n   *\n   * const saveResults = await model.save('localstorage://my-model-1');\n   *\n   * const loadedModel = await tf.loadGraphModel('localstorage://my-model-1');\n   * console.log('Prediction from loaded model:');\n   * model.predict(zeros).print();\n   * ```\n   *\n   * @param handlerOrURL An instance of `IOHandler` or a URL-like,\n   * scheme-based string shortcut for `IOHandler`.\n   * @param config Options for saving the model.\n   * @returns A `Promise` of `SaveResult`, which summarizes the result of\n   * the saving, such as byte sizes of the saved artifacts for the model's\n   *   topology and weight values.\n   */\n  /**\n   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}\n   */\n  async save(handlerOrURL: io.IOHandler|string, config?: io.SaveConfig):\n      Promise<io.SaveResult> {\n    if (typeof handlerOrURL === 'string') {\n      const handlers = io.getSaveHandlers(handlerOrURL);\n      if (handlers.length === 0) {\n        throw new Error(\n            `Cannot find any save handlers for URL '${handlerOrURL}'`);\n      } else if (handlers.length > 1) {\n        throw new Error(\n            `Found more than one (${handlers.length}) save handlers for ` +\n            `URL '${handlerOrURL}'`);\n      }\n      handlerOrURL = handlers[0];\n    }\n    if (handlerOrURL.save == null) {\n      throw new Error(\n          'GraphModel.save() cannot proceed because the IOHandler ' +\n          'provided does not have the `save` attribute defined.');\n    }\n\n    return handlerOrURL.save(this.artifacts);\n  }\n\n  /**\n   * Execute the inference for the input tensors.\n   *\n   * @param input The input tensors, when there is single input for the model,\n   * inputs param should be a `tf.Tensor`. For models with mutliple inputs,\n   * inputs params should be in either `tf.Tensor`[] if the input order is\n   * fixed, or otherwise NamedTensorMap format.\n   *\n   * For model with multiple inputs, we recommend you use NamedTensorMap as the\n   * input type, if you use `tf.Tensor`[], the order of the array needs to\n   * follow the\n   * order of inputNodes array. @see {@link GraphModel.inputNodes}\n   *\n   * You can also feed any intermediate nodes using the NamedTensorMap as the\n   * input type. For example, given the graph\n   *    InputNode => Intermediate => OutputNode,\n   * you can execute the subgraph Intermediate => OutputNode by calling\n   *    model.execute('IntermediateNode' : tf.tensor(...));\n   *\n   * This is useful for models that uses tf.dynamic_rnn, where the intermediate\n   * state needs to be fed manually.\n   *\n   * For batch inference execution, the tensors for each input need to be\n   * concatenated together. For example with mobilenet, the required input shape\n   * is [1, 244, 244, 3], which represents the [batch, height, width, channel].\n   * If we are provide a batched data of 100 images, the input tensor should be\n   * in the shape of [100, 244, 244, 3].\n   *\n   * @param config Prediction configuration for specifying the batch size and\n   * output node names. Currently the batch size option is ignored for graph\n   * model.\n   *\n   * @returns Inference result tensors. The output would be single `tf.Tensor`\n   * if model has single output node, otherwise Tensor[] or NamedTensorMap[]\n   * will be returned for model with multiple outputs.\n   */\n  /** @doc {heading: 'Models', subheading: 'Classes'} */\n  predict(inputs: Tensor|Tensor[]|NamedTensorMap, config?: ModelPredictConfig):\n      Tensor|Tensor[]|NamedTensorMap {\n    return this.execute(inputs, this.outputNodes);\n  }\n\n  private normalizeInputs(inputs: Tensor|Tensor[]|\n                          NamedTensorMap): NamedTensorMap {\n    if (!(inputs instanceof Tensor) && !Array.isArray(inputs)) {\n      // The input is already a NamedTensorMap.\n      return inputs;\n    }\n    inputs = Array.isArray(inputs) ? inputs : [inputs];\n    if (inputs.length !== this.inputNodes.length) {\n      throw new Error(\n          'Input tensor count mismatch,' +\n          `the graph model has ${this.inputNodes.length} placeholders, ` +\n          `while there are ${inputs.length} input tensors.`);\n    }\n    return this.inputNodes.reduce((map, inputName, i) => {\n      map[inputName] = (inputs as Tensor[])[i];\n      return map;\n    }, {} as NamedTensorMap);\n  }\n\n  private normalizeOutputs(outputs: string|string[]): string[] {\n    outputs = outputs || this.outputNodes;\n    return !Array.isArray(outputs) ? [outputs] : outputs;\n  }\n\n  /**\n   * Executes inference for the model for given input tensors.\n   * @param inputs tensor, tensor array or tensor map of the inputs for the\n   * model, keyed by the input node names.\n   * @param outputs output node name from the Tensorflow model, if no\n   * outputs are specified, the default outputs of the model would be used.\n   * You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   *\n   * @returns A single tensor if provided with a single output or no outputs\n   * are provided and there is only one default output, otherwise return a\n   * tensor array. The order of the tensor array is the same as the outputs\n   * if provided, otherwise the order of outputNodes attribute of the model.\n   */\n  /** @doc {heading: 'Models', subheading: 'Classes'} */\n  execute(inputs: Tensor|Tensor[]|NamedTensorMap, outputs?: string|string[]):\n      Tensor|Tensor[] {\n    inputs = this.normalizeInputs(inputs);\n    outputs = this.normalizeOutputs(outputs);\n    const result = this.executor.execute(inputs, outputs);\n    return result.length > 1 ? result : result[0];\n  }\n  /**\n   * Executes inference for the model for given input tensors in async\n   * fashion, use this method when your model contains control flow ops.\n   * @param inputs tensor, tensor array or tensor map of the inputs for the\n   * model, keyed by the input node names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   *\n   * @returns A Promise of single tensor if provided with a single output or\n   * no outputs are provided and there is only one default output, otherwise\n   * return a tensor map.\n   */\n  /** @doc {heading: 'Models', subheading: 'Classes'} */\n  async executeAsync(\n      inputs: Tensor|Tensor[]|NamedTensorMap,\n      outputs?: string|string[]): Promise<Tensor|Tensor[]> {\n    inputs = this.normalizeInputs(inputs);\n    outputs = this.normalizeOutputs(outputs);\n    const result = await this.executor.executeAsync(inputs, outputs);\n    return result.length > 1 ? result : result[0];\n  }\n\n  private convertTensorMapToTensorsMap(map: NamedTensorMap): NamedTensorsMap {\n    return Object.keys(map).reduce((newMap: NamedTensorsMap, key) => {\n      newMap[key] = [map[key]];\n      return newMap;\n    }, {});\n  }\n\n  /**\n   * Releases the memory used by the weight tensors.\n   */\n  /** @doc {heading: 'Models', subheading: 'Classes'} */\n  dispose() {\n    this.executor.dispose();\n  }\n}\n\n/**\n * Load a graph model given a URL to the model definition.\n *\n * Example of loading MobileNetV2 from a URL and making a prediction with a\n * zeros input:\n *\n * ```js\n * const modelUrl =\n *    'https://storage.googleapis.com/tfjs-models/savedmodel/mobilenet_v2_1.0_224/model.json';\n * const model = await tf.loadGraphModel(modelUrl);\n * const zeros = tf.zeros([1, 224, 224, 3]);\n * model.predict(zeros).print();\n * ```\n *\n * Example of loading MobileNetV2 from a TF Hub URL and making a prediction with\n * a zeros input:\n *\n * ```js\n * const modelUrl =\n *    'https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/classification/2';\n * const model = await tf.loadGraphModel(modelUrl, {fromTFHub: true});\n * const zeros = tf.zeros([1, 224, 224, 3]);\n * model.predict(zeros).print();\n * ```\n * @param modelUrl The url or an `io.IOHandler` that loads the model.\n * @param options Options for the HTTP request, which allows to send credentials\n *    and custom headers.\n */\n/** @doc {heading: 'Models', subheading: 'Loading'} */\nexport async function loadGraphModel(\n    modelUrl: string|io.IOHandler,\n    options: io.LoadOptions = {}): Promise<GraphModel> {\n  if (modelUrl == null) {\n    throw new Error(\n        'modelUrl in loadGraphModel() cannot be null. Please provide a url ' +\n        'or an IOHandler that loads the model');\n  }\n  if (options == null) {\n    options = {};\n  }\n\n  if (options.fromTFHub) {\n    if ((modelUrl as io.IOHandler).load == null) {\n      if (!(modelUrl as string).endsWith('/')) {\n        modelUrl = (modelUrl as string) + '/';\n      }\n      modelUrl = `${modelUrl}${DEFAULT_MODEL_NAME}${TFHUB_SEARCH_PARAM}`;\n    }\n  }\n  const model = new GraphModel(modelUrl, options);\n  await model.load();\n  return model;\n}\n","/** @license See the LICENSE file. */\n\n// This code is auto-generated, do not modify this file!\nconst version = '2.1.0';\nexport {version};\n"],"names":["DataType","SaverDef","CheckpointFormatVersion","CUSTOM_OPS","getRegisteredOp","name","getParamValue","paramName","node","tensorMap","context","inputParam","inputParams","undefined","inputIndexStart","start","end","inputIndexEnd","type","getTensor","inputNames","slice","map","tensor","data","dataSync","tfc.util","toNestedArray","shape","attrParam","attrParams","value","tensorsMap","_a","nodeName","index","contextId","currentContextIds","find","getNodeNameWithContextId","getNodeNameAndIndex","inputName","currentContextId","parseNodeName","parts","split","length","Number","getPadding","pad","explicitPadding","i","tfOpName","category","inputs","attrs","tfName","notSupported","defaultValue","tfDeprecatedName","ops","arithmetic","basicMath","control","convolution","creation","dynamic","evaluation","logical","image","graph","matrices","normalization","reduction","sliceJoin","spectral","transformation","mappersJson","concat","op","json","this","opMappers","reduce","mapper","Object","OperationMapper","_instance","signature","tfNodes","placeholders","weights","nodes","_this","mapNode","startsWith","push","outputs","inputNodeNameToKey","outputNodeNameToKey","mapSignatureEntries","allNodes","keys","forEach","key","children","signatureKey","functions","library","function","func","mapFunction","entries","prev","curr","attr","newNode","input","substr","rawAttrs","param","getStringParam","getStringArrayParam","getNumberParam","getNumericArrayParam","getBoolParam","getBoolArrayParam","getTensorShapeParam","getTensorShapeArrayParam","getDtypeParam","getDtypeArrayParam","getFuncParam","Error","functionDef","nodeDef","inputArg","arg","dtype","parseDtypeParam","returnNodeMap","ret","outputArg","output","defaultOutput","mapArgsToSignature","methodName","mapArgToTensorInfo","nameMap","parseStringParam","s","keepCase","Array","isArray","String","fromCharCode","apply","text","global","env","atob","Buffer","toString","decodeBase64","toLowerCase","def","b","parseInt","tensorflow.DataType","DT_FLOAT","DT_INT32","DT_INT64","DT_INT8","DT_UINT8","DT_BOOL","DT_DOUBLE","DT_STRING","list","v","parseTensorShapeParam","unknownRank","dim","size","f","getInput","getAttr","NodeValueImpl","assertShapesMatchAllowUndefinedSize","shapeA","shapeB","errorMessagePrefix","util","assert","n1","n2","shapesEqualAllowUndefinedSize","maxSize","elementShape","identicalElementShapes","dynamicSize","clearAfterRead","idTensor","scalar","keep","TensorArray","id","closed_","tensors","dispose","tensorWithState","cleared","read","indices","t","written","write","readMany","stack","maxIndex","Math","max","writeMany","unstack","totalLength","cumulativeLengths","len","elementPerRow","tidy","reshape","indices_1","sizes","elementDtype","maxNumElements","TensorList","numElements","reshapedTensors","pop","elementIndex","executeOp","thenFunc","elseFunc","cond","args","condValue","_b","functionMap","executeFunctionAsync","tensorArrayMap","tensorListMap","bodyFunc","condFunc","condResult","argIds_1","kept","indexOf","result","origResult","resultIds","condResult_1","clone","pred","frameId","enterFrame","exitFrame","nextIteration","name_1","tensorArray","addTensorArray","writeTensor","writeTensorArray","getTensorArray","readId","readIndex","gatherId","gatherIndices","gatherDtype","gather","scatterId","scatterIndices","scatterTensor","scatterTensorArray","scatter","concatId","concatTensorArray","concatDtype","splitId","splitTensor","lengths","splitTensorArray","sizeId","sizeTensorArray","closeId","closeTensorArray","clearAndClose","tensorList","getTensorList","setItem","elementDType","getItem","addTensorList","reserve","fromTensor","pushBack","popBack","TypeError","tfc.tidy","tfc.add","tfc.addN","tfc.mod","tfc.mul","tfc.div","tfc.divNoNan","tfc.floorDiv","tfc.sub","tfc.minimum","tfc.maximum","tfc.pow","tfc.squaredDifference","arithmetic.executeOp","tfc.abs","tfc.acos","tfc.acosh","tfc.asin","tfc.asinh","tfc.atan","tfc.atan2","tfc.atanh","tfc.ceil","tfc.complex","tfc.cos","tfc.cosh","tfc.elu","tfc.erf","tfc.exp","tfc.expm1","tfc.floor","tfc.log","tfc.log1p","tfc.imag","tfc.neg","tfc.reciprocal","tfc.real","tfc.relu","tfc.round","tfc.selu","tfc.sigmoid","tfc.sin","tfc.sign","tfc.sinh","tfc.softplus","tfc.sqrt","tfc.square","tfc.tanh","tfc.tan","tfc.clipByValue","tfc.rsqrt","tfc.prod","tfc.leakyRelu","tfc.prelu","basicMath.executeOp","control.executeOp","stride","dataFormat","toUpperCase","dilation","tfc.conv1d","dilations","tfc.conv2d","extraOp","activationFunc","isBiasAdd","isPrelu","isBatchNorm","numArgs","biasArg","preluArg","tfc.fused","conv2d","depthwiseConv2d","x","filter","strides","bias","activation","preluActivationWeights","tfc.conv2dTranspose","tfc.depthwiseConv2d","tfc.conv3d","kernelSize","tfc.avgPool","tfc.maxPool","includeBatchInIndex","_c","tfc.avgPool3d","tfc.maxPool3d","strideHeight","strideWidth","dilationHeight","dilationWidth","tfc.dilation2d","convolution.executeOp","tfc.fill","stop_1","num","tfc.linspace","logits","numSamples","seed","tfc.multinomial","depth","onValue","offValue","tfc.oneHot","tfc.ones","tfc.onesLike","tfc.randomUniform","stop_2","step","tfc.range","mean","stdDev","tfc.truncatedNormal","tfc.zeros","tfc.zerosLike","creation.executeOp","boxes","scores","maxOutputSize","iouThreshold","scoreThreshold","softNmsSigma","tfc.image","nonMaxSuppressionWithScoreAsync","selectedIndices","selectedScores","padToMaxOutputSize","nonMaxSuppressionPaddedAsync","validOutputs","nonMaxSuppressionAsync","condition","asType","tfc.whereAsync","tfc.setdiff1dAsync","dynamic.executeOp","k","sorted","tfc.topk","values","evaluation.executeOp","images","alignCorners","resizeBilinear","resizeNearestNeighbor","boxInd","cropSize","method","extrapolationValue","cropAndResize","image.executeOp","tfc.tensor1d","tfc.scalar","rank","message","summarize","console","warn","log","prototype","call","graph.executeOp","tfc.equal","tfc.notEqual","tfc.greater","tfc.greaterEqual","tfc.less","tfc.lessEqual","tfc.logicalAnd","tfc.logicalNot","tfc.logicalOr","tfc.where","logical.executeOp","tfc.matMul","tfc.transpose","matMul","a","transposeA","transposeB","matrices.executeOp","tfc.batchNorm","tfc.localResponseNormalization","tfc.softmax","tfc.logSoftmax","tfc.sparseToDense","normalization.executeOp","axis","keepDims","tfc.max","tfc.mean","tfc.min","tfc.sum","tfc.all","tfc.any","tfc.argMax","tfc.argMin","exclusive","reverse","tfc.cumsum","reduction.executeOp","n","tfc.concat","tfc.gather","tfc.reverse","begin","tfc.slice","beginMask","endMask","ellipsisMask","newAxisMask","shrinkAxisMask","tfc.stridedSlice","squeezedShape","squeeze","mapped","sameShape","arraysEqual","tfc.stack","tfc.unstack","reps","tfc.tile","numOrSizeSplits","tfc.split","tfc.scatterND","tfc.gatherND","sparseValues","sliceJoin.executeOp","tfc.fft","tfc.ifft","tfc.rfft","tfc.irfft","spectral.executeOp","tfc.cast","tfc.expandDims","tfc.squeeze","tfc.reshape","tfc.pad","blockShape","paddings","tfc.spaceToBatchND","crops","tfc.batchToSpaceND","blockSize","tfc.depthToSpace","tfc.broadcastTo","transformation.executeOp","opMapper","customExecutor","Promise","then","weightMap","frameName","iterationId","rootContext","generateCurrentContextIds","ExecutionContext","contexts","_currentContextIds","names","contextIdforContexts","join","lastId","newFrame","unshift","splice","shift","assign","getExecutionSubgraph","usedNodes","Set","missingInputs","dynamicNode","syncInputs","seen","inputNodeNames","frontier","isControlFlow","isDynamicShape","child","has","add","CONTROL_FLOW_OPS","DYNAMIC_SHAPE_OPS","parent","Map","_outputs","_inputs","_signature","_functions","_functionExecutorMap","GraphExecutor","weightIds","_weightIds","functionExecutorMap","_weightMap","sortedInputs","sort","sortedOutputs","SEPERATOR","executionInfo","outNames","inNames","weight","orderedNodes","every","getNodesInTopologicalOrder","mapInputs","checkInputs","checkInputShapeAndType","mapOutputs","checkOutputs","inputNodes","outputNodes","compilationKey","getCompilationKey","compiledMap","get","compile","set","tensorsToKeep","getFrozenTensorIds","intermediateTensorConsumerCount","checkTensorForDisposal","ids","outputNames","getTensorsForCurrentContenxt","count","_executeAsync","isFunctionExecution","executeWithControlFlow","results","outputIds","inputIds","isDisposed","mappedInputs","currentContext","added","promises","processStack","all","missingOutputs","alternativeMsg","item","currentContext_1","processChildNodes","this_1","childNode","some","shape_1","match","notInGraph","normalizedName","modelUrl","loadOptions","GraphModel","version","executor","path","load","handler","requestInit","io","browserHTTPRequest","handlers","getLoadHandlers","findIOHandler","artifacts","loadSync","modelTopology","userDefinedMetadata","versions","producer","minConsumer","decodeWeights","weightData","weightSpecs","Instance","transformGraph","convertTensorMapToTensorsMap","handlerOrURL","config","getSaveHandlers","save","execute","Tensor","normalizeInputs","normalizeOutputs","executeAsync","newMap","options","fromTFHub","endsWith","model","opFunc"],"mappings":";;;;;;;;;;;;;;;;0QA8BYA,EAyRKC,q7CAzRjB,SAAYD,GACVA,+BACAA,2BACAA,6BACAA,2BACAA,2BACAA,2BACAA,yBACAA,6BACAA,mCACAA,2BACAA,0BACAA,4BACAA,8BACAA,8BACAA,kCACAA,qCACAA,uCACAA,qCACAA,qCACAA,qCACAA,mCACAA,uCACAA,6CACAA,qCACAA,mCACAA,qCACAA,uCACAA,uCACAA,2CA7BF,CAAYA,IAAAA,OAyRZ,SAAiBC,IAEf,SAAYC,GAAyBA,uBAAcA,eAAUA,eAA7D,CAAYD,4BAAAA,+BAFd,CAAiBA,IAAAA,OCnSjB,IAAME,EAAwC,YA6C9BC,EAAgBC,GAC9B,OAAOF,EAAWE,YC3CJC,EACZC,EAAmBC,EAAYC,EAC/BC,GACF,IAAMC,EAAaH,EAAKI,YAAYL,GACpC,GAAII,QAA6CE,IAA/BF,EAAWG,gBAA+B,CAC1D,IAAMC,EAAQJ,EAAWG,gBACnBE,EAAmC,IAA7BL,EAAWM,mBACnBJ,OAC8BA,IAA7BF,EAAWM,cAA8BF,EAAQ,EACRJ,EAAWM,cACzD,GAAwB,WAApBN,EAAWO,KACb,OAAOC,EACHX,EAAKY,WAAWT,EAAWG,iBAAkBL,EAAWC,GAE9D,GAAwB,YAApBC,EAAWO,KAGb,OAFeV,EAAKY,WAAWC,MAAMN,EAAOC,GAE9BM,KAAI,SAAAjB,GAAQ,OAAAc,EAAUd,EAAMI,EAAWC,MAEvD,IAAMa,EACFJ,EAAUX,EAAKY,WAAWC,MAAMN,GAAO,GAAIN,EAAWC,GACpDc,EAAOD,EAAOE,WACpB,MAA2B,WAApBd,EAAWO,KACdM,EAAK,GACLE,OAASC,cAAcJ,EAAOK,MAAOJ,GAE3C,IAAMK,EAAYrB,EAAKsB,WAAWvB,GAClC,OAAOsB,GAAaA,EAAUE,eAShBZ,EACZd,EAAc2B,EACdtB,GACI,IAAAuB,OAACC,OAAUC,OACXC,EAAY1B,EAAQ2B,kBAAkBC,MAAK,SAAAF,GAC/C,QAASJ,EAAWO,EAAyBL,EAAUE,OAGzD,YAAqBvB,IAAduB,EACHJ,EAAWO,EAAyBL,EAAUE,IAAYD,QAC1DtB,WAoBU2B,EACZC,EAAmB/B,GACf,IAAAuB,OAACC,OAAUC,OAEjB,MAAO,CACLI,EAAyBL,EAAUxB,GAAWA,EAAQgC,kBACtDP,GAIJ,SAASI,EAAyBlC,EAAc+B,GAC9C,OAASA,EAAe/B,MAAQ+B,EAAc/B,WAGhCsC,EAActC,GAC5B,IAAMuC,EAAQvC,EAAKwC,MAAM,KACzB,OAAqB,IAAjBD,EAAME,OACD,CAACzC,EAAM,GAIT,CADUuC,EAAM,GACLG,OAAOH,EAAMA,EAAME,OAAS,cAUhCE,EACZxC,EAAYC,EACZC,GACF,IAAIuC,EAAM3C,EAAc,MAAOE,EAAMC,EAAWC,GAChD,GAAY,aAARuC,EAAoB,CAEtBA,EAAM3C,EAAc,mBAAoBE,EAAMC,EAAWC,GAIzD,IAHA,IAAMwC,EAEF,CAAC,CAAC,EAAG,GAAI,CAAC,EAAG,GAAI,CAAC,EAAG,GAAI,CAAC,EAAG,IACxBC,EAAI,EAAGA,EAAI,EAAGA,IACrBD,EAAgBC,GAAG,GAAMF,EAAqB,EAAJE,GAC1CD,EAAgBC,GAAG,GAAMF,EAAqB,EAAJE,EAAQ,GAEpD,OAAOD,EAET,OAAOD,ECrHF,2BAAyB,CAC9B,CACEG,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CAAC,CAACvC,MAAS,EAAGC,IAAO,EAAGX,KAAQ,UAAWa,KAAQ,aAE/D,CACEkC,SAAY,UACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,UACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,WACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,WACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,UACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,YAGtC,CACEkC,SAAY,UACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,YAGtC,CACEkC,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,oBACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,WACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,8BClKxC,CAC9B,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,cACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,iBAAkBnD,KAAQ,eAAgBa,KAAQ,UAC7D,CAACsC,OAAU,iBAAkBnD,KAAQ,eAAgBa,KAAQ,YAGjE,CACEkC,SAAY,UACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,UACrC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,WAEvCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,aACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,GAAO,CACvED,OAAU,OACVnD,KAAQ,aACRa,KAAQ,QACRuC,cAAgB,KAItB,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,GAAO,CACvED,OAAU,OACVnD,KAAQ,aACRa,KAAQ,QACRuC,cAAgB,KAItB,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,QAASa,KAAQ,WAExCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,GAAO,CACvED,OAAU,eACVnD,KAAQ,eACRa,KAAQ,SACRwC,aAAgB,GAElB,CACEF,OAAU,eACVnD,KAAQ,eACRa,KAAQ,SACRwC,aAAgB,KAItB,CACEN,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,UACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,SACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,aACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,WACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,MACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,aAEvCqC,MAAS,CACP,CACEC,OAAU,YACVnD,KAAQ,WACRa,KAAQ,OACRuC,cAAgB,GAElB,CAACD,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,YACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CACEC,OAAU,QACVnD,KAAQ,QACRa,KAAQ,SACRwC,aAAgB,IAElB,CACEF,OAAU,IACVnD,KAAQ,QACRa,KAAQ,QACRuC,cAAgB,8BC5cQ,CAC9B,CACEL,SAAY,WACZC,SAAY,UACZC,OAAU,CAAC,CAACvC,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,YAElD,CACEkC,SAAY,SACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,UACrC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,YAGzC,CACEkC,SAAY,QACZC,SAAY,UACZC,OAAU,CAAC,CAACvC,MAAS,EAAGC,IAAO,EAAGX,KAAQ,UAAWa,KAAQ,aAE/D,CACEkC,SAAY,QACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,WAEzCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,GAClE,CAACD,OAAU,aAAcnD,KAAQ,YAAaa,KAAQ,UACtD,CAACsC,OAAU,cAAenD,KAAQ,aAAca,KAAQ,UAG5D,CACEkC,SAAY,OACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,WAEzCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,gBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,WAEzCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,gBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,WAEvCqC,MAAS,CACP,CAACC,OAAU,QAASnD,KAAQ,QAASa,KAAQ,SAC7C,CAACsC,OAAU,gBAAiBnD,KAAQ,eAAgBa,KAAQ,SAC5D,CAACsC,OAAU,eAAgBnD,KAAQ,cAAea,KAAQ,QAC1D,CAACsC,OAAU,mBAAoBnD,KAAQ,iBAAkBa,KAAQ,QACjE,CACEsC,OAAU,2BACVnD,KAAQ,yBACRa,KAAQ,QAEV,CAACsC,OAAU,oBAAqBnD,KAAQ,OAAQa,KAAQ,YAG5D,CACEkC,SAAY,qBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,gBAAiBa,KAAQ,UAC9C,CAACH,MAAS,EAAGV,KAAQ,QAASa,KAAQ,UACtC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,WAEzCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,oBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,gBAAiBa,KAAQ,UAC9C,CAACH,MAAS,EAAGV,KAAQ,QAASa,KAAQ,UACtC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,WAEzCqC,MAAS,CAAC,CACRC,OAAU,QACVnD,KAAQ,QACRa,KAAQ,QACRuC,cAAgB,KAGpB,CACEL,SAAY,sBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,gBAAiBa,KAAQ,UAC9C,CAACH,MAAS,EAAGV,KAAQ,UAAWa,KAAQ,YACxC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,WAEzCqC,MAAS,CACP,CAACC,OAAU,QAASnD,KAAQ,QAASa,KAAQ,SAC7C,CAACsC,OAAU,gBAAiBnD,KAAQ,eAAgBa,KAAQ,WAGhE,CACEkC,SAAY,uBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,gBAAiBa,KAAQ,UAC9C,CAACH,MAAS,EAAGV,KAAQ,UAAWa,KAAQ,YACxC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,WAEzCqC,MAAS,CAAC,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,WAErD,CACEkC,SAAY,sBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,gBAAiBa,KAAQ,UAC9C,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,WAEzCqC,MAAS,CACP,CAACC,OAAU,QAASnD,KAAQ,QAASa,KAAQ,SAAU,CACrDsC,OAAU,wBACVnD,KAAQ,sBACRa,KAAQ,QACRuC,cAAgB,KAItB,CACEL,SAAY,qBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,gBAAiBa,KAAQ,UAC9C,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGV,KAAQ,UAAWa,KAAQ,YACxC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,WAEzCqC,MAAS,CAAC,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,WAErD,CACEkC,SAAY,oBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,gBAAiBa,KAAQ,UAC9C,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,YAG3C,CACEkC,SAAY,qBACZC,SAAY,UACZC,OAAU,CAAC,CAACvC,MAAS,EAAGV,KAAQ,gBAAiBa,KAAQ,YAE3D,CACEkC,SAAY,cACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,UACrC,CAACH,MAAS,EAAGC,IAAO,EAAGX,KAAQ,OAAQa,KAAQ,YAEjDqC,MAAS,CACP,CAACC,OAAU,cAAenD,KAAQ,aAAca,KAAQ,QACxD,CAACsC,OAAU,cAAenD,KAAQ,aAAca,KAAQ,UAG5D,CACEkC,SAAY,KACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,UACrC,CAACH,MAAS,EAAGC,IAAO,EAAGX,KAAQ,OAAQa,KAAQ,YAEjDqC,MAAS,CACP,CAACC,OAAU,cAAenD,KAAQ,aAAca,KAAQ,QACxD,CAACsC,OAAU,cAAenD,KAAQ,aAAca,KAAQ,UAG5D,CACEkC,SAAY,iBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGC,IAAO,EAAGX,KAAQ,OAAQa,KAAQ,YAEjDqC,MAAS,CACP,CAACC,OAAU,OAAQnD,KAAQ,OAAQa,KAAQ,QAC3C,CAACsC,OAAU,OAAQnD,KAAQ,OAAQa,KAAQ,UAG/C,CACEkC,SAAY,QACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGC,IAAO,EAAGX,KAAQ,OAAQa,KAAQ,YAEjDqC,MAAS,CACP,CAACC,OAAU,OAAQnD,KAAQ,OAAQa,KAAQ,QAC3C,CAACsC,OAAU,OAAQnD,KAAQ,OAAQa,KAAQ,UAG/C,CACEkC,SAAY,oBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGV,KAAQ,UAAWa,KAAQ,YACxC,CAACH,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,UAE/CqC,MACI,CAAC,CAACC,OAAU,gBAAiBnD,KAAQ,eAAgBa,KAAQ,WAEnE,CACEkC,SAAY,sBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGV,KAAQ,UAAWa,KAAQ,YACxC,CAACH,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,SAC7C,CAACH,MAAS,EAAGV,KAAQ,cAAea,KAAQ,WAE9CqC,MACI,CAAC,CAACC,OAAU,gBAAiBnD,KAAQ,eAAgBa,KAAQ,WAEnE,CACEkC,SAAY,mBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,UAC7C,CAACH,MAAS,EAAGV,KAAQ,UAAWa,KAAQ,YACxC,CAACH,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,UAE/CqC,MACI,CAAC,CAACC,OAAU,gBAAiBnD,KAAQ,eAAgBa,KAAQ,WAEnE,CACEkC,SAAY,oBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,UAC7C,CAACH,MAAS,EAAGV,KAAQ,QAASa,KAAQ,UACtC,CAACH,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,UAE/CqC,MACI,CAAC,CAACC,OAAU,gBAAiBnD,KAAQ,eAAgBa,KAAQ,WAEnE,CACEkC,SAAY,oBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,UAC7C,CAACH,MAAS,EAAGV,KAAQ,QAASa,KAAQ,UACtC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,WAEzCqC,MACI,CAAC,CAACC,OAAU,gBAAiBnD,KAAQ,eAAgBa,KAAQ,WAEnE,CACEkC,SAAY,oBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,SAC7C,CAACH,MAAS,EAAGV,KAAQ,cAAea,KAAQ,WAE9CqC,MACI,CAAC,CAACC,OAAU,gBAAiBnD,KAAQ,eAAgBa,KAAQ,WAEnE,CACEkC,SAAY,uBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,UAE/CqC,MACI,CAAC,CAACC,OAAU,gBAAiBnD,KAAQ,eAAgBa,KAAQ,WAEnE,CACEkC,SAAY,kBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,UAC7C,CAACH,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,UAE/CqC,MAAS,CACP,CAACC,OAAU,gBAAiBnD,KAAQ,eAAgBa,KAAQ,SAC5D,CAACsC,OAAU,eAAgBnD,KAAQ,cAAea,KAAQ,WAG9D,CACEkC,SAAY,kBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,SAC7C,CAACH,MAAS,EAAGV,KAAQ,UAAWa,KAAQ,aAE1CqC,MACI,CAAC,CAACC,OAAU,gBAAiBnD,KAAQ,eAAgBa,KAAQ,WAEnE,CACEkC,SAAY,mBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,WAE/CqC,MAAS,CACP,CAACC,OAAU,gBAAiBnD,KAAQ,eAAgBa,KAAQ,SAC5D,CAACsC,OAAU,gBAAiBnD,KAAQ,eAAgBa,KAAQ,WAGhE,CACEkC,SAAY,oBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,UAC7C,CAACH,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,UAE/CqC,MACI,CAAC,CAACC,OAAU,gBAAiBnD,KAAQ,eAAgBa,KAAQ,WAEnE,CACEkC,SAAY,qBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,UAC7C,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,WAEzCqC,MACI,CAAC,CAACC,OAAU,gBAAiBnD,KAAQ,eAAgBa,KAAQ,oCChVrC,CAC9B,CACEkC,SAAY,UACZC,SAAY,cACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,UAAWnD,KAAQ,UAAWa,KAAQ,YACjD,CAACsC,OAAU,UAAWnD,KAAQ,MAAOa,KAAQ,UAAW,CACtDsC,OAAU,cACVnD,KAAQ,aACRa,KAAQ,SACRuC,cAAgB,GAElB,CAACD,OAAU,QAASnD,KAAQ,aAAca,KAAQ,YAClD,CAACsC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,UACZC,SAAY,cACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,UAAWnD,KAAQ,UAAWa,KAAQ,YACjD,CAACsC,OAAU,UAAWnD,KAAQ,MAAOa,KAAQ,UAAW,CACtDsC,OAAU,cACVnD,KAAQ,aACRa,KAAQ,SACRuC,cAAgB,GAElB,CAACD,OAAU,QAASnD,KAAQ,aAAca,KAAQ,YAClD,CAACsC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,oBACZC,SAAY,cACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,UAAWnD,KAAQ,UAAWa,KAAQ,YACjD,CAACsC,OAAU,UAAWnD,KAAQ,MAAOa,KAAQ,UAC7C,CAACsC,OAAU,QAASnD,KAAQ,aAAca,KAAQ,YAAa,CAC7DsC,OAAU,yBACVnD,KAAQ,sBACRa,KAAQ,QAEV,CAACsC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,YACZC,SAAY,cACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,UAAWnD,KAAQ,UAAWa,KAAQ,YACjD,CAACsC,OAAU,UAAWnD,KAAQ,MAAOa,KAAQ,UAAW,CACtDsC,OAAU,cACVnD,KAAQ,aACRa,KAAQ,SACRuC,cAAgB,GAElB,CAACD,OAAU,QAASnD,KAAQ,aAAca,KAAQ,YAClD,CAACsC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,YACZC,SAAY,cACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,UAAWnD,KAAQ,UAAWa,KAAQ,YACjD,CAACsC,OAAU,UAAWnD,KAAQ,MAAOa,KAAQ,UAAW,CACtDsC,OAAU,cACVnD,KAAQ,aACRa,KAAQ,SACRuC,cAAgB,GAElB,CAACD,OAAU,QAASnD,KAAQ,aAAca,KAAQ,YAClD,CAACsC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,SACZC,SAAY,cACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,WAEzCqC,MAAS,CACP,CAACC,OAAU,SAAUnD,KAAQ,SAAUa,KAAQ,UAC/C,CAACsC,OAAU,UAAWnD,KAAQ,MAAOa,KAAQ,UAAW,CACtDsC,OAAU,cACVnD,KAAQ,aACRa,KAAQ,SACRwC,aAAgB,OAElB,CAACF,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,GAAO,CACvED,OAAU,WACVnD,KAAQ,WACRa,KAAQ,SACRwC,aAAgB,KAItB,CACEN,SAAY,SACZC,SAAY,cACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,WAEzCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,GAClE,CAACD,OAAU,UAAWnD,KAAQ,UAAWa,KAAQ,YACjD,CAACsC,OAAU,UAAWnD,KAAQ,MAAOa,KAAQ,UAC7C,CAACsC,OAAU,gBAAiBnD,KAAQ,gBAAiBa,KAAQ,QAAS,CACpEsC,OAAU,cACVnD,KAAQ,aACRa,KAAQ,SACRwC,aAAgB,QAElB,CACEF,OAAU,oBACVnD,KAAQ,mBACRa,KAAQ,WACRwC,aAAgB,IAElB,CAACF,OAAU,YAAanD,KAAQ,YAAaa,KAAQ,cAGzD,CACEkC,SAAY,eACZC,SAAY,cACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGC,IAAK,EAAGX,KAAQ,OAAQa,KAAQ,YAE/CqC,MAAS,CACP,CAACC,OAAU,WAAYnD,KAAQ,UAAWa,KAAQ,UAClD,CAACsC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,GAClE,CAACD,OAAU,UAAWnD,KAAQ,UAAWa,KAAQ,YACjD,CAACsC,OAAU,UAAWnD,KAAQ,MAAOa,KAAQ,UAC7C,CACEsC,OAAU,oBACVnD,KAAQ,mBACRa,KAAQ,WACRwC,aAAgB,IAElB,CACEF,OAAU,mBACVnD,KAAQ,gBACRa,KAAQ,OACRwC,cAAgB,GAElB,CACEF,OAAU,cACVnD,KAAQ,aACRa,KAAQ,SACRwC,aAAgB,QAElB,CACEF,OAAU,YACVnD,KAAQ,YACRa,KAAQ,WACRwC,aAAgB,CAAC,EAAG,EAAG,EAAG,IAE5B,CACEF,OAAU,YACVnD,KAAQ,WACRa,KAAQ,WACRwC,aAAgB,IAElB,CACEF,OAAU,UACVnD,KAAQ,UACRa,KAAQ,SACRwC,aAAgB,QAItB,CACEN,SAAY,sBACZC,SAAY,cACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGV,KAAQ,cAAea,KAAQ,aAE9CqC,MAAS,CACP,CAACC,OAAU,UAAWnD,KAAQ,UAAWa,KAAQ,YACjD,CAACsC,OAAU,UAAWnD,KAAQ,MAAOa,KAAQ,UAC7C,CACEsC,OAAU,cACVnD,KAAQ,aACRa,KAAQ,SACRuC,cAAgB,GAElB,CACED,OAAU,oBACVnD,KAAQ,mBACRa,KAAQ,WACRwC,aAAgB,MAItB,CACEN,SAAY,kBACZC,SAAY,cACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,QAASa,KAAQ,UACtC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,WAEzCqC,MAAS,CACP,CAACC,OAAU,UAAWnD,KAAQ,UAAWa,KAAQ,YACjD,CAACsC,OAAU,UAAWnD,KAAQ,MAAOa,KAAQ,UAAW,CACtDsC,OAAU,cACVnD,KAAQ,aACRa,KAAQ,SACRwC,aAAgB,QAElB,CACEF,OAAU,oBACVnD,KAAQ,mBACRa,KAAQ,WACRwC,aAAgB,IAElB,CAACF,OAAU,YAAanD,KAAQ,YAAaa,KAAQ,cAGzD,CACEkC,SAAY,wBACZC,SAAY,cACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,QAASa,KAAQ,UACtC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,WAEzCqC,MAAS,CACP,CAACC,OAAU,UAAWnD,KAAQ,UAAWa,KAAQ,YACjD,CAACsC,OAAU,UAAWnD,KAAQ,MAAOa,KAAQ,UAAW,CACtDsC,OAAU,cACVnD,KAAQ,aACRa,KAAQ,SACRwC,aAAgB,QAElB,CACEF,OAAU,oBACVnD,KAAQ,mBACRa,KAAQ,WACRwC,aAAgB,IAElB,CAACF,OAAU,YAAanD,KAAQ,YAAaa,KAAQ,cAGzD,CACEkC,SAAY,6BACZC,SAAY,cACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGC,IAAK,EAAGX,KAAQ,OAAQa,KAAQ,YAE/CqC,MAAS,CACP,CAACC,OAAU,WAAYnD,KAAQ,UAAWa,KAAQ,UAClD,CAACsC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,GAClE,CAACD,OAAU,UAAWnD,KAAQ,UAAWa,KAAQ,YACjD,CAACsC,OAAU,UAAWnD,KAAQ,MAAOa,KAAQ,UAAW,CACtDsC,OAAU,cACVnD,KAAQ,aACRa,KAAQ,SACRwC,aAAgB,QAElB,CACEF,OAAU,YACVnD,KAAQ,YACRa,KAAQ,WACRwC,aAAgB,CAAC,EAAG,EAAG,EAAG,IAE5B,CACEF,OAAU,YACVnD,KAAQ,WACRa,KAAQ,WACRwC,aAAgB,MAItB,CACEN,SAAY,SACZC,SAAY,cACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,WAEzCqC,MAAS,CACP,CAACC,OAAU,UAAWnD,KAAQ,UAAWa,KAAQ,YACjD,CAACsC,OAAU,UAAWnD,KAAQ,MAAOa,KAAQ,UAAW,CACtDsC,OAAU,cACVnD,KAAQ,aACRa,KAAQ,SACRwC,aAAgB,QAElB,CAACF,OAAU,YAAanD,KAAQ,YAAaa,KAAQ,cAGzD,CACEkC,SAAY,aACZC,SAAY,cACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,WAEzCqC,MAAS,CACP,CAACC,OAAU,UAAWnD,KAAQ,UAAWa,KAAQ,YACjD,CAACsC,OAAU,QAASnD,KAAQ,YAAaa,KAAQ,YACjD,CAACsC,OAAU,UAAWnD,KAAQ,MAAOa,KAAQ,qCCnUnB,CAC9B,CACEkC,SAAY,OACZC,SAAY,WACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,QAASa,KAAQ,YACtC,CAACH,MAAS,EAAGV,KAAQ,QAASa,KAAQ,WAExCqC,MAAS,CAAC,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,WAErD,CACEkC,SAAY,WACZC,SAAY,WACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,QAASa,KAAQ,UACtC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,UACrC,CAACH,MAAS,EAAGV,KAAQ,MAAOa,KAAQ,WAEtCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,SACZC,SAAY,WACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,UAAWa,KAAQ,UACxC,CAACH,MAAS,EAAGV,KAAQ,QAASa,KAAQ,UACtC,CAACH,MAAS,EAAGV,KAAQ,UAAWa,KAAQ,SAAUwC,aAAgB,GAClE,CAAC3C,MAAS,EAAGV,KAAQ,WAAYa,KAAQ,SAAUwC,aAAgB,IAErEH,MAAS,CACP,CACEC,OAAU,OACVnD,KAAQ,OACRa,KAAQ,SACRuC,cAAgB,GAElB,CAACD,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,WACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,QAASa,KAAQ,aAExCqC,MAAS,CAAC,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,WAErD,CACEkC,SAAY,WACZC,SAAY,WACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CAAC,CAACC,OAAU,QAASnD,KAAQ,QAASa,KAAQ,WAEzD,CACEkC,SAAY,gBACZC,SAAY,WACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,QAASa,KAAQ,aAExCqC,MAAS,CACP,CACEC,OAAU,SACVnD,KAAQ,SACRa,KAAQ,SACRwC,aAAgB,GAElB,CACEF,OAAU,SACVnD,KAAQ,SACRa,KAAQ,SACRwC,aAAgB,GAElB,CAACF,OAAU,QAASnD,KAAQ,QAASa,KAAQ,SAC7C,CAACsC,OAAU,OAAQnD,KAAQ,OAAQa,KAAQ,SAAUwC,aAAgB,GAAI,CACvEF,OAAU,QACVnD,KAAQ,QACRa,KAAQ,SACRwC,aAAgB,EAChBD,cAAgB,GAElB,CAACD,OAAU,IAAKnD,KAAQ,IAAKa,KAAQ,SAAUuC,cAAgB,KAGnE,CACEL,SAAY,QACZC,SAAY,WACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,QAASa,KAAQ,UACtC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,UACrC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,SAAUwC,aAAgB,IAEjEH,MAAS,CAAC,CAACC,OAAU,OAAQnD,KAAQ,QAASa,KAAQ,WAExD,CACEkC,SAAY,kBACZC,SAAY,WACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,QAASa,KAAQ,aAExCqC,MAAS,CACP,CACEC,OAAU,QACVnD,KAAQ,OACRa,KAAQ,SACRwC,aAAgB,GAElB,CACEF,OAAU,SACVnD,KAAQ,SACRa,KAAQ,SACRwC,aAAgB,GAElB,CAACF,OAAU,OAAQnD,KAAQ,OAAQa,KAAQ,UAAW,CACpDsC,OAAU,QACVnD,KAAQ,QACRa,KAAQ,SACRwC,aAAgB,EAChBD,cAAgB,GAElB,CAACD,OAAU,QAASnD,KAAQ,QAASa,KAAQ,SAC7C,CAACsC,OAAU,IAAKnD,KAAQ,IAAKa,KAAQ,SAAUuC,cAAgB,KAGnE,CACEL,SAAY,QACZC,SAAY,WACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,QAASa,KAAQ,aAExCqC,MAAS,CAAC,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,WAErD,CACEkC,SAAY,YACZC,SAAY,WACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CAAC,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,WAErD,CACEkC,SAAY,cACZC,SAAY,WACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGV,KAAQ,aAAca,KAAQ,WAE7CqC,MAAS,CACP,CAACC,OAAU,OAAQnD,KAAQ,OAAQa,KAAQ,UAC3C,CAACsC,OAAU,QAASnD,KAAQ,QAASa,KAAQ,UAC7C,CAACsC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,SACzC,CAACsC,OAAU,eAAgBnD,KAAQ,eAAgBa,KAAQ,oCC1JjC,CAC9B,CACEkC,SAAY,sBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,QAASa,KAAQ,UACtC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGV,KAAQ,gBAAiBa,KAAQ,UAC9C,CAACH,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,YAGjD,CACEkC,SAAY,sBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,QAASa,KAAQ,UACtC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGV,KAAQ,gBAAiBa,KAAQ,UAC9C,CAACH,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,UAC7C,CAACH,MAAS,EAAGV,KAAQ,iBAAkBa,KAAQ,YAGnD,CACEkC,SAAY,sBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,QAASa,KAAQ,UACtC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGV,KAAQ,gBAAiBa,KAAQ,UAC9C,CAACH,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,UAC7C,CAACH,MAAS,EAAGV,KAAQ,iBAAkBa,KAAQ,WAEjDqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,GAAO,CACvED,OAAU,cACVnD,KAAQ,YACRa,KAAQ,QACRuC,cAAgB,GAElB,CACED,OAAU,yBACVnD,KAAQ,qBACRa,KAAQ,UAId,CACEkC,SAAY,sBACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,QAASa,KAAQ,UACtC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGV,KAAQ,gBAAiBa,KAAQ,UAC9C,CAACH,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,UAC7C,CAACH,MAAS,EAAGV,KAAQ,iBAAkBa,KAAQ,UAC/C,CAACH,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,YAGjD,CACEkC,SAAY,QACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,YAAaa,KAAQ,WAE5CqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,WACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CAAC,CACRC,OAAU,IACVnD,KAAQ,QACRa,KAAQ,QACRuC,cAAgB,8BC/EU,CAAC,CAC/BL,SAAY,SACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CAAC,CAACC,OAAU,SAAUnD,KAAQ,SAAUa,KAAQ,mCCP3B,CAC9B,CACEkC,SAAY,yBACZC,SAAY,QACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,UAAWa,KAAQ,WAE1CqC,MAAS,CACP,CAACC,OAAU,QAASnD,KAAQ,QAASa,KAAQ,SAC7C,CAACsC,OAAU,QAASnD,KAAQ,QAASa,KAAQ,WAGjD,CACEkC,SAAY,cACZC,SAAY,QACZE,MAAS,CACP,CAACC,OAAU,QAASnD,KAAQ,QAASa,KAAQ,SAC7C,CAACsC,OAAU,QAASnD,KAAQ,QAASa,KAAQ,WAGjD,CAACkC,SAAY,QAASC,SAAY,SAAU,CAC1CD,SAAY,WACZC,SAAY,QACZC,OAAU,CAAC,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,YAE/C,CACEkC,SAAY,YACZC,SAAY,QACZC,OAAU,CAAC,CAACvC,MAAS,EAAGC,IAAO,EAAGX,KAAQ,IAAKa,KAAQ,aAEzD,CACEkC,SAAY,WACZC,SAAY,QACZC,OAAU,CAAC,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,YAE/C,CACEkC,SAAY,OACZC,SAAY,QACZC,OAAU,CAAC,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,YAE/C,CACEkC,SAAY,OACZC,SAAY,QACZC,OAAU,CAAC,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,YAE/C,CACEkC,SAAY,QACZC,SAAY,QACZC,OAAU,CAAC,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,YAE/C,CACEkC,SAAY,SACZC,SAAY,QACZC,OAAU,CAAC,CAACvC,MAAS,EAAGC,IAAO,EAAGX,KAAQ,IAAKa,KAAQ,aAEzD,CACEkC,SAAY,QACZC,SAAY,QACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,YAEvCqC,MAAS,CACP,CAACC,OAAU,UAAWnD,KAAQ,UAAWa,KAAQ,UAAW,CAC1DsC,OAAU,UACVnD,KAAQ,SACRa,KAAQ,SACRuC,cAAgB,GAElB,CACED,OAAU,YACVnD,KAAQ,YACRa,KAAQ,SACRwC,aAAgB,KAItB,CAACN,SAAY,OAAQC,SAAY,QAASC,OAAU,IAAK,CACvDF,SAAY,eACZC,SAAY,QACZC,OAAU,CAAC,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,YAE/C,CACEkC,SAAY,0BACZC,SAAY,QACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,MAAOnD,KAAQ,MAAOa,KAAQ,UACzC,CAACsC,OAAU,MAAOnD,KAAQ,MAAOa,KAAQ,qCC1Ff,CAC9B,CACEkC,SAAY,iBACZC,SAAY,QACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,aAEvCqC,MAAS,CACP,CAACC,OAAU,gBAAiBnD,KAAQ,eAAgBa,KAAQ,QAC5D,CAACsC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,wBACZC,SAAY,QACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,aAEvCqC,MAAS,CACP,CAACC,OAAU,gBAAiBnD,KAAQ,eAAgBa,KAAQ,QAC5D,CAACsC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,gBACZC,SAAY,QACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,QAASa,KAAQ,UACtC,CAACH,MAAS,EAAGV,KAAQ,QAASa,KAAQ,UACtC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGV,KAAQ,WAAYa,KAAQ,aAE3CqC,MAAS,CACP,CAACC,OAAU,SAAUnD,KAAQ,SAAUa,KAAQ,UAAW,CACxDsC,OAAU,sBACVnD,KAAQ,qBACRa,KAAQ,qCCtCgB,CAC9B,CACEkC,SAAY,QACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,WACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,UACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,eACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,OACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,YACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,aACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,aACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,YACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,SACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,YAAaa,KAAQ,UAC1C,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,WACZC,SAAY,UACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,YAAaa,KAAQ,UAC1C,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CAAC,CACRC,OAAU,IACVnD,KAAQ,QACRa,KAAQ,QACRuC,cAAgB,8BC3HU,CAC9B,CACEL,SAAY,eACZC,SAAY,WACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGC,IAAK,EAAGX,KAAQ,OAAQa,KAAQ,YAE/CqC,MAAS,CACP,CAACC,OAAU,WAAYnD,KAAQ,UAAWa,KAAQ,UAAW,CAC3DsC,OAAU,YACVnD,KAAQ,WACRa,KAAQ,WACRwC,aAAgB,IAElB,CACEF,OAAU,UACVnD,KAAQ,UACRa,KAAQ,SACRwC,aAAgB,MAElB,CACEF,OAAU,cACVnD,KAAQ,aACRa,KAAQ,OACRwC,cAAgB,GAElB,CACEF,OAAU,cACVnD,KAAQ,aACRa,KAAQ,OACRwC,cAAgB,GAElB,CAACF,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,SACZC,SAAY,WACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CACEC,OAAU,cACVnD,KAAQ,aACRa,KAAQ,OACRwC,cAAgB,GAElB,CACEF,OAAU,cACVnD,KAAQ,aACRa,KAAQ,OACRwC,cAAgB,GAElB,CAACF,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,cACZC,SAAY,WACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CACEC,OAAU,QACVnD,KAAQ,aACRa,KAAQ,OACRwC,cAAgB,GAElB,CACEF,OAAU,QACVnD,KAAQ,aACRa,KAAQ,OACRwC,cAAgB,GAElB,CAACF,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,gBACZC,SAAY,WACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CACEC,OAAU,QACVnD,KAAQ,aACRa,KAAQ,OACRwC,cAAgB,GAElB,CACEF,OAAU,QACVnD,KAAQ,aACRa,KAAQ,OACRwC,cAAgB,GAElB,CAACF,OAAU,IAAKnD,KAAQ,QAASa,KAAQ,QAASuC,cAAgB,KAGtE,CACEL,SAAY,YACZC,SAAY,WACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,aAEvCqC,MAAS,CAAC,CACRC,OAAU,IACVnD,KAAQ,QACRa,KAAQ,QACRuC,cAAgB,8BCrHU,CAC9B,CACEL,SAAY,iBACZC,SAAY,gBACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,QAASa,KAAQ,UACtC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,UACrC,CAACH,MAAS,EAAGV,KAAQ,WAAYa,KAAQ,WAE3CqC,MAAS,CACP,CACEC,OAAU,UACVnD,KAAQ,UACRa,KAAQ,SACRwC,aAAgB,MAElB,CACEF,OAAU,cACVnD,KAAQ,aACRa,KAAQ,SACRuC,cAAgB,KAItB,CACEL,SAAY,mBACZC,SAAY,gBACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,QAASa,KAAQ,UACtC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,UACrC,CAACH,MAAS,EAAGV,KAAQ,WAAYa,KAAQ,WAE3CqC,MAAS,CACP,CACEC,OAAU,UACVnD,KAAQ,UACRa,KAAQ,SACRwC,aAAgB,MAElB,CACEF,OAAU,cACVnD,KAAQ,aACRa,KAAQ,SACRuC,cAAgB,KAItB,CACEL,SAAY,mBACZC,SAAY,gBACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,QAASa,KAAQ,UACtC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,UACrC,CAACH,MAAS,EAAGV,KAAQ,WAAYa,KAAQ,WAE3CqC,MAAS,CACP,CACEC,OAAU,UACVnD,KAAQ,UACRa,KAAQ,SACRwC,aAAgB,MAElB,CACEF,OAAU,cACVnD,KAAQ,aACRa,KAAQ,SACRuC,cAAgB,KAItB,CACEL,SAAY,MACZC,SAAY,gBACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CACEC,OAAU,eACVnD,KAAQ,SACRa,KAAQ,SACRwC,aAAgB,GAElB,CAACF,OAAU,OAAQnD,KAAQ,OAAQa,KAAQ,SAAUwC,aAAgB,GACrE,CACEF,OAAU,QACVnD,KAAQ,QACRa,KAAQ,SACRwC,aAAgB,GAElB,CACEF,OAAU,OACVnD,KAAQ,OACRa,KAAQ,SACRwC,aAAgB,MAItB,CACEN,SAAY,UACZC,SAAY,gBACZC,OAAU,CAAC,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,YAE/C,CACEkC,SAAY,aACZC,SAAY,gBACZC,OAAU,CAAC,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,YAE/C,CACEkC,SAAY,gBACZC,SAAY,gBACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,gBAAiBa,KAAQ,UAC9C,CAACH,MAAS,EAAGV,KAAQ,cAAea,KAAQ,YAC5C,CAACH,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,UAC7C,CAACH,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,WAE/CqC,MAAS,CAAC,CACRC,OAAU,mBACVnD,KAAQ,kBACRa,KAAQ,OACRwC,cAAgB,EAChBD,cAAgB,8BChIU,CAC9B,CACEL,SAAY,MACZC,SAAY,YACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,aAEvCqC,MAAS,CAAC,CAACC,OAAU,YAAanD,KAAQ,WAAYa,KAAQ,UAEhE,CACEkC,SAAY,OACZC,SAAY,YACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,aAEvCqC,MAAS,CAAC,CAACC,OAAU,YAAanD,KAAQ,WAAYa,KAAQ,UAEhE,CACEkC,SAAY,MACZC,SAAY,YACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,aAEvCqC,MAAS,CAAC,CAACC,OAAU,YAAanD,KAAQ,WAAYa,KAAQ,UAEhE,CACEkC,SAAY,MACZC,SAAY,YACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,aAEvCqC,MAAS,CAAC,CAACC,OAAU,YAAanD,KAAQ,WAAYa,KAAQ,UAEhE,CACEkC,SAAY,MACZC,SAAY,YACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,aAEvCqC,MAAS,CAAC,CAACC,OAAU,YAAanD,KAAQ,WAAYa,KAAQ,UAEhE,CACEkC,SAAY,MACZC,SAAY,YACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,aAEvCqC,MAAS,CAAC,CAACC,OAAU,YAAanD,KAAQ,WAAYa,KAAQ,UAEhE,CACEkC,SAAY,SACZC,SAAY,YACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,YAGzC,CACEkC,SAAY,SACZC,SAAY,YACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,YAGzC,CACEkC,SAAY,OACZC,SAAY,YACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,aAEvCqC,MAAS,CAAC,CAACC,OAAU,YAAanD,KAAQ,WAAYa,KAAQ,UAEhE,CACEkC,SAAY,SACZC,SAAY,YACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,WAEvCqC,MAAS,CACP,CAACC,OAAU,YAAanD,KAAQ,YAAaa,KAAQ,QACrD,CAACsC,OAAU,UAAWnD,KAAQ,UAAWa,KAAQ,mCCzFvB,CAC9B,CACEkC,SAAY,WACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGC,KAAQ,EAAGX,KAAQ,UAAWa,KAAQ,WACnD,CAACH,OAAU,EAAGV,KAAQ,OAAQa,KAAQ,WAExCqC,MACI,CAAC,CAACC,OAAU,IAAKnD,KAAQ,IAAKa,KAAQ,SAAUwC,aAAgB,KAEtE,CACEN,SAAY,SACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGC,IAAO,EAAGX,KAAQ,UAAWa,KAAQ,WAClD,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,WAEvCqC,MAAS,CAAC,CAACC,OAAU,IAAKnD,KAAQ,IAAKa,KAAQ,SAAUwC,aAAgB,KAG3E,CACEN,SAAY,WACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,UAAWa,KAAQ,UACxC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,SAAUwC,aAAgB,KAGnE,CACEN,SAAY,SACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,UAAWa,KAAQ,WAE1CqC,MAAS,CACP,CAACC,OAAU,OAAQnD,KAAQ,OAAQa,KAAQ,SAAUwC,aAAgB,GAAI,CACvEF,OAAU,mBACVnD,KAAQ,kBACRa,KAAQ,OACRuC,cAAgB,KAItB,CACEL,SAAY,UACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,OAAQuC,cAAgB,KAGjE,CACEL,SAAY,YACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,cAGzC,CACEkC,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,QAASa,KAAQ,YACtC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,cAGzC,CACEkC,SAAY,eACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,QAASa,KAAQ,YACtC,CAACH,MAAS,EAAGV,KAAQ,MAAOa,KAAQ,YACpC,CAACH,MAAS,EAAGV,KAAQ,UAAWa,KAAQ,aAE1CqC,MAAS,CACP,CACEC,OAAU,aACVnD,KAAQ,YACRa,KAAQ,SACRwC,aAAgB,GAElB,CACEF,OAAU,WACVnD,KAAQ,UACRa,KAAQ,SACRwC,aAAgB,GAElB,CACEF,OAAU,gBACVnD,KAAQ,cACRa,KAAQ,SACRwC,aAAgB,GAElB,CACEF,OAAU,gBACVnD,KAAQ,eACRa,KAAQ,SACRwC,aAAgB,GAElB,CACEF,OAAU,mBACVnD,KAAQ,iBACRa,KAAQ,SACRwC,aAAgB,KAItB,CACEN,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGC,IAAO,EAAGX,KAAQ,UAAWa,KAAQ,YAEpDqC,MAAS,CACP,CAACC,OAAU,OAAQnD,KAAQ,OAAQa,KAAQ,SAAUwC,aAAgB,KAGzE,CACEN,SAAY,SACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,WAEzCqC,MAAS,CACP,CAACC,OAAU,OAAQnD,KAAQ,OAAQa,KAAQ,SAAUwC,aAAgB,GAAI,CACvEF,OAAU,MACVnD,KAAQ,MACRa,KAAQ,SACRwC,aAAgB,EAChBD,cAAgB,KAItB,CACEL,SAAY,OACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,cAGzC,CACEkC,SAAY,QACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,SAAUwC,aAAgB,GAC/D,CAAC3C,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CAAC,CACRC,OAAU,YACVnD,KAAQ,kBACRa,KAAQ,SACRwC,aAAgB,KAGpB,CACEN,SAAY,SACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,kBAAmBa,KAAQ,YAChD,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,SAAUwC,aAAgB,KAGnE,CACEN,SAAY,YACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,UAAWa,KAAQ,UACxC,CAACH,MAAS,EAAGV,KAAQ,SAAUa,KAAQ,UACvC,CAACH,MAAS,EAAGV,KAAQ,QAASa,KAAQ,cAG1C,CACEkC,SAAY,WACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,UAAWa,KAAQ,YAG5C,CACEkC,SAAY,gBACZC,SAAY,aACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,gBAAiBa,KAAQ,UAC9C,CAACH,MAAS,EAAGV,KAAQ,cAAea,KAAQ,YAC5C,CAACH,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,UAC7C,CAACH,MAAS,EAAGV,KAAQ,eAAgBa,KAAQ,WAE/CqC,MAAS,CAAC,CACRC,OAAU,mBACVnD,KAAQ,kBACRa,KAAQ,OACRwC,cAAgB,EAChBD,cAAgB,8BCzMU,CAC9B,CACEL,SAAY,MACZC,SAAY,WACZC,OAAU,CAAC,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,YAE/C,CACEkC,SAAY,OACZC,SAAY,WACZC,OAAU,CAAC,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,YAE/C,CACEkC,SAAY,OACZC,SAAY,WACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAAW,CAC3CH,MAAS,EACTV,KAAQ,aACRa,KAAQ,SACRuC,cAAgB,KAItB,CACEL,SAAY,QACZC,SAAY,WACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAAW,CAC3CH,MAAS,EACTV,KAAQ,aACRa,KAAQ,SACRuC,cAAgB,8BC/BQ,CAC9B,CACEL,SAAY,OACZC,SAAY,iBACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CACEC,OAAU,OACVnD,KAAQ,SACRa,KAAQ,QACRuC,cAAgB,GAElB,CAACD,OAAU,OAAQnD,KAAQ,QAASa,KAAQ,WAGhD,CACEkC,SAAY,aACZC,SAAY,iBACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,OAAQa,KAAQ,YAGzC,CACEkC,SAAY,MACZC,SAAY,iBACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,UAAWa,KAAQ,aAE1CqC,MAAS,CAAC,CACRC,OAAU,iBACVnD,KAAQ,gBACRa,KAAQ,SACRwC,aAAgB,KAGpB,CACEN,SAAY,QACZC,SAAY,iBACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,UAAWa,KAAQ,YAAa,CACnDH,MAAS,EACTV,KAAQ,gBACRa,KAAQ,SACRwC,aAAgB,KAItB,CACEN,SAAY,UACZC,SAAY,iBACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,QAASa,KAAQ,cAG1C,CACEkC,SAAY,UACZC,SAAY,iBACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CAAC,CACRC,OAAU,OACVG,iBAAoB,eACpBtD,KAAQ,OACRa,KAAQ,cAGZ,CACEkC,SAAY,iBACZC,SAAY,iBACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,aAAca,KAAQ,YAC3C,CAACH,MAAS,EAAGV,KAAQ,WAAYa,KAAQ,cAG7C,CACEkC,SAAY,iBACZC,SAAY,iBACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,aAAca,KAAQ,YAC3C,CAACH,MAAS,EAAGV,KAAQ,QAASa,KAAQ,cAG1C,CACEkC,SAAY,eACZC,SAAY,iBACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,WAEpCqC,MAAS,CACP,CAACC,OAAU,aAAcnD,KAAQ,YAAaa,KAAQ,UACtD,CAACsC,OAAU,cAAenD,KAAQ,aAAca,KAAQ,YAG5D,CACEkC,SAAY,cACZC,SAAY,iBACZC,OAAU,CACR,CAACvC,MAAS,EAAGV,KAAQ,IAAKa,KAAQ,UAClC,CAACH,MAAS,EAAGV,KAAQ,QAASa,KAAQ,aAExCqC,MAAS,mBC5EX,aACE,IAAMK,EAAM,CACVC,EAAYC,EAAWC,EAASC,EAAaC,EAAUC,EACvDC,EAAYC,EAASC,EAAOC,EAAOC,EAAUC,EAAeC,EAC5DC,EAAWC,EAAUC,GAEjBC,EAA0B,GAAGC,aAAH,GAAalB,EAAItC,KAAI,SAAAyD,GAAM,OAAAA,EAAGC,SAE9DC,KAAKC,UAAYL,EAAYM,QACzB,SAAC7D,EAAK8D,GAEJ,OADA9D,EAAI8D,EAAOhC,UAAYgC,EAChB9D,IAET,IA0VR,OA5WE+D,sBAAkBC,kBAAlB,WACE,OAAOL,KAAKM,YAAcN,KAAKM,UAAY,IAAIN,uCAsBjDK,2BAAA,SACIhB,EACAkB,GAFJ,wBAEIA,MACF,IAAMC,EAAUnB,EAAM9D,KAChBkF,EAAuB,GACvBC,EAAkB,GAClBC,EAAQH,EAAQN,QAA8B,SAAC7D,EAAKd,GAQxD,OAPAc,EAAId,EAAKH,MAAQwF,EAAKC,QAAQtF,GAC1BA,EAAKuE,GAAGgB,WAAW,gBACrBL,EAAaM,KAAK1E,EAAId,EAAKH,OAEb,UAAZG,EAAKuE,IACPY,EAAQK,KAAK1E,EAAId,EAAKH,OAEjBiB,IACN,IAECgC,EAAiB,GACf2C,EAAkB,GACpBC,EAA8C,GAC9CC,EAA+C,GAClC,MAAbX,IACFU,EAAqBjB,KAAKmB,oBAAoBZ,EAAUlC,QACxD6C,EAAsBlB,KAAKmB,oBAAoBZ,EAAUS,UAE3D,IAAMI,EAAWhB,OAAOiB,KAAKV,GAC7BS,EAASE,SAAQ,SAAAC,GACf,IAAMhG,EAAOoF,EAAMY,GACnBhG,EAAKY,WAAWmF,SAAQ,SAAAlG,GACf,IAAA6B,UACP1B,EAAK8C,OAAO0C,KAAKJ,EAAM1D,IACvB0D,EAAM1D,GAAUuE,SAAST,KAAKxF,SAMc,IAA5C6E,OAAOiB,KAAKH,GAAqBrD,OACnCuD,EAASE,SAAQ,SAAAC,GACf,IAAMhG,EAAOoF,EAAMY,GACU,IAAzBhG,EAAKiG,SAAS3D,QAChBmD,EAAQD,KAAKxF,MAIjB6E,OAAOiB,KAAKH,GAAqBI,SAAQ,SAAAlG,GAChC,IAAA6B,UACD1B,EAAOoF,EAAM1D,GACP,MAAR1B,IACFA,EAAKkG,aAAeP,EAAoB9F,GACxC4F,EAAQD,KAAKxF,OAKf6E,OAAOiB,KAAKJ,GAAoBpD,OAAS,EAC3CuC,OAAOiB,KAAKJ,GAAoBK,SAAQ,SAAAlG,GAC/B,IAAA6B,UACD1B,EAAOoF,EAAM1D,GACf1B,IACFA,EAAKkG,aAAeR,EAAmB7F,GACvCiD,EAAO0C,KAAKxF,OAIhB8C,EAASoC,EAGX,IAAIiB,EAAY,GAQhB,OAPqB,MAAjBrC,EAAMsC,SAA6C,MAA1BtC,EAAMsC,QAAQC,WACzCF,EAAYrC,EAAMsC,QAAQC,SAAS1B,QAAO,SAACwB,EAAWG,GAEpD,OADAH,EAAUG,EAAKtB,UAAUnF,MAAQwF,EAAKkB,YAAYD,GAC3CH,IACN,KAGE,CACLf,QACAtC,SACA2C,UACAN,UACAD,eACAF,YACAmB,cAIIrB,gCAAR,SAA4B0B,GAC1B,OAAO3B,OAAOiB,KAAKU,GAAW,IACzB7B,QAAgC,SAAC8B,EAAMC,GAEtC,OADAD,EAAKD,EAAQE,GAAM7G,MAAQ6G,EACpBD,IACN,KAGD3B,oBAAR,SAAgB9E,GAGd,IAAM4E,EACFhF,EAAgBI,EAAKuE,KAAOE,KAAKC,UAAU1E,EAAKuE,KAAO,GAC1C,MAAbvE,EAAK2G,OACP3G,EAAK2G,KAAO,IAGd,IAAMC,EAAgB,CACpB/G,KAAMG,EAAKH,KACX0E,GAAIvE,EAAKuE,GACT1B,SAAU+B,EAAO/B,SACjBjC,YACKZ,EAAK6G,OACL,IAAI/F,KAAI,SAAA+F,GAAS,OAAAA,EAAMtB,WAAW,KAAOsB,EAAMC,OAAO,GAAKD,KAChE/D,OAAQ,GACRmD,SAAU,GACV7F,YAAa,GACbkB,WAAY,GACZyF,SAAU/G,EAAK2G,MAuIjB,OApIqB,MAAjB/B,EAAO9B,SACT8D,EAAQxG,YACJwE,EAAO9B,OAAO6B,QACV,SAAC7D,EAAKkG,GAMJ,OALAlG,EAAIkG,EAAMnH,MAAQ,CAChBa,KAAMsG,EAAMtG,KACZJ,gBAAiB0G,EAAMzG,MACvBE,cAAeuG,EAAMxG,KAEhBM,IAET,KAEU,MAAhB8D,EAAO7B,QACT6D,EAAQtF,WACJsD,EAAO7B,MAAM4B,QAAoC,SAAC7D,EAAKkG,GACrD,IAAMtG,EAAOsG,EAAMtG,KACfa,OAAQlB,EACZ,OAAQ2G,EAAMtG,MACZ,IAAK,cAIWL,KAHdkB,EAAQ0F,EACJjH,EAAK2G,KAAMK,EAAMhE,OAAQgE,EAAM9D,gBAEN8D,EAAM7D,mBACjC5B,EAAQ0F,EACJjH,EAAK2G,KAAMK,EAAM7D,iBACjB6D,EAAM9D,eAEZ,MACF,IAAK,gBAIW7C,KAHdkB,EAAQ2F,EACJlH,EAAK2G,KAAMK,EAAMhE,OAAQgE,EAAM9D,gBAEN8D,EAAM7D,mBACjC5B,EAAQ2F,EACJlH,EAAK2G,KAAMK,EAAM7D,iBACjB6D,EAAM9D,eAEZ,MACF,IAAK,cAIW7C,KAHdkB,EAAQ4F,EACJnH,EAAK2G,KAAMK,EAAMhE,OAChBgE,EAAM9D,cAAgB,KACE8D,EAAM7D,mBACjC5B,EAAQ4F,EACJnH,EAAK2G,KAAMK,EAAM7D,iBACjB6D,EAAM9D,eAEZ,MACF,IAAK,gBAGW7C,KAFdkB,EAAQ6F,EACJpH,EAAK2G,KAAMK,EAAMhE,OAAQgE,EAAM9D,gBACN8D,EAAM7D,mBACjC5B,EAAQ6F,EACJpH,EAAK2G,KAAMK,EAAM7D,iBACjB6D,EAAM9D,eAEZ,MACF,IAAK,YAGW7C,KAFdkB,EAAQ8F,EACJrH,EAAK2G,KAAMK,EAAMhE,OAAQgE,EAAM9D,gBACN8D,EAAM7D,mBACjC5B,EAAQ8F,EACJrH,EAAK2G,KAAMK,EAAM7D,iBACjB6D,EAAM9D,eAEZ,MACF,IAAK,cAGW7C,KAFdkB,EAAQ+F,EACJtH,EAAK2G,KAAMK,EAAMhE,OAAQgE,EAAM9D,gBACN8D,EAAM7D,mBACjC5B,EAAQ+F,EACJtH,EAAK2G,KAAMK,EAAM7D,iBACjB6D,EAAM9D,eAEZ,MACF,IAAK,aAGW7C,KAFdkB,EAAQgG,EACJvH,EAAK2G,KAAMK,EAAMhE,OAAQgE,EAAM9D,gBACN8D,EAAM7D,mBACjC5B,EAAQgG,EACJvH,EAAK2G,KAAMK,EAAM7D,iBACjB6D,EAAM9D,eAEZ,MACF,IAAK,eAGW7C,KAFdkB,EAAQiG,EACJxH,EAAK2G,KAAMK,EAAMhE,OAAQgE,EAAM9D,gBACN8D,EAAM7D,mBACjC5B,EAAQiG,EACJxH,EAAK2G,KAAMK,EAAM7D,iBACjB6D,EAAM9D,eAEZ,MACF,IAAK,aAGW7C,KAFdkB,EAAQkG,EACJzH,EAAK2G,KAAMK,EAAMhE,OAAQgE,EAAM9D,gBACN8D,EAAM7D,mBACjC5B,EAAQkG,EACJzH,EAAK2G,KAAMK,EAAM7D,iBACjB6D,EAAM9D,eAEZ,MACF,IAAK,eAGW7C,KAFdkB,EAAQmG,EACJ1H,EAAK2G,KAAMK,EAAMhE,OAAQgE,EAAM9D,gBACN8D,EAAM7D,mBACjC5B,EAAQmG,EACJ1H,EAAK2G,KAAMK,EAAM7D,iBACjB6D,EAAM9D,eAEZ,MACF,IAAK,YAGW7C,KAFdkB,EAAQoG,EACJ3H,EAAK2G,KAAMK,EAAMhE,OAAQgE,EAAM9D,gBACN8D,EAAM7D,mBACjC5B,EAAQoG,EACJ3H,EAAK2G,KAAMK,EAAM7D,iBACjB6D,EAAM9D,eAEZ,MACF,IAAK,SACL,IAAK,UACH,MACF,QACE,MAAM,IAAI0E,MACN,2BAA2BZ,EAAMtG,iBAAgBV,EAAKuE,IAG9D,OADAzD,EAAIkG,EAAMnH,MAAQ,CAAC0B,QAAOb,QACnBI,IACN,KAEF8F,GAID9B,wBAAR,SAAoB+C,GAApB,WACQ5C,EAAU4C,EAAYC,QAEtB3C,EAAkB,GACpBC,EAA+B,GACpB,MAAXH,IACFG,EAAQH,EAAQN,QAA8B,SAAC7D,EAAKd,GAKlD,OAJAc,EAAId,EAAKH,MAAQwF,EAAKC,QAAQtF,GACd,UAAZA,EAAKuE,IACPY,EAAQK,KAAK1E,EAAId,EAAKH,OAEjBiB,IACN,KAEL,IAAMgC,EAAiB,GACjB2C,EAAkB,GAExBoC,EAAY7C,UAAU+C,SAAShC,SAAQ,SAAAiC,GAC9B,IAAAtG,eACD1B,EAAa,CACjBH,KAAM6B,EACN6C,GAAI,cACJzB,OAAQ,GACRlC,WAAY,GACZiC,SAAU,QACVzC,YAAa,GACbkB,WAAY,CAAC2G,MAAO,CAAC1G,MAAO2G,EAAgBF,EAAItH,MAAOA,KAAM,UAC7DuF,SAAU,IAEZjG,EAAKkG,aAAe8B,EAAInI,KACxBiD,EAAO0C,KAAKxF,GACZoF,EAAM1D,GAAY1B,KAGH6E,OAAOiB,KAAKV,GACpBW,SAAQ,SAAAC,GACf,IAAMhG,EAAOoF,EAAMY,GACnBhG,EAAKY,WAAWmF,SAAQ,SAAAlG,GACf,IAAA6B,UACP1B,EAAK8C,OAAO0C,KAAKJ,EAAM1D,IACvB0D,EAAM1D,GAAUuE,SAAST,KAAKxF,SAIlC,IAAMmI,EAAgBN,EAAYO,IAElCP,EAAY7C,UAAUqD,UAAUtC,SAAQ,SAAAuC,GAChC,IAAA7G,eAACC,OAAUC,OACX3B,EAAOoF,EAAM1D,GACP,MAAR1B,IACFA,EAAKuI,cAAgB5G,EACrB8D,EAAQD,KAAKxF,OAIjB,IAAMgF,EAAYP,KAAK+D,mBAAmBX,GAC1C,MAAO,CAACzC,QAAOtC,SAAQ2C,UAASN,UAASD,aAtDZ,GAsD0BF,cAGjDF,+BAAR,SAA2B+C,GAA3B,WAEE,MAAO,CACLY,WAAYZ,EAAY7C,UAAUnF,KAClCiD,OAAQ+E,EAAY7C,UAAU+C,SAASpD,QACnC,SAAC7D,EAAKkH,GAEJ,OADAlH,EAAIkH,EAAInI,MAAQwF,EAAKqD,mBAAmBV,GACjClH,IAET,IACJ2E,QAASoC,EAAY7C,UAAUqD,UAAU1D,QACrC,SAAC7D,EAAKkH,GAEJ,OADAlH,EAAIkH,EAAInI,MAAQwF,EAAKqD,mBAAmBV,EAAKH,EAAYO,KAClDtH,IAET,MAIAgE,+BAAR,SACIkD,EACAW,GACF,IAAI9I,EAAOmI,EAAInI,KAIf,OAHe,MAAX8I,IACF9I,EAAO8I,EAAQ9I,IAEV,CAACA,OAAMoI,MAAOD,EAAItH,qBAiBbkI,EAAiBC,EAAcC,GAC7C,IAAMvH,EACFwH,MAAMC,QAAQH,GAAKI,OAAOC,aAAaC,MAAM,KAAMN,YAf5BO,GAC3B,IAAMC,EAASC,QAAMD,OACrB,QAA2B,IAAhBA,EAAOE,KAChB,OAAOF,EAAOE,KAAKH,GACd,GAAsB,oBAAXI,OAChB,OAAO,IAAIA,OAAOJ,EAAM,UAAUK,WAElC,MAAM,IAAI7B,MACN,oFAOsD8B,CAAab,GACzE,OAAOC,EAAWvH,EAAQA,EAAMoI,uBAGlB1C,EACZlE,EAA+ClD,EAAc+J,EAC7Dd,gBAAAA,MACF,IAAM9B,EAAQjE,EAAMlD,GACpB,OAAa,MAATmH,EACK4B,EAAiB5B,EAAM6B,EAAGC,GAE5Bc,WAGOvC,EACZtE,EAA+ClD,EAC/C+J,GACF,IAAM5C,EAAQjE,EAAMlD,GACpB,OAAOmH,EAAQA,EAAM6C,EAAID,WAGXzC,EACZpE,EAA+ClD,EAC/C+J,GACF,IAAM5C,EAAQjE,EAAMlD,IAAS,GACvB0B,EACY,MAAdyF,EAAS,EAAYA,EAAS,EAAmB,MAAdA,EAAS,EAAYA,EAAS,EAAI4C,EACzE,MAAyB,iBAAVrI,EAAsBA,EAAQuI,SAASvI,EAAO,aAG/C2G,EAAgB3G,GAK9B,OAJuB,qBAErBA,EAAQwI,EAAoBxI,IAEtBA,GACN,KAAKwI,EAAoBC,SACvB,MAAO,UACT,KAAKD,EAAoBE,SACzB,KAAKF,EAAoBG,SACzB,KAAKH,EAAoBI,QACzB,KAAKJ,EAAoBK,SACvB,MAAO,QACT,KAAKL,EAAoBM,QACvB,MAAO,OACT,KAAKN,EAAoBO,UACvB,MAAO,UACT,KAAKP,EAAoBQ,UACvB,MAAO,SACT,QAGE,OAAO,eAIG5C,EACZ5E,EAA+ClD,EAC/C+J,GACF,IAAM5C,EAAQjE,EAAMlD,GACpB,OAAImH,GAASA,EAAMV,KACVU,EAAMV,KAAKzG,KAEb+J,WAGOnC,EACZ1E,EAA+ClD,EAC/C+J,GACF,IAAM5C,EAAQjE,EAAMlD,GACpB,OAAImH,GAASA,EAAMtG,KACVwH,EAAgBlB,EAAMtG,MAExBkJ,WAGOlC,EACZ3E,EAA+ClD,EAC/C+J,GACF,IAAM5C,EAAQjE,EAAMlD,GACpB,OAAImH,GAASA,EAAMwD,MAAQxD,EAAMwD,KAAK9J,KAC7BsG,EAAMwD,KAAK9J,KAAKI,KAAI,SAAA2J,GAAK,OAAAvC,EAAgBuC,MAE3Cb,WAGOc,EAAsBtJ,GAEpC,IAAIA,EAAMuJ,YAGV,OAAiB,MAAbvJ,EAAMwJ,IACDxJ,EAAMwJ,IAAI9J,KACb,SAAA8J,GACI,MAAqB,iBAAbA,EAAIC,KAAqBD,EAAIC,KAAOf,SAASc,EAAIC,KAAM,OAElE,YAGOtD,EACZxE,EAA+ClD,EAC/C+J,GACF,IAAM5C,EAAQjE,EAAMlD,GACpB,OAAImH,GAASA,EAAM5F,MACVsJ,EAAsB1D,EAAM5F,OAE9BwI,WAGOxC,EACZrE,EAA+ClD,EAC/C+J,GACF,IAAM5C,EAAQjE,EAAMlD,GACpB,OAAImH,IACOA,EAAMwD,KAAKM,GAAK9D,EAAMwD,KAAKM,EAAExI,OAAS0E,EAAMwD,KAAKM,EACX9D,EAAMwD,KAAK7H,IAClD,IACH7B,KAAI,SAAA2J,GAAK,MAAc,iBAANA,EAAkBA,EAAIX,SAASW,EAAG,OAEnDb,WAGO1C,EACZnE,EAA+ClD,EAAc+J,EAC7Dd,gBAAAA,MACF,IAAM9B,EAAQjE,EAAMlD,GACpB,OAAImH,GAASA,EAAMwD,MAAQxD,EAAMwD,KAAK3B,EAC7B7B,EAAMwD,KAAK3B,EAAE/H,KAAI,SAAC2J,GACvB,OAAO7B,EAAiB6B,EAAG3B,MAGxBc,WAGOpC,EACZzE,EAA+ClD,EAC/C+J,GACF,IAAM5C,EAAQjE,EAAMlD,GACpB,OAAImH,GAASA,EAAMwD,MAAQxD,EAAMwD,KAAKpJ,MAC7B4F,EAAMwD,KAAKpJ,MAAMN,KAAI,SAAC2J,GAC3B,OAAOC,EAAsBD,MAG1Bb,WAGOtC,EACZvE,EAA+ClD,EAC/C+J,GACF,IAAM5C,EAAQjE,EAAMlD,GACpB,OAAImH,GAASA,EAAMwD,MAAQxD,EAAMwD,KAAKX,EAC7B7C,EAAMwD,KAAKX,EAEbD,ECziBT,iBAGE,WACY5J,EAAoBC,EACpBC,GAFZ,WACYuE,UAAAzE,EAAoByE,eAAAxE,EACpBwE,aAAAvE,EAJIuE,YAAmB,GACnBA,WAAoC,GAIlDA,KAAK3B,OAAS9C,EAAKY,WAAWE,KAAI,SAAAjB,GAAQ,OAAAwF,EAAK0F,SAASlL,MACnC,MAAjBG,EAAK+G,WACPtC,KAAK1B,MAAQ8B,OAAOiB,KAAK9F,EAAK+G,UACZpC,QAAO,SAAC5B,EAAmCiD,GAE1C,OADAjD,EAAMiD,GAAOX,EAAK2F,QAAQhF,GACnBjD,IACN,KA8D1B,OAtDUkI,qBAAR,SAAiBpL,GACf,OAAOc,EAAUd,EAAM4E,KAAKxE,UAAWwE,KAAKvE,UAOtC+K,oBAAR,SAAgBpL,EAAcqD,GAC5B,IAAM3B,EAAQkD,KAAKzE,KAAK+G,SAASlH,GACjC,GAAoB,MAAhB0B,EAAMR,OACR,OAAOJ,EAAUd,EAAM4E,KAAKxE,UAAWwE,KAAKvE,SAE9C,GAAe,MAAXqB,EAAMoB,GAAwB,MAAXpB,EAAMuJ,EAC3B,OAAO3D,EAAe1C,KAAKzE,KAAK+G,SAAUlH,EAAMqD,GAElD,GAAe,MAAX3B,EAAMsH,EACR,OAAO5B,EAAexC,KAAKzE,KAAK+G,SAAUlH,EAAMqD,GAElD,GAAe,MAAX3B,EAAMsI,EACR,OAAOxC,EAAa5C,KAAKzE,KAAK+G,SAAUlH,EAAMqD,GAEhD,GAAmB,MAAf3B,EAAMH,MACR,OAAOmG,EACH9C,KAAKzE,KAAK+G,SAAUlH,EAAMqD,GAEhC,GAAkB,MAAd3B,EAAMb,KACR,OAAO+G,EAAchD,KAAKzE,KAAK+G,SAAUlH,EAAMqD,GAEjD,GAAkB,MAAd3B,EAAMiJ,KAAc,CACtB,GAAoB,MAAhBjJ,EAAMiJ,KAAK7H,GAA6B,MAAhBpB,EAAMiJ,KAAKM,EACrC,OAAO1D,EACH3C,KAAKzE,KAAK+G,SAAUlH,EAAMqD,GAEhC,GAAoB,MAAhB3B,EAAMiJ,KAAK3B,EACb,OAAO3B,EACHzC,KAAKzE,KAAK+G,SAAUlH,EAAMqD,GAEhC,GAAwB,MAApB3B,EAAMiJ,KAAKpJ,MACb,OAAOoG,EACH/C,KAAKzE,KAAK+G,SAAUlH,EAAMqD,GAEhC,GAAoB,MAAhB3B,EAAMiJ,KAAKX,EACb,OAAOvC,EACH7C,KAAKzE,KAAK+G,SAAUlH,EAAMqD,GAEhC,GAAuB,MAAnB3B,EAAMiJ,KAAK9J,KACb,OAAOgH,EACHjD,KAAKzE,KAAK+G,SAAUlH,EAAMqD,GAIlC,OAAOA,iBC3EKgI,EACZC,EAAkBC,EAAkBC,gBAAAA,MACtCC,OAAKC,gBAKuCC,EAAcC,GAC1D,GAAID,EAAGlJ,SAAWmJ,EAAGnJ,OACnB,OAAO,EAET,IAAK,IAAIK,EAAI,EAAGA,EAAI6I,EAAGlJ,OAAQK,IAC7B,IAAe,IAAX6I,EAAG7I,KAAwB,IAAX8I,EAAG9I,IAAa6I,EAAG7I,KAAO8I,EAAG9I,GAC/C,OAAO,EAGX,OAAO,EAbH+I,CAA8BP,EAAQC,IACtC,WAAM,OAAAC,EAAqB,WAAWF,UAAcC,mBCE1D,iBAIE,WACavL,EAAuBoI,EAAyB0D,EACjDC,EAAiCC,EAChCC,EAA+BC,GAF/BtH,UAAA5E,EAAuB4E,WAAAwD,EAAyBxD,aAAAkH,EACjDlH,kBAAAmH,EAAiCnH,4BAAAoH,EAChCpH,iBAAAqH,EAA+BrH,oBAAAsH,EANpCtH,aAA6B,GAC7BA,cAAU,EAMhBA,KAAKuH,SAAWC,SAAO,GACvBC,OAAKzH,KAAKuH,UA+Qd,OA5QEnH,sBAAIsH,sBAAJ,WACE,OAAO1H,KAAKuH,SAASI,oCAGvBvH,sBAAIsH,0BAAJ,WACE,OAAO1H,KAAK4H,yCAMdF,0BAAA,WACE1H,KAAK6H,QAAQvG,SAAQ,SAAAhF,GAAU,OAAAA,EAAOA,OAAOwL,aAC7C9H,KAAK6H,QAAU,GACf7H,KAAK4H,SAAU,EACf5H,KAAKuH,SAASO,WAGhBJ,iBAAA,WACE,OAAO1H,KAAK6H,QAAQhK,QAOtB6J,iBAAA,SAAKxK,GACH,GAAI8C,KAAK4H,QACP,MAAM,IAAIzE,MAAM,eAAenD,KAAK5E,kCAGtC,GAAI8B,EAAQ,GAAKA,GAAS8C,KAAKoG,OAC7B,MAAM,IAAIjD,MAAM,4BAA4BjG,0BACxC8C,KAAKoG,QAGX,IAAM2B,EAAkB/H,KAAK6H,QAAQ3K,GACrC,GAAI6K,EAAgBC,QAClB,MAAM,IAAI7E,MACN,eAAenD,KAAK5E,+BAChB8B,EADJ,wGAUN,OALI8C,KAAKsH,iBACPS,EAAgBC,SAAU,GAG5BD,EAAgBE,MAAO,EAChBF,EAAgBzL,QAMzBoL,qBAAA,SAASQ,GAAT,WACE,OAAOA,EAAQ7L,KAAI,SAAAa,GAAS,OAAA0D,EAAKqH,KAAK/K,OAQxCwK,kBAAA,SAAMxK,EAAeZ,GACnB,GAAI0D,KAAK4H,QACP,MAAM,IAAIzE,MAAM,eAAenD,KAAK5E,kCAGtC,GAAI8B,EAAQ,IAAM8C,KAAKqH,aAAenK,GAAS8C,KAAKkH,QAClD,MAAM,IAAI/D,MAAM,2BACZjG,gDAAmD8C,KAAKkH,SAG9D,IAAMiB,EAAInI,KAAK6H,QAAQ3K,IAAU,GAEjC,GAAIZ,EAAOkH,QAAUxD,KAAKwD,MACxB,MAAM,IAAIL,MAAM,eACZnD,KAAK5E,+CAA8C8B,6CAEnDZ,EAAOkH,oCAAmCxD,KAAKwD,WAcrD,GAVoB,IAAhBxD,KAAKoG,QACiB,MAArBpG,KAAKmH,cAAqD,IAA7BnH,KAAKmH,aAAatJ,SAClDmC,KAAKmH,aAAe7K,EAAOK,OAG7B8J,EACIzG,KAAKmH,aAAc7K,EAAOK,MAC1B,eAAeqD,KAAK5E,+CAChB8B,OAEJiL,EAAEF,KACJ,MAAM,IAAI9E,MACN,eAAenD,KAAK5E,+CAChB8B,yCAGV,GAAIiL,EAAEC,QACJ,MAAM,IAAIjF,MACN,eAAenD,KAAK5E,+CAChB8B,4CAGViL,EAAE7L,OAASA,EACXmL,OAAKnL,GACL6L,EAAEC,SAAU,EAEZpI,KAAK6H,QAAQ3K,GAASiL,GAMxBT,sBAAA,SAAUQ,EAAmBL,GAA7B,WACE,GAAIK,EAAQrK,SAAWgK,EAAQhK,OAC7B,MAAM,IAAIsF,MACN,eAAenD,KAAK5E,KAApB,8DAEI8M,EAAQrK,4CACRgK,EAAQhK,YAGlBqK,EAAQ5G,SAAQ,SAACpD,EAAGhB,GAAU,OAAA0D,EAAKyH,MAAMnK,EAAG2J,EAAQ3K,QAWtDwK,mBAAA,SAAOQ,EAAoB1E,GACzB,GAAMA,GAASA,IAAUxD,KAAKwD,MAC5B,MAAM,IAAIL,MAAM,wBACZnD,KAAKwD,qCAAoCA,GAG/C,GAAK0E,EAMHA,EAAUA,EAAQ9L,MAAM,EAAG4D,KAAKoG,YANpB,CACZ8B,EAAU,GACV,IAAK,IAAIhK,EAAI,EAAGA,EAAI8B,KAAKoG,OAAQlI,IAC/BgK,EAAQnH,KAAK7C,GAMjB,GAAuB,IAAnBgK,EAAQrK,OACV,OAAOvB,SAAO,GAAI,CAAC,GAAGuD,OAAOG,KAAKmH,eAKpC,IAAMU,EAAU7H,KAAKsI,SAASJ,GAK9B,OAHAzB,EACIzG,KAAKmH,aAAcU,EAAQ,GAAGlL,MAAO,gCAElC4L,QAAMV,EAAS,IAMxBH,mBAAA,SAAOlE,GACL,GAAMA,GAASA,IAAUxD,KAAKwD,MAC5B,MAAM,IAAIL,MAAM,wBACZnD,KAAKwD,qCAAoCA,GAG/C,GAAoB,IAAhBxD,KAAKoG,OACP,OAAO9J,SAAO,GAAI,CAAC,GAAGuD,OAAOG,KAAKmH,eAIpC,IADA,IAAMe,EAAU,GACPhK,EAAI,EAAGA,EAAI8B,KAAKoG,OAAQlI,IAC/BgK,EAAQnH,KAAK7C,GAGf,IAAM2J,EAAU7H,KAAKsI,SAASJ,GAO9B,OALAzB,EACIzG,KAAKmH,aAAcU,EAAQ,GAAGlL,MAC9B,mDACIqD,KAAKmH,yCAAwCU,EAAQ,GAAGlL,WAEzDkD,SAAOgI,EAAS,IASzBH,oBAAA,SAAQQ,EAAmB5L,GACzB,GAAIA,EAAOkH,QAAUxD,KAAKwD,MACxB,MAAM,IAAIL,MAAM,wBACZnD,KAAKwD,+BAA8BlH,EAAOkH,OAGhD,GAAI0E,EAAQrK,SAAWvB,EAAOK,MAAM,GAClC,MAAM,IAAIwG,MAAM,sDACZ+E,EAAQrK,eAAcvB,EAAOK,MAAM,IAGzC,IAAM6L,EAAWC,KAAKC,UAALD,KAAYP,GAE7B,IAAKlI,KAAKqH,aAAemB,GAAYxI,KAAKkH,QACxC,MAAM,IAAI/D,MACN,mCAAmCqF,WAAiBxI,KAAKkH,aAG/DlH,KAAK2I,UAAUT,EAASU,UAAQtM,EAAQ,KAS1CoL,kBAAA,SAAM7J,EAAkBvB,GAAxB,WACE,GAAIA,EAAOkH,QAAUxD,KAAKwD,MACxB,MAAM,IAAIL,MAAM,wBACZnD,KAAKwD,+BAA8BlH,EAAOkH,OAEhD,IAAIqF,EAAc,EACZC,EAAoBjL,EAAOxB,KAAI,SAAA0M,GAEnC,OADAF,GAAeE,KAIjB,GAAIF,IAAgBvM,EAAOK,MAAM,GAC/B,MAAM,IAAIwG,MAAM,qGAEZ0F,8BAAuCvM,EAAOK,OAGpD,IAAKqD,KAAKqH,aAAexJ,EAAOA,SAAWmC,KAAKkH,QAC9C,MAAM,IAAI/D,MACN,2DACInD,KAAKkH,gBAAerJ,EAAOA,OAD/B,kEAKN,IAAMmL,EAAgC,IAAhBH,EAAoB,EAAIvM,EAAO8J,KAAOyC,EACtDhB,EAAoB,GAC1BoB,QAAK,WACH3M,EAASA,EAAO4M,QAAQ,CAAC,EAAGL,EAAaG,IACzC,IAAK,IAAI9K,EAAI,EAAGA,EAAIL,EAAOA,SAAUK,EAAG,CACtC,IACMiL,EAAU,CAAC,EADa,IAANjL,EAAW,EAAI4K,EAAkB5K,EAAI,GACzB,GAC9BkL,EAAQ,CAAC,EAAGvL,EAAOK,GAAI8K,GAC7BnB,EAAQ3J,GAAK9B,QAAME,EAAQ6M,EAASC,GAAOF,QAAQtI,EAAKuG,cAE1D,OAAOU,KAGT,IADA,IAAMK,EAAU,GACPhK,EAAI,EAAGA,EAAIL,EAAOA,OAAQK,IACjCgK,EAAQhK,GAAKA,EAEf8B,KAAK2I,UAAUT,EAASL,sBClQ1B,WACaA,EAA4BV,EAC5BkC,EAAwBC,gBAAAA,GAAkB,GAD1CtJ,aAAA6H,EAA4B7H,kBAAAmH,EAC5BnH,kBAAAqJ,EACI,MAAXxB,GACFA,EAAQvG,SAAQ,SAAAhF,GACd,GAAI+M,IAAiB/M,EAAOkH,MAC1B,MAAM,IAAIL,MAAM,mCACZkG,yBAAmC/M,EAAOkH,OAEhDiD,EACIU,EAAc7K,EAAOK,MAAO,+BAEhC8K,OAAKnL,MAGT0D,KAAKuH,SAAWC,SAAO,GACvBxH,KAAKsJ,eAAiBA,EACtB7B,OAAKzH,KAAKuH,UAwNd,OApPEnH,sBAAImJ,sBAAJ,WACE,OAAOvJ,KAAKuH,SAASI,oCAiCvB4B,iBAAA,WACE,OAAO,IAAIA,EACHvJ,KAAK6H,gBAAU7H,KAAKmH,aAAcnH,KAAKqJ,eAMjDE,0BAAA,WACEvJ,KAAK6H,QAAQvG,SAAQ,SAAAhF,GAAU,OAAAA,EAAOwL,aACtC9H,KAAK6H,QAAQhK,OAAS,EACtBmC,KAAKuH,SAASO,WAKhByB,iBAAA,WACE,OAAOvJ,KAAK6H,QAAQhK,QAUtB0L,kBAAA,SAAMpC,EAAwBkC,EAAwBG,GAAtD,WAEE,gBAFoDA,GAAe,GAE/DH,IAAiBrJ,KAAKqJ,aACxB,MAAM,IAAIlG,MAAM,mCACZkG,yBAAmCrJ,KAAKqJ,cAE9C,IAAqB,IAAjBG,GAAsBxJ,KAAK6H,QAAQhK,SAAW2L,EAChD,MAAM,IAAIrG,MAAM,kCACZqG,mCACAxJ,KAAK6H,QAAQhK,qBAInB,OAFA4I,EACIU,EAAcnH,KAAKmH,aAAc,+BAC9B8B,QAAK,WACV,IAAMQ,EACF7I,EAAKiH,QAAQxL,KAAI,SAAAC,GAAU,OAAAA,EAAO4M,QAAQ/B,MAC9C,OAAOoB,QAAMkB,EAAiB,OASlCF,oBAAA,SAAQpC,EAAwBkC,GAC9B,GAAIA,IAAiBrJ,KAAKqJ,aACxB,MAAM,IAAIlG,MAAM,mCACZkG,yBAAmCrJ,KAAKqJ,cAG9C,GAAoB,IAAhBrJ,KAAKoG,OACP,MAAM,IAAIjD,MAAM,qCAGlB,IAAM7G,EAAS0D,KAAK6H,QAAQ6B,MAG5B,OAFAjD,EACInK,EAAOK,MAAOwK,EAAc,+BACzB7K,EAAO4M,QAAQ/B,IAOxBoC,qBAAA,SAASjN,GACP,GAAIA,EAAOkH,QAAUxD,KAAKqJ,aACxB,MAAM,IAAIlG,MAAM,mCACZ7G,EAAOkH,6BAA4BxD,KAAKqJ,cAM9C,GAHA5C,EACInK,EAAOK,MAAOqD,KAAKmH,aAAc,+BAEjCnH,KAAKsJ,iBAAmBtJ,KAAKoG,OAC/B,MAAM,IAAIjD,MAAM,4CAElBsE,OAAKnL,GACL0D,KAAK6H,QAAQ9G,KAAKzE,IAOpBiN,mBAAA,SAAOnD,GACL,GAAIA,EAAO,EACT,MAAM,IAAIjD,MACN,0DAA0DiD,GAGhE,IAA6B,IAAzBpG,KAAKsJ,gBAAyBlD,EAAOpG,KAAKsJ,eAC5C,MAAM,IAAInG,MAAM,+BACZiD,+BAAiCpG,KAAKsJ,oBAE5CtJ,KAAK6H,QAAQhK,OAASuI,GASxBmD,oBAAA,SAAQI,EAAsBxC,EAAwBkC,GAEpD,GAAIA,IAAiBrJ,KAAKqJ,aACxB,MAAM,IAAIlG,MAAM,mCACZkG,yBAAmCrJ,KAAKqJ,cAE9C,GAAIM,EAAe,GAAKA,EAAe3J,KAAK6H,QAAQhK,OAClD,MAAM,IAAIsF,MAAM,4BACZwG,qBAA+B3J,KAAK6H,QAAQhK,qBAGlD,GAAkC,MAA9BmC,KAAK6H,QAAQ8B,GACf,MAAM,IAAIxG,MAAM,oBAAoBwG,eAOtC,OAJAlD,EACIzG,KAAK6H,QAAQ8B,GAAchN,MAAOwK,EAClC,+BAEGnH,KAAK6H,QAAQ8B,IAQtBJ,oBAAA,SAAQI,EAAsBrN,GAC5B,GAAIA,EAAOkH,QAAUxD,KAAKqJ,aACxB,MAAM,IAAIlG,MAAM,mCACZ7G,EAAOkH,6BAA4BxD,KAAKqJ,cAG9C,GAAIM,EAAe,IACU,IAAzB3J,KAAKsJ,gBAAyBK,GAAgB3J,KAAKsJ,eACrD,MAAM,IAAInG,MAAM,yBACZwG,yBAAmC3J,KAAKsJ,6BAG9C7C,EACIzG,KAAKmH,aAAc7K,EAAOK,MAAO,+BACrC8K,OAAKnL,GACL0D,KAAK6H,QAAQ8B,GAAgBrN,GAU/BiN,mBAAA,SAAOrB,EAAmBmB,EAAwBlC,GAAlD,WAEE,GAAIkC,IAAiBrJ,KAAKqJ,aACxB,MAAM,IAAIlG,MAAM,mCACZkG,yBAAmCrJ,KAAKqJ,cAU9C,OAPA5C,EACIzG,KAAKmH,aAAcA,EAAc,+BAMd,KAFvBe,EAAUA,EAAQ9L,MAAM,EAAG4D,KAAKoG,SAEpBvI,OACHvB,SAAO,GAAI,CAAC,GAAGuD,OAAOG,KAAKmH,eAG7B8B,QAAK,WACV,IAAMpB,EAAUK,EAAQ7L,KAAI,SAAA6B,GAAK,OAAA0C,EAAKiH,QAAQ3J,GAAGgL,QAAQ/B,MACzD,OAAOoB,QAAMV,EAAS,OAS1B0B,mBAAA,SAAOF,EAAwBlC,GAA/B,WACE,GAAMkC,GAAgBA,IAAiBrJ,KAAKqJ,aAC1C,MAAM,IAAIlG,MAAM,uBACZnD,KAAKqJ,4CAA2CA,GAMtD,OAHA5C,EACIzG,KAAKmH,aAAcA,EAAc,+BAEjB,IAAhBnH,KAAKoG,OACA9J,SAAO,GAAI,CAAC,GAAGuD,OAAOG,KAAKmH,eAG7B8B,QAAK,WACV,IAAMpB,EAAUjH,EAAKiH,QAAQxL,KAAI,SAAA8L,GAAK,OAAAA,EAAEe,QAAQ/B,MAChD,OAAOtH,SAAOgI,EAAS,YCxQ7B,IAWa+B,EAAqC,SAC9CrO,EAAYC,EACZC,kOACMF,EAAKuE,QACN,SACA,cAAA,gBAkBA,YACA,iBAAA,gBAuDA,WAAA,gBAKA,SAAA,iBASA,QAAA,iBAMA,QAAA,iBAQA,OAAA,iBAMA,gBAAA,iBAMA,gBAAA,iBAoBA,qBAAA,iBAUA,oBAAA,iBAQA,sBAAA,iBAWA,uBAAA,iBAYA,sBAAA,iBASA,qBAAA,iBAYA,oBAAA,iBAMA,qBAAA,iBAQA,oBAAA,iBAUA,oBAAA,iBAcA,0BACA,oBAAA,iBAcA,oBAAA,iBAYA,mBAAA,iBAaA,kBAAA,iBAaA,uBAAA,iBAYA,mBAAA,iBAUA,qBAAA,iBASA,oBAAA,iBAWA,kBAAA,iCAhUe,OARZ+J,EACFxO,EAAc,aAAcE,EAAMC,EAAWC,GAC3CqO,EACFzO,EAAc,aAAcE,EAAMC,EAAWC,GAC3CsO,EACF1O,EAAc,OAAQE,EAAMC,EAAWC,GACrCuO,EACF3O,EAAc,OAAQE,EAAMC,EAAWC,MACnBsO,EAAKxN,eAC7B,OADM0N,EAAYC,WACJ,MACLzO,EAAQ0O,YAAYN,GAAUO,qBACjCJ,EAAMvO,EAAQ4O,eAAgB5O,EAAQ6O,mBAEnC7O,EAAQ0O,YAAYL,GAAUM,qBACjCJ,EAAMvO,EAAQ4O,eAAgB5O,EAAQ6O,uBAcvC,OATCC,EACFlP,EAAc,OAAQE,EAAMC,EAAWC,GACrC+O,EACFnP,EAAc,OAAQE,EAAMC,EAAWC,GACrCuO,EACF3O,EAAc,OAAQE,EAAMC,EAAWC,MAIhCA,EAAQ0O,YAAYK,GAAUJ,qBACjCJ,EAAMvO,EAAQ4O,eAAgB5O,EAAQ6O,uBAE9B,OAJVG,EACDP,UAECQ,EAASV,EAAK3N,KAAI,SAAAC,GAAU,OAAAA,EAAOqL,SACnB8C,EAAW,GAAGlO,eAAhC0N,EAAYC,UAEhBO,EAAWnJ,SAAQ,SAAAhF,GACZA,EAAOqO,OAAuC,IAA/BD,EAAOE,QAAQtO,EAAOqL,KACxCrL,EAAOwL,aAIP+C,EAAuBb,2EAMhB,OAFHc,EAAaD,KAEJpP,EAAQ0O,YAAYI,GAAUH,qBACzCS,EAAQpP,EAAQ4O,eAAgB5O,EAAQ6O,uBAcvC,OAfLO,EAAS7N,SAEH+N,EAAYF,EAAOxO,KAAI,SAAAC,GAAU,OAAAA,EAAOqL,MAI9CmD,EAAWxJ,SAAQ,SAAAhF,GACZA,EAAOqO,OAAuC,IAA/BD,EAAOE,QAAQtO,EAAOqL,MACJ,IAAlCoD,EAAUH,QAAQtO,EAAOqL,KAC3BrL,EAAOwL,gBAMArM,EAAQ0O,YAAYK,GAAUJ,qBACjCS,EAAQpP,EAAQ4O,eAAgB5O,EAAQ6O,uBACpC,UAHNU,EACDhO,UAEwB,GAAGT,sBAAhC0N,EAAYjN,SAEZgO,EAAW1J,SAAQ,SAAAhF,GACZA,EAAOqO,OAAuC,IAA/BD,EAAOE,QAAQtO,EAAOqL,MACJ,IAAlCoD,EAAUH,QAAQtO,EAAOqL,KAC3BrL,EAAOwL,+CA1BNmC,EAAU,sDA8BjB,SAAOY,UAGP,SAAO,CACJxP,EAAc,OAAQE,EAAMC,EAAWC,GAAwBwP,kBAS1D,OALFC,EACF7P,EAAc,OAAQE,EAAMC,EAAWC,GACrCc,EACFlB,EAAc,OAAQE,EAAMC,EAAWC,MAE7ByP,EAAK3O,gBAAnB,SAAQ2N,UAAmB,GAAK,MAACtO,EAAWW,EAAK0O,SACjB,CAAC1O,EAAK0O,aAASrP,YAK/C,UAFM4B,EAAYjC,EAAKY,WAAWkB,MAC9B,SAAAjC,GAAQ,YAAwCQ,IAAxCM,EAAUd,EAAMI,EAAWC,OACpB,CAACS,EAAUsB,EAAWhC,EAAWC,GAASwP,cAC1CrP,WAQnB,OALMuP,EACF9P,EAAc,YAAaE,EAAMC,EAAWC,GAC1Cc,EACFlB,EAAc,SAAUE,EAAMC,EAAWC,GAC7CA,EAAQ2P,WAAWD,MACZ,CAAC5O,EAAK0O,kBAMb,OAHM3O,EACFjB,EAAc,SAAUE,EAAMC,EAAWC,GAC7CA,EAAQ4P,eACD,CAAC/O,EAAO2O,kBAMf,OAHM7I,EACF/G,EAAc,SAAUE,EAAMC,EAAWC,GAC7CA,EAAQ6P,mBACD,CAAClJ,EAAM6I,kBAoBd,OAjBM7E,EAAO/K,EAAc,OAAQE,EAAMC,EAAWC,GAC9C+H,EACFnI,EAAc,QAASE,EAAMC,EAAWC,GACtC0L,GACF9L,EAAc,eAAgBE,EAAMC,EAAWC,GAC7C4L,EACFhM,EAAc,cAAeE,EAAMC,EAAWC,GAC5C6L,EACFjM,EAAc,iBAAkBE,EAAMC,EAAWC,GAC/C2L,EACF/L,EAAc,yBAA0BE,EAAMC,EAAWC,GAEvD8P,EAAOlQ,EAAc,OAAQE,EAAMC,EAAWC,GAC9C+P,EAAc,IAAI9D,EACpB6D,EAAM/H,EAAO4C,EAAMe,GAAcC,EAAwBC,EACzDC,GACJ7L,EAAQgQ,eAAeD,MAChB,CAACA,EAAYjE,SAAUC,SAAO,aAUrC,OAPMG,EAAKtM,EAAc,gBAAiBE,EAAMC,EAAWC,GAErDyB,EAAQ7B,EAAc,QAASE,EAAMC,EAAWC,GAChDiQ,GACFrQ,EAAc,SAAUE,EAAMC,EAAWC,IACvCkQ,EAAmBlQ,EAAQmQ,eAAejE,EAAGA,KAClCU,MAAMnL,EAAOwO,OACvB,CAACC,EAAiBpE,mBAQzB,OALMsE,EAASxQ,EAAc,gBAAiBE,EAAMC,EAAWC,GAEzDqQ,EACFzQ,EAAc,QAASE,EAAMC,EAAWC,MAErC,CADiBA,EAAQmQ,eAAeC,EAAOlE,IAC9BM,KAAK6D,aAW7B,OARMC,EACF1Q,EAAc,gBAAiBE,EAAMC,EAAWC,GAE9CuQ,EACF3Q,EAAc,UAAWE,EAAMC,EAAWC,GACxCwQ,EACF5Q,EAAc,QAASE,EAAMC,EAAWC,MAErC,CADmBA,EAAQmQ,eAAeG,EAASpE,IAChCuE,OAAOF,EAAeC,aAYhD,OATME,EACF9Q,EAAc,gBAAiBE,EAAMC,EAAWC,GAE9C2Q,EACF/Q,EAAc,UAAWE,EAAMC,EAAWC,GACxC4Q,EACFhR,EAAc,SAAUE,EAAMC,EAAWC,IACvC6Q,EAAqB7Q,EAAQmQ,eAAeO,EAAUxE,KACzC4E,QAAQH,EAAgBC,MACpC,CAACC,EAAmB/E,mBAS3B,OANMiF,GACFnR,EAAc,gBAAiBE,EAAMC,EAAWC,GAE9CgR,EAAoBhR,EAAQmQ,eAAeY,GAAS7E,IACpD+E,GACFrR,EAAc,QAASE,EAAMC,EAAWC,MACrC,CAACgR,EAAkB5M,OAAO6M,cAYjC,OATMC,EACFtR,EAAc,gBAAiBE,EAAMC,EAAWC,GAE9CmR,GACFvR,EAAc,SAAUE,EAAMC,EAAWC,GACvCoR,GACFxR,EAAc,UAAWE,EAAMC,EAAWC,IACxCqR,EAAmBrR,EAAQmQ,eAAee,EAAQhF,KACvC/J,MAAMiP,GAASD,OACzB,CAACE,EAAiBvF,mBAMzB,OAHMwF,EAAS1R,EAAc,gBAAiBE,EAAMC,EAAWC,GAEzDuR,EAAkBvR,EAAQmQ,eAAemB,EAAOpF,OAC/C,CAACH,SAAOwF,EAAgB5G,OAAQ,mBAQvC,OALM6G,EACF5R,EAAc,gBAAiBE,EAAMC,EAAWC,IAE9CyR,EAAmBzR,EAAQmQ,eAAeqB,EAAQtF,KACvCwF,mBACV,CAACD,EAAiB3F,mBAUzB,OAPMA,GACFlM,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CyB,EAAQ7B,EAAc,QAASE,EAAMC,EAAWC,GAChDiQ,GACFrQ,EAAc,SAAUE,EAAMC,EAAWC,IACvC2R,GAAa3R,EAAQ4R,cAAc9F,GAASI,KACvC2F,QAAQpQ,EAAOwO,OACnB,CAAC0B,GAAW7F,mBAcnB,OAXMA,GACFlM,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CqQ,EACFzQ,EAAc,QAASE,EAAMC,EAAWC,GACtC0L,GACF9L,EAAc,eAAgBE,EAAMC,EAAWC,GAE7C8R,GACFlS,EAAc,eAAgBE,EAAMC,EAAWC,MAG5C,EADD2R,GAAa3R,EAAQ4R,cAAc9F,GAASI,KAC/B6F,QAAQ1B,EAAW3E,GAAcoG,cAepD,OAXMnB,EACF/Q,EAAc,UAAWE,EAAMC,EAAWC,GACxC4Q,EACFhR,EAAc,SAAUE,EAAMC,EAAWC,GACvC0L,GACF9L,EAAc,eAAgBE,EAAMC,EAAWC,GAC7C+N,EACFnO,EAAc,cAAeE,EAAMC,EAAWC,GAC5C2R,YDoDR9Q,EAAgB4L,EAAmBf,EACnCqC,GACF,GAAItB,EAAQrK,SAAWvB,EAAOK,MAAM,GAClC,MAAM,IAAIwG,MAAM,sDACZ+E,EAAQrK,eAAcvB,EAAOK,MAAM,IAGzC,IAAM6L,EAAWC,KAAKC,UAALD,KAAYP,GAE7B,GAAmB,MAAfsB,IAAwC,IAAjBA,GAAsBhB,GAAYgB,EAC3D,MAAM,IAAIrG,MACN,mCAAmCqF,WAAiBgB,OAG1D,IAAMzD,EAAO,IAAIwD,EAAW,GAAIpC,EAAc7K,EAAOkH,MAAOgG,GACtD3B,EAAUe,UAAQtM,EAAQ,GAIhC,OAHA4L,EAAQ5G,SAAQ,SAACxE,EAAOI,GACtB6I,EAAKuH,QAAQxQ,EAAO+K,EAAQ3K,OAEvB6I,ECtECwG,CAAQF,EAAeD,EAAgBjF,GAAcqC,GACzD/N,EAAQgS,cAAcL,OACf,CAACA,GAAW7F,mBAYnB,OATMJ,GACF9L,EAAc,eAAgBE,EAAMC,EAAWC,GAC7C4N,GACFhO,EAAc,eAAgBE,EAAMC,EAAWC,GAE7C+N,EACFnO,EAAc,cAAeE,EAAMC,EAAWC,GAC5C2R,YD2BRjG,EAAwBkC,EAAwBG,GAClD,OAAO,IAAID,EAAW,GAAIpC,EAAckC,EAAcG,GC5B/BkE,CAAQvG,GAAckC,GAAcG,GACvD/N,EAAQgS,cAAcL,OACf,CAACA,GAAW7F,mBAanB,OAVMwE,EACF1Q,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CuQ,EACF3Q,EAAc,UAAWE,EAAMC,EAAWC,GACxC0L,GACF9L,EAAc,eAAgBE,EAAMC,EAAWC,GAC7C4N,GACFhO,EAAc,eAAgBE,EAAMC,EAAWC,MAG5C,EADD2R,GAAa3R,EAAQ4R,cAActB,EAASpE,KAC/BuE,OAAOF,EAAe3C,GAAclC,cAavD,OAVMI,GACFlM,EAAc,eAAgBE,EAAMC,EAAWC,GAC7C0L,GACF9L,EAAc,eAAgBE,EAAMC,EAAWC,GAC7C4N,GACFhO,EAAc,eAAgBE,EAAMC,EAAWC,GAE7C+N,EACFnO,EAAc,cAAeE,EAAMC,EAAWC,MAE3C,EADD2R,GAAa3R,EAAQ4R,cAAc9F,GAASI,KAC/BY,MAAMpB,GAAckC,GAAcG,aAYrD,OATMlN,EACFjB,EAAc,SAAUE,EAAMC,EAAWC,GACvC0L,GACF9L,EAAc,eAAgBE,EAAMC,EAAWC,GAC7C4N,GACFhO,EAAc,eAAgBE,EAAMC,EAAWC,GAE7C2R,YDpCR9Q,EAAgB6K,EAAwBkC,GAC1C,IAAM7F,EAAQlH,EAAOkH,MACrB,GAAIlH,EAAOK,MAAMkB,OAAS,EACxB,MAAM,IAAIsF,MACN,oDAAoD7G,EAAOK,OAEjE,GAAIL,EAAOkH,QAAU6F,EACnB,MAAM,IAAIlG,MAAM,mCACZ7G,EAAOkH,6BAA4B6F,GAGzC5C,EADoBnK,EAAOK,MAAMP,MAAM,GAEtB+K,EAAc,+BAE/B,IAAMiG,EAAuB9Q,EAAOsM,UACpC,OAAO,IAAIW,EAAW6D,EAAYjG,EAAc3D,GCqBzBmK,CAAWrR,EAAQ6K,GAAckC,IACpD5N,EAAQgS,cAAcL,OACf,CAACA,GAAW7F,mBAUnB,OAPMiF,GACFnR,EAAc,eAAgBE,EAAMC,EAAWC,GAC7C2R,GAAa3R,EAAQ4R,cAAcb,GAAS7E,IAC5C+E,GACFrR,EAAc,QAASE,EAAMC,EAAWC,GACtC0L,GACF9L,EAAc,eAAgBE,EAAMC,EAAWC,MAC5C,CAAC2R,GAAWvN,OAAO6M,GAAavF,cASvC,OANMI,GACFlM,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CiQ,GACFrQ,EAAc,SAAUE,EAAMC,EAAWC,IACvC2R,GAAa3R,EAAQ4R,cAAc9F,GAASI,KACvCiG,SAASlC,OACb,CAAC0B,GAAW7F,mBAWnB,OARMA,GACFlM,EAAc,eAAgBE,EAAMC,EAAWC,GAC7C0L,GACF9L,EAAc,eAAgBE,EAAMC,EAAWC,GAC7C8R,GACFlS,EAAc,eAAgBE,EAAMC,EAAWC,MAG5C,EADD2R,GAAa3R,EAAQ4R,cAAc9F,GAASI,KAC/BkG,QAAQ1G,GAAcoG,cAYzC,OATMX,GACFvR,EAAc,SAAUE,EAAMC,EAAWC,GACvC0L,GACF9L,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CoR,GACFxR,EAAc,UAAWE,EAAMC,EAAWC,GAExC2R,YDXR9Q,EAAgBuB,EAAkBsJ,GACpC,IAAI0B,EAAc,EACZC,EAAoBjL,EAAOxB,KAAI,SAAA0M,GAEnC,OADAF,GAAeE,KAIjB,GAAIF,IAAgBvM,EAAOK,MAAM,GAC/B,MAAM,IAAIwG,MAAM,qGAEV0F,8BAAuCvM,EAAOK,OAmBtD,IAhBA,IAAMqM,EAAgC,IAAhBH,EAAoB,EAAIvM,EAAO8J,KAAOyC,EACtDhB,EAAoBoB,QAAK,WAC7B,IAAMpB,EAAU,GAChBvL,EAASA,EAAO4M,QAAQ,CAAC,EAAGL,EAAaG,IACzC,IAAK,IAAI9K,EAAI,EAAGA,EAAIL,EAAOA,SAAUK,EAAG,CACtC,IACMgK,EAAU,CAAC,EADa,IAANhK,EAAW,EAAI4K,EAAkB5K,EAAI,GACzB,GAC9BkL,EAAQ,CAAC,EAAGvL,EAAOK,GAAI8K,GAC7BnB,EAAQ3J,GAAK9B,QAAME,EAAQ4L,EAASkB,GAAOF,QAAQ/B,GAGrD,OADA7K,EAAOwL,UACAD,KAGH9B,EAAO,IAAIwD,EAAW,GAAIpC,EAAc7K,EAAOkH,MAAO3F,EAAOA,QAE1DK,EAAI,EAAGA,EAAI2J,EAAQhK,OAAQK,IAClC6H,EAAKuH,QAAQpP,EAAG2J,EAAQ3J,IAE1B,OAAO6H,ECrBgBnI,CAAMgP,GAAaC,GAAS1F,IAC/C1L,EAAQgS,cAAcL,OACf,CAACA,GAAW7F,mBAGnB,MAAMuG,UAAU,aAAavS,EAAKuE,2CCxUxB8J,EACZrO,EAAYC,EACZC,GACF,IAAMqB,EACF,SAAEvB,EAAYC,EAA4BC,GACxC,OAAQF,EAAK6C,UACX,IAAK,aACH,OAAO2P,QACH,WAAM,OC9BuB,SAACxS,EACFC,EACAC,GAE1C,OAAQF,EAAKuE,IACX,IAAK,UACL,IAAK,QACL,IAAK,MACH,MAAO,CAACkO,MACH3S,EAAc,IAAKE,EAAMC,EAAWC,GACrCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,MAAO,CAACwS,OACJ5S,EAAc,UAAWE,EAAMC,EAAWC,KAEhD,IAAK,WACL,IAAK,MACH,MAAO,CAACyS,MACJ7S,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,MACH,MAAO,CAAC0S,MACJ9S,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,UACL,IAAK,MACH,MAAO,CAAC2S,MACJ/S,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,WACH,MAAO,CAAC4S,WACJhT,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,WACH,MAAO,CAAC6S,WACJjT,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,MACH,MAAO,CAAC8S,MACJlT,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,UACH,MAAO,CAAC+S,UACJnT,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,UACH,MAAO,CAACgT,UACJpT,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,MACH,MAAO,CAACiT,MACJrT,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,oBACH,MAAO,CAACkT,oBACJtT,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,QACE,MAAMqS,UAAU,aAAavS,EAAKuE,2BDrClB8O,CAAqBrT,EAAMC,EAAWC,MAClD,IAAK,aACH,OAAOsS,QACH,WAAM,OEjCuB,SAACxS,EACFC,EACAC,GAE1C,OAAQF,EAAKuE,IACX,IAAK,MACL,IAAK,aACH,MAAO,CAAC+O,MACJxT,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,OACH,MAAO,CAACqT,OACJzT,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,MAAO,CAACsT,QACJ1T,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,OACH,MAAO,CAACuT,OACJ3T,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,MAAO,CAACwT,QACJ5T,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,OACH,MAAO,CAACyT,OACJ7T,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,MAAO,CAAC0T,QACJ9T,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,MAAO,CAAC2T,QACJ/T,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,OACH,MAAO,CAAC4T,OACJhU,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,UACH,MAAO,CAAC6T,UACJjU,EAAc,OAAQE,EAAMC,EAAWC,GACvCJ,EAAc,OAAQE,EAAMC,EAAWC,KAC7C,IAAK,MACH,MAAO,CAAC8T,MACJlU,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,OACH,MAAO,CAAC+T,OACJnU,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,MACH,MAAO,CAACgU,MACJpU,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,MACH,MAAO,CAACiU,MACJrU,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,MACH,MAAO,CAACkU,MACJtU,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,MAAO,CAACmU,QACJvU,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,QACH,MAAO,CAACoU,QACJxU,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,MACH,MAAO,CAACqU,MACJzU,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,MAAO,CAACsU,QACJ1U,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,MAAO,CAACuU,OACJ3U,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,MACH,MAAO,CAACwU,MACJ5U,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,aACH,MAAO,CAACyU,aACJ7U,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,MAAO,CAAC0U,OACJ9U,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,OACH,MAAO,CAAC2U,OACJ/U,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,MAAO,CAAC4U,QACJhV,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,MAAO,CAAC6U,OACJjV,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,UACH,MAAO,CAAC8U,UACJlV,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,MACH,MAAO,CAAC+U,MACJnV,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,OACH,MAAO,CAACgV,OACJpV,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,MAAO,CAACiV,OACJrV,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,WACH,MAAO,CAACkV,WACJtV,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,MAAO,CAACmV,OACJvV,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,SACH,MAAO,CAACoV,SACJxV,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,MAAO,CAACqV,OACJzV,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,MACH,MAAO,CAACsV,MACJ1V,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACL,IAAK,cACH,MAAO,CAACuV,cACJ3V,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,eAAgBE,EAAMC,EAAWC,GAC/CJ,EAAc,eAAgBE,EAAMC,EAAWC,KACrD,IAAK,QACH,MAAO,CAACwV,QAAU/U,EAAUX,EAAKY,WAAW,GAAIX,EAAWC,KAC7D,IAAK,OACH,MAAO,CAACyV,OACJ7V,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,OAAQE,EAAMC,EAAWC,KAC7C,IAAK,YACH,MAAO,CAAC0V,YACJ9V,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,QAASE,EAAMC,EAAWC,KAC9C,IAAK,QACH,MAAO,CAAC2V,QACJ/V,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,QAASE,EAAMC,EAAWC,KAC9C,QACE,MAAMqS,UAAU,aAAavS,EAAKuE,2BFhHlBuR,CAAoB9V,EAAMC,EAAWC,MACjD,IAAK,UACH,OAAO6V,EAAkB/V,EAAMC,EAAWC,GAC5C,IAAK,cACH,OAAOsS,QACH,WAAM,OGtCuB,SAACxS,EACAC,EACAC,GAE5C,OAAQF,EAAKuE,IACX,IAAK,SACH,IAAMyR,EACFlW,EAAc,SAAUE,EAAMC,EAAWC,GACvCuC,EAAM3C,EAAc,MAAOE,EAAMC,EAAWC,GAC5C+V,EACDnW,EAAc,aAAcE,EAAMC,EAAWC,GACzCgW,cACHC,EACFrW,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,MAAO,CAACkW,SACJtW,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,SAAUE,EAAMC,EAAWC,GACzC8V,EAAQvT,EAAyBwT,EACjCE,IAEN,IAAK,SACGH,EACFlW,EAAc,UAAWE,EAAMC,EAAWC,GACxCuC,EAAMD,EAAWxC,EAAMC,EAAWC,GAClC+V,EACDnW,EAAc,aAAcE,EAAMC,EAAWC,GACzCgW,cALT,IAMMG,EACFvW,EAAc,YAAaE,EAAMC,EAAWC,GAChD,MAAO,CAACoW,SACJxW,EAAc,IAAKE,EAAMC,EAAWC,GAEpCJ,EAAc,SAAUE,EAAMC,EAAWC,GACzC,CAAC8V,EAAO,GAAIA,EAAO,IAAKvT,EACxBwT,EAA+B,CAACI,EAAU,GAAIA,EAAU,MAE9D,IAAK,eACL,IAAK,6BACG,IAAA5U,sBAAC8U,OAASC,OAGVC,EAAwB,YAAZF,EACZG,EAA6B,UAAnBF,EACVG,EAA0B,mBAAZJ,EAEdK,EACD9W,EAAc,UAAWE,EAAMC,EAAWC,GAC/C,GAAIuW,EAAW,CACb,GAAIC,GAAuB,IAAZE,EACb,MAAM,IAAIhP,MACN,yGAGN,IAAK8O,GAAuB,IAAZE,EACd,MAAM,IAAIhP,MACN,oFAIR,GAAI+O,EACF,MAAM,IAAI/O,MACN,yEAEAoO,EACFlW,EAAc,UAAWE,EAAMC,EAAWC,GACxCuC,EAAMD,EAAWxC,EAAMC,EAAWC,GAClC+V,EACDnW,EAAc,aAAcE,EAAMC,EAAWC,GACzCgW,cACHG,EACFvW,EAAc,YAAaE,EAAMC,EAAWC,GAPhD,IAQMyO,kBAACkI,OAASC,OAKhB,MAAO,EAH0B,iBAAZ9W,EAAKuE,GACtBwS,QAAUC,OACVD,QAAUE,iBACO,CACnBC,EAAGpX,EAAc,IAAKE,EAAMC,EAAWC,GAEvCiX,OAAQrX,EAAc,SAAUE,EAAMC,EAAWC,GAEjDkX,QAAS,CAACpB,EAAO,GAAIA,EAAO,IAC5BvT,IAAKA,EACLwT,WAAYA,EACZI,UAAW,CAACA,EAAU,GAAIA,EAAU,IACpCgB,KAAMR,EACNS,WAAYd,EACZe,uBAAwBT,KAG5B,IAAK,sBACL,IAAK,kBACH,IAAM1V,EAAQtB,EACI,cAAeE,EAAMC,EACrBC,GAEZ8V,EACFlW,EAAc,UAAWE,EAAMC,EAAWC,GACxCuC,EAAMD,EAAWxC,EAAMC,EAAWC,GACxC,MAAO,CAACsX,kBACJ1X,EAAc,IAAKE,EAAMC,EAAWC,GAEpCJ,EAAc,SAAUE,EAAMC,EAAWC,GACzCkB,EAAO,CAAC4U,EAAO,GAAIA,EAAO,IAAKvT,IAErC,IAAK,wBACL,IAAK,kBACGuT,EACFlW,EAAc,UAAWE,EAAMC,EAAWC,GACxCuC,EAAMD,EAAWxC,EAAMC,EAAWC,GAClCmW,EACFvW,EAAc,YAAaE,EAAMC,EAAWC,GAC1C+V,EACDnW,EAAc,aAAcE,EAAMC,EAAWC,GACzCgW,cAET,MAAO,CAACuB,kBACJ3X,EAAc,QAASE,EAAMC,EAAWC,GAExCJ,EAAc,SAAUE,EAAMC,EAAWC,GACzC,CAAC8V,EAAO,GAAIA,EAAO,IAAKvT,EACxBwT,EAA+B,CAACI,EAAU,GAAIA,EAAU,MAE9D,IAAK,SACGL,EACFlW,EAAc,UAAWE,EAAMC,EAAWC,GACxCuC,EAAM3C,EAAc,MAAOE,EAAMC,EAAWC,GAC5C+V,EACDnW,EAAc,aAAcE,EAAMC,EAAWC,GACzCgW,cACHG,EACFvW,EAAc,YAAaE,EAAMC,EAAWC,GAChD,MAAO,CAACwX,SACJ5X,EAAc,IAAKE,EAAMC,EAAWC,GAEpCJ,EAAc,SAAUE,EAAMC,EAAWC,GAEzC,CAAC8V,EAAO,GAAIA,EAAO,GAAIA,EAAO,IAAKvT,EACnCwT,EACA,CAACI,EAAU,GAAIA,EAAU,GAAIA,EAAU,MAE7C,IAAK,UACGL,EACFlW,EAAc,UAAWE,EAAMC,EAAWC,GACxCuC,EAAM3C,EAAc,MAAOE,EAAMC,EAAWC,GAFlD,IAGMyX,EACF7X,EAAc,aAAcE,EAAMC,EAAWC,GAEjD,MAAO,CAAC0X,UACJ9X,EAAc,IAAKE,EAAMC,EAAWC,GAEpC,CAACyX,EAAW,GAAIA,EAAW,IAAK,CAAC3B,EAAO,GAAIA,EAAO,IACnDvT,IAEN,IAAK,UACGuT,EACFlW,EAAc,UAAWE,EAAMC,EAAWC,GACxCuC,EAAM3C,EAAc,MAAOE,EAAMC,EAAWC,GAC5CyX,EACF7X,EAAc,aAAcE,EAAMC,EAAWC,GAEjD,MAAO,CAAC2X,UACJ/X,EAAc,IAAKE,EAAMC,EAAWC,GAEpC,CAACyX,EAAW,GAAIA,EAAW,IAAK,CAAC3B,EAAO,GAAIA,EAAO,IACnDvT,IAEN,IAAK,oBACGuT,EACFlW,EAAc,UAAWE,EAAMC,EAAWC,GACxCuC,EAAM3C,EAAc,MAAOE,EAAMC,EAAWC,GAC5CyX,EACF7X,EAAc,aAAcE,EAAMC,EAAWC,GAJjD,IAKM4X,EACFhY,EAAc,sBAAuBE,EAAMC,EAAWC,GAEpD6X,gEAIN,MAAO,qBAET,IAAK,YACG/B,EACFlW,EAAc,UAAWE,EAAMC,EAAWC,GACxCuC,EAAM3C,EAAc,MAAOE,EAAMC,EAAWC,GAC5CyX,EACF7X,EAAc,aAAcE,EAAMC,EAAWC,GAEjD,MAAO,CAAC8X,YACJlY,EAAc,IAAKE,EAAMC,EAAWC,GACpC,CAACyX,EAAW,GAAIA,EAAW,GAAIA,EAAW,IAC1C,CAAC3B,EAAO,GAAIA,EAAO,GAAIA,EAAO,IAAKvT,IAGzC,IAAK,YACGuT,EACFlW,EAAc,UAAWE,EAAMC,EAAWC,GACxCuC,EAAM3C,EAAc,MAAOE,EAAMC,EAAWC,GAC5CyX,EACF7X,EAAc,aAAcE,EAAMC,EAAWC,GAEjD,MAAO,CAAC+X,YACJnY,EAAc,IAAKE,EAAMC,EAAWC,GACpC,CAACyX,EAAW,GAAIA,EAAW,GAAIA,EAAW,IAC1C,CAAC3B,EAAO,GAAIA,EAAO,GAAIA,EAAO,IAAKvT,IAGzC,IAAK,aACH,IAAM2U,EACFtX,EAAc,UAAWE,EAAMC,EAAWC,GAMxCgY,GALAzV,EAAM3C,EAAc,MAAOE,EAAMC,EAAWC,GAC5CmW,EACFvW,EAAc,YAAaE,EAAMC,EAAWC,GAG3BkX,EAAQ,IACvBe,EAAcf,EAAQ,GAGtBgB,EAAiB/B,EAAU,GAC3BgC,EAAgBhC,EAAU,GAEhC,MAAO,CAACiC,aACJxY,EAAc,IAAKE,EAAMC,EAAWC,GAEpCJ,EAAc,SAAUE,EAAMC,EAAWC,GACzC,CAACgY,EAAcC,GAAc1V,EAC7B,CAAC2V,EAAgBC,GAAgB,SAGvC,QACE,MAAM9F,UAAU,aAAavS,EAAKuE,2BHlMlBgU,CAAsBvY,EAAMC,EAAWC,MACnD,IAAK,WACH,OAAOsS,QAAS,WAAM,OIxCW,SAACxS,EACFC,EACAC,GAE1C,OAAQF,EAAKuE,IACX,IAAK,OACH,IAAMnD,EACFtB,EAAc,QAASE,EAAMC,EAAWC,GACtC+H,EACFnI,EAAc,QAASE,EAAMC,EAAWC,GACtCqB,EAAQzB,EAAc,QAASE,EAAMC,EAAWC,GACtD,MAAO,CAACsY,OAASpX,EAAOG,EAAO0G,IAEjC,IAAK,WACH,IAAM1H,EAAQT,EAAc,QAASE,EAAMC,EAAWC,GAChDuY,EAAO3Y,EAAc,OAAQE,EAAMC,EAAWC,GAC9CwY,EAAM5Y,EAAc,MAAOE,EAAMC,EAAWC,GAClD,MAAO,CAACyY,WAAapY,EAAOkY,EAAMC,IAEpC,IAAK,cACH,IAAME,EACF9Y,EAAc,SAAUE,EAAMC,EAAWC,GACvC2Y,EACF/Y,EAAc,aAAcE,EAAMC,EAAWC,GAC3C4Y,EAAOhZ,EAAc,OAAQE,EAAMC,EAAWC,GACpD,MAAO,CAAC6Y,cAAgBH,EAAQC,EAAYC,IAE9C,IAAK,SACH,IAAMnM,EACF7M,EAAc,UAAWE,EAAMC,EAAWC,GACxC8Y,EAAQlZ,EAAc,QAASE,EAAMC,EAAWC,GAChD+Y,EACFnZ,EAAc,UAAWE,EAAMC,EAAWC,GACxCgZ,EACFpZ,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,MAAO,CAACiZ,SAAWxM,EAASqM,EAAOC,EAASC,IAE9C,IAAK,OACH,MAAO,CAACE,OACJtZ,EAAc,QAASE,EAAMC,EAAWC,GACxCJ,EAAc,QAASE,EAAMC,EAAWC,KAE9C,IAAK,WACH,MAAO,CAACmZ,WACJvZ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,gBACH,MAAO,CAACoZ,gBAEJxZ,EAAc,QAASE,EAAMC,EAAWC,GACxCJ,EAAc,SAAUE,EAAMC,EAAWC,GACzCJ,EAAc,SAAUE,EAAMC,EAAWC,GACzCJ,EAAc,QAASE,EAAMC,EAAWC,KAE9C,IAAK,QACGK,EAAQT,EAAc,QAASE,EAAMC,EAAWC,GAAtD,IACMqZ,EAAOzZ,EAAc,OAAQE,EAAMC,EAAWC,GAC9CsZ,EAAO1Z,EAAc,OAAQE,EAAMC,EAAWC,GACpD,MAAO,CAACuZ,QACJlZ,EAAOgZ,EAAMC,EACb1Z,EAAc,QAASE,EAAMC,EAAWC,KAG9C,IAAK,kBACGkB,EACFtB,EAAc,QAASE,EAAMC,EAAWC,GAD5C,IAEMwZ,EAAO5Z,EAAc,OAAQE,EAAMC,EAAWC,GAC9CyZ,EACF7Z,EAAc,SAAUE,EAAMC,EAAWC,GACvC4Y,EAAOhZ,EAAc,OAAQE,EAAMC,EAAWC,GACpD,MAAO,CAAC0Z,kBACJxY,EAAOsY,EAAMC,EACb7Z,EAAc,QAASE,EAAMC,EAAWC,GAExC4Y,IAEN,IAAK,QACH,MAAO,CAACe,QACJ/Z,EAAc,QAASE,EAAMC,EAAWC,GACxCJ,EAAc,QAASE,EAAMC,EAAWC,KAE9C,IAAK,YACH,MAAO,CAAC4Z,YACJha,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,QACE,MAAMqS,UAAU,aAAavS,EAAKuE,2BJ9CNwV,CAAmB/Z,EAAMC,EAAWC,MAC5D,IAAK,UACH,OK1CsC,SAC9CF,EAAYC,EACZC,4HACMF,EAAKuE,QACN,0BACA,0BACA,0BACA,sBAAA,gBAuCA,QAAA,gBAQA,WAAA,uCA9CGyV,EACFla,EAAc,QAASE,EAAMC,EAAWC,GACtC+Z,EACFna,EAAc,SAAUE,EAAMC,EAAWC,GACvCga,EACFpa,EAAc,gBAAiBE,EAAMC,EAAWC,GAC9Cia,EACFra,EAAc,eAAgBE,EAAMC,EAAWC,GAC7Cka,EACFta,EAAc,iBAAkBE,EAAMC,EAAWC,GAErC,wBAAZF,EAAKuE,UACD8V,EACFva,EAAc,eAAgBE,EAAMC,EAAWC,MAE9Boa,QAAUC,gCAC3BP,EAAuBC,EAAwBC,EAC/CC,EAAcC,EAAgBC,YAElC,SAAO,EAJD/K,EAASX,UAIA6L,gBAAiBlL,EAAOmL,8BAGzB,wBAAZza,EAAKuE,UACDmW,EACF5a,EAAc,qBAAsBE,EAAMC,EAAWC,MAGpCoa,QAAUK,6BAC3BX,EAAuBC,EAAwBC,EAC/CC,EAAcC,EAAgBM,YAElC,SAAO,EAJDpL,EAASX,UAIA6L,gBAAiBlL,EAAOsL,sBAGjC,SAAMN,QAAUO,uBACpBb,EAAuBC,EAAwBC,EAC/CC,EAAcC,WAFlB,UAAQzL,kBAQQ,OAHVmM,EACDhb,EAAc,YAAaE,EAAMC,EAAWC,GACxC6a,OAAO,WACMC,aAAeF,WAErC,OAFMxL,GAAUX,UAChBmM,EAAUvO,aACH+C,UAGP,SAAO2L,iBACHnb,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,aAGxC,MAAMqS,UAAU,aAAavS,EAAKuE,iCLlBrB2W,CAAkBlb,EAAMC,EAAWC,GAC5C,IAAK,aACH,OAAOsS,QACH,WAAM,OM5ClB,SAACxS,EAAYC,EACZC,GACC,OAAQF,EAAKuE,IACX,IAAK,SACH,IAAM2S,EAAIpX,EAAc,IAAKE,EAAMC,EAAWC,GACxCib,EAAIrb,EAAc,IAAKE,EAAMC,EAAWC,GACxCkb,EACFtb,EAAc,SAAUE,EAAMC,EAAWC,GACvCoP,EAAS+L,OAASnE,EAAGiE,EAAGC,GAC9B,MAAO,CAAC9L,EAAOgM,OAAQhM,EAAO3C,SAEhC,QACE,MAAM4F,UAAU,aAAavS,EAAKuE,2BNgCtBgX,CAAqBvb,EAAMC,EAAWC,MAClD,IAAK,QACH,OAAOsS,QAAS,WAAM,OO/CW,SAACxS,EACAC,EACAC,GAE5C,OAAQF,EAAKuE,IACX,IAAK,iBACH,IAAMiX,EACF1b,EAAc,SAAUE,EAAMC,EAAWC,GACvC2K,EAAO/K,EAAc,OAAQE,EAAMC,EAAWC,GAC9Cub,EACF3b,EAAc,eAAgBE,EAAMC,EAAWC,GACnD,MAAO,CAACoa,QAAUoB,eACdF,EAAuC,CAAC3Q,EAAK,GAAIA,EAAK,IACtD4Q,IAEN,IAAK,wBACGD,EACF1b,EAAc,SAAUE,EAAMC,EAAWC,GACvC2K,EAAO/K,EAAc,OAAQE,EAAMC,EAAWC,GAC9Cub,EACF3b,EAAc,eAAgBE,EAAMC,EAAWC,GACnD,MAAO,CAACoa,QAAUqB,sBACdH,EAAuC,CAAC3Q,EAAK,GAAIA,EAAK,IACtD4Q,IAEN,IAAK,gBACH,IAAM5X,EACF/D,EAAc,QAASE,EAAMC,EAAWC,GACtC8Z,EACFla,EAAc,QAASE,EAAMC,EAAWC,GACtC0b,EACF9b,EAAc,SAAUE,EAAMC,EAAWC,GACvC2b,EACF/b,EAAc,WAAYE,EAAMC,EAAWC,GACzC4b,EACFhc,EAAc,SAAUE,EAAMC,EAAWC,GACvC6b,EACFjc,EAAc,qBAAsBE,EAAMC,EAAWC,GAEzD,MAAO,CAACoa,QAAU0B,cACdnY,EAAuBmW,EAAuB4B,EAC9CC,EAA8BC,EAC9BC,IAEN,QACE,MAAMxJ,UAAU,aAAavS,EAAKuE,2BPEN0X,CAAgBjc,EAAMC,EAAWC,MACzD,IAAK,QACH,OAAOsS,QAAS,WAAM,OQjDW,SAACxS,EACFC,EACAC,GAE1C,OAAQF,EAAKuE,IACX,IAAK,QACH,OAAOtE,EAAUD,EAAKH,MAExB,IAAK,yBACH,IAAM+J,EACF9J,EAAc,UAAWE,EAAMC,EAAWC,GAC9C,MAAO,CAACS,EAAUX,EAAKH,KAAMI,EAAWC,IAAY0J,GACtD,IAAK,cACH,MAAO,CAACjJ,EAAUX,EAAKH,KAAMI,EAAWC,IAC1C,IAAK,WACL,IAAK,eACL,IAAK,0BACH,MAAO,CACJJ,EAAc,IAAKE,EAAMC,EAAWC,GAAwBwP,SAEjE,IAAK,YACH,OAAQ5P,EAAc,IAAKE,EAAMC,EAAWC,GACvCY,KAAI,SAAC8L,GAAkB,OAAAA,EAAE8C,WAChC,IAAK,WAGH,MAAO,CADF5P,EAAc,IAAKE,EAAMC,EAAWC,GACxBwP,SACnB,IAAK,QACH,MAAO,CAACwM,WACHpc,EAAc,IAAKE,EAAMC,EAAWC,GAAwBkB,MAC7D,UACN,IAAK,SACH,OAAQtB,EAAc,IAAKE,EAAMC,EAAWC,GACvCY,KAAI,SAAC8L,GAAkB,OAAAsP,WAAatP,EAAExL,UAC7C,IAAK,OACH,MAAO,CAAC+a,SACHrc,EAAc,IAAKE,EAAMC,EAAWC,GAAwB2K,KAC7D,UACN,IAAK,OACH,MAAO,CAACsR,SACHrc,EAAc,IAAKE,EAAMC,EAAWC,GAAwBkc,KAC7D,UACN,IAAK,OACH,MAAO,CAACD,SAAW,IACrB,IAAK,QACH,IAAMtV,EAAQ/G,EAAc,IAAKE,EAAMC,EAAWC,GAC5Cc,EACFlB,EAAc,OAAQE,EAAMC,EAAWC,GACrCmc,EACFvc,EAAc,UAAWE,EAAMC,EAAWC,GACxCoc,EACFxc,EAAc,YAAaE,EAAMC,EAAWC,GAChDqc,QAAQC,KACJ,kGAEJD,QAAQE,IAAIJ,GACZ,IAAK,IAAI1Z,EAAI,EAAGA,EAAI3B,EAAKsB,OAAQK,IAC/B4Z,QAAQE,IACJ1T,MAAM2T,UAAU7b,MAAM8b,KAAK3b,EAAK2B,GAAG1B,YAAYJ,MAAM,EAAGyb,IAE9D,MAAO,CAACzV,GAEV,QACE,MAAM0L,UAAU,aAAavS,EAAKuE,2BRdNqY,CAAgB5c,EAAMC,EAAWC,MACzD,IAAK,UACH,OAAOsS,QAAS,WAAM,OSnDW,SAACxS,EACAC,EACAC,GAE5C,OAAQF,EAAKuE,IACX,IAAK,QACH,MAAO,CAACsY,QACJ/c,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,WACH,MAAO,CAAC4c,WACJhd,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,UACH,MAAO,CAAC6c,UACJjd,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,eACH,MAAO,CAAC8c,eACJld,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,MAAO,CAAC+c,OACJnd,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,YACH,MAAO,CAACgd,YACJpd,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,aACH,MAAO,CAACid,aACJrd,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,aACH,MAAO,CAACkd,aACJtd,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,YACH,MAAO,CAACmd,YACJvd,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,SACL,IAAK,WACH,MAAO,CAACod,QACJxd,EAAc,YAAaE,EAAMC,EAAWC,GAC5CJ,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,QACE,MAAMqS,UAAU,aAAavS,EAAKuE,2BTNNgZ,CAAkBvd,EAAMC,EAAWC,MAC3D,IAAK,WACH,OAAOsS,QAAS,WAAM,OUrDW,SAACxS,EACFC,EACAC,GAE1C,OAAQF,EAAKuE,IACX,IAAK,cACL,IAAK,gBACL,IAAK,SACH,MAAO,CAACiZ,SACJ1d,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,aAAcE,EAAMC,EAAWC,GAC7CJ,EAAc,aAAcE,EAAMC,EAAWC,KAEnD,IAAK,YACH,MAAO,CAACud,YACJ3d,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,OAAQE,EAAMC,EAAWC,KAE7C,IAAK,eACG,IAAAuB,sBAAC8U,OAASC,OAGVC,EAAwB,YAAZF,EACZG,EAA6B,UAAnBF,EAEVI,EACD9W,EAAc,UAAWE,EAAMC,EAAWC,GAC/C,GAAIuW,EAAW,CACb,GAAIC,GAAuB,IAAZE,EACb,MAAM,IAAIhP,MACN,sFAGN,IAAK8O,GAAuB,IAAZE,EACd,MAAM,IAAIhP,MACN,iEAGF,IAAA+G,kBAACkI,OAASC,OAEhB,MAAO,CAACC,QAAU2G,OAAO,CACvBC,EAAG7d,EAAc,IAAKE,EAAMC,EAAWC,GACvC2J,EAAG/J,EAAc,IAAKE,EAAMC,EAAWC,GACvC0d,WAAY9d,EAAc,aAAcE,EAAMC,EAAWC,GAEzD2d,WAAY/d,EAAc,aAAcE,EAAMC,EAAWC,GAEzDmX,KAAMR,EACNS,WAAYd,EACZe,uBAAwBT,KAG5B,QACE,MAAMvE,UAAU,aAAavS,EAAKuE,2BVDNuZ,CAAmB9d,EAAMC,EAAWC,MAC5D,IAAK,gBACH,OAAOsS,QACH,WAAM,OWxDuB,SAACxS,EACFC,EACAC,GAE1C,OAAQF,EAAKuE,IACX,IAAK,iBACL,IAAK,mBASL,IAAK,mBACH,MAAO,CAACwZ,YACJje,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,OAAQE,EAAMC,EAAWC,GACvCJ,EAAc,WAAYE,EAAMC,EAAWC,GAC3CJ,EAAc,SAAUE,EAAMC,EAAWC,GACzCJ,EAAc,QAASE,EAAMC,EAAWC,GACxCJ,EAAc,UAAWE,EAAMC,EAAWC,KAEhD,IAAK,MACH,MAAO,CAAC8d,6BACJle,EAAc,IAAKE,EAAMC,EAAWC,GAEpCJ,EAAc,SAAUE,EAAMC,EAAWC,GACzCJ,EAAc,OAAQE,EAAMC,EAAWC,GACvCJ,EAAc,QAASE,EAAMC,EAAWC,GACxCJ,EAAc,OAAQE,EAAMC,EAAWC,KAE7C,IAAK,UACH,MAAO,CAAC+d,UACJne,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,aACH,MAAO,CAACge,aACJpe,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,gBACH,MAAO,CAACie,gBACJre,EAAc,gBAAiBE,EAAMC,EAAWC,GAEhDJ,EAAc,cAAeE,EAAMC,EAAWC,GAC9CJ,EAAc,eAAgBE,EAAMC,EAAWC,GAC/CJ,EAAc,eAAgBE,EAAMC,EAAWC,KAGrD,QACE,MAAMqS,UAAU,aAAavS,EAAKuE,2BXKlB6Z,CAAwBpe,EAAMC,EAAWC,MACrD,IAAK,YACH,OAAOsS,QACH,WAAM,OY3DuB,SAACxS,EACAC,EACAC,GAE5C,OAAQF,EAAKuE,IACX,IAAK,MACH,IAAM8Z,EAAOve,EAAc,OAAQE,EAAMC,EAAWC,GAC9Coe,EACFxe,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,MAAO,CAACqe,MACJze,EAAc,IAAKE,EAAMC,EAAWC,GAAwBme,EAC5DC,IAEN,IAAK,OACGD,EAAOve,EAAc,OAAQE,EAAMC,EAAWC,GAC9Coe,EACFxe,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,MAAO,CAACse,OACJ1e,EAAc,IAAKE,EAAMC,EAAWC,GAAwBme,EAC5DC,IAEN,IAAK,MACGD,EAAOve,EAAc,OAAQE,EAAMC,EAAWC,GAC9Coe,EACFxe,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,MAAO,CAACue,MACJ3e,EAAc,IAAKE,EAAMC,EAAWC,GAAwBme,EAC5DC,IAEN,IAAK,MACGD,EAAOve,EAAc,OAAQE,EAAMC,EAAWC,GAC9Coe,EACFxe,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,MAAO,CAACwe,MACJ5e,EAAc,IAAKE,EAAMC,EAAWC,GAAwBme,EAC5DC,IAEN,IAAK,MACGD,EAAOve,EAAc,OAAQE,EAAMC,EAAWC,GAC9Coe,EACFxe,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,MAAO,CAACye,MACJ7e,EAAc,IAAKE,EAAMC,EAAWC,GAAwBme,EAC5DC,IAEN,IAAK,MACGD,EAAOve,EAAc,OAAQE,EAAMC,EAAWC,GAC9Coe,EACFxe,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,MAAO,CAAC0e,MACJ9e,EAAc,IAAKE,EAAMC,EAAWC,GAAwBme,EAC5DC,IAEN,IAAK,SACGD,EAAOve,EAAc,OAAQE,EAAMC,EAAWC,GACpD,MAAO,CAAC2e,SACJ/e,EAAc,IAAKE,EAAMC,EAAWC,GAAwBme,IAElE,IAAK,SACGA,EAAOve,EAAc,OAAQE,EAAMC,EAAWC,GACpD,MAAO,CAAC4e,SACJhf,EAAc,IAAKE,EAAMC,EAAWC,GAAwBme,IAElE,IAAK,OACGA,EAAOve,EAAc,OAAQE,EAAMC,EAAWC,GAC9Coe,EACFxe,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,MAAO,CAACyV,OACJ7V,EAAc,IAAKE,EAAMC,EAAWC,GAAwBme,EAC5DC,IAEN,IAAK,SACGD,EAAOve,EAAc,OAAQE,EAAMC,EAAWC,GAApD,IACM6e,EACFjf,EAAc,YAAaE,EAAMC,EAAWC,GAC1C8e,EACFlf,EAAc,UAAWE,EAAMC,EAAWC,GAC9C,MAAO,CAAC+e,SACJnf,EAAc,IAAKE,EAAMC,EAAWC,GAAwBme,EAC5DU,EAAWC,IAEjB,QACE,MAAMzM,UAAU,aAAavS,EAAKuE,2BZvBlB2a,CAAoBlf,EAAMC,EAAWC,MACjD,IAAK,aACH,OAAOsS,QACH,WAAM,Oa9DuB,SAACxS,EACAC,EACAC,GAE5C,OAAQF,EAAKuE,IACX,IAAK,WACL,IAAK,SACH,IAAM4a,EAAIrf,EAAc,IAAKE,EAAMC,EAAWC,GACxCme,EAAOve,EAAc,OAAQE,EAAMC,EAAWC,GAChD4C,EACAhD,EAAc,UAAWE,EAAMC,EAAWC,GAE9C,OADA4C,EAASA,EAAOjC,MAAM,EAAGse,GAClB,CAACC,SAAWtc,EAAQub,IAE7B,IAAK,WACL,IAAK,SACGA,EAAOve,EAAc,OAAQE,EAAMC,EAAWC,GAApD,IACM2G,EAAQ/G,EAAc,IAAKE,EAAMC,EAAWC,GAC5CyM,EACF7M,EAAc,UAAWE,EAAMC,EAAWC,GAC9C,MAAO,CAACmf,SAAWxY,EAAO8F,EAAQoO,OAAO,SAAUsD,IAErD,IAAK,YACL,IAAK,UACGA,EAAOve,EAAc,OAAQE,EAAMC,EAAWC,GAC9C2G,EAAQ/G,EAAc,IAAKE,EAAMC,EAAWC,GAClD,MAAO,CAACof,UAAYzY,EAAOwX,IAE7B,IAAK,QAEH,IAAMkB,EAAQzf,EAAc,QAASE,EAAMC,EAAWC,GAEhD2K,EAAO/K,EAAc,OAAQE,EAAMC,EAAWC,GACpD,MAAO,CAACsf,QACJ1f,EAAc,IAAKE,EAAMC,EAAWC,GAAwBqf,EAC5D1U,IAEN,IAAK,eACG0U,EACFzf,EAAc,QAASE,EAAMC,EAAWC,GAD5C,IAEMM,EAAMV,EAAc,MAAOE,EAAMC,EAAWC,GAC5CkX,EACFtX,EAAc,UAAWE,EAAMC,EAAWC,GACxCuf,EACF3f,EAAc,YAAaE,EAAMC,EAAWC,GAC1Cwf,EACF5f,EAAc,UAAWE,EAAMC,EAAWC,GACxCyf,EACF7f,EAAc,eAAgBE,EAAMC,EAAWC,GAC7C0f,EACF9f,EAAc,cAAeE,EAAMC,EAAWC,GAC5C2f,EACF/f,EAAc,iBAAkBE,EAAMC,EAAWC,GAC/Ca,EAASjB,EAAc,IAAKE,EAAMC,EAAWC,GAEnD,MAAO,CAAC4f,eACJ/e,EAAQwe,EAAO/e,EAAK4W,EAASqI,EAAWC,EAASC,EACjDC,EAAaC,IAEnB,IAAK,OACH,OAAOrN,QAAS,WACd,IAAM6L,EAAOve,EAAc,OAAQE,EAAMC,EAAWC,GAC9CoM,EACFxM,EAAc,UAAWE,EAAMC,EAAWC,GAExCkB,EAAQkL,EAAQ,GAAGlL,MACnB2e,EAAgBzT,EAAQ,GAAG0T,UAAU5e,MACrC6e,EAAS3T,EAAQxL,KAAI,SAAAC,GACzB,IAAMmf,EAAYhf,OAASif,YAAYpf,EAAOK,MAAOA,GACrD,IAAK8e,IACAhf,OAASif,YAAYpf,EAAOif,UAAU5e,MAAO2e,GAChD,MAAM,IAAInY,MAAM,0CAElB,OAAOsY,EAAYnf,EAASA,EAAO4M,QAAQvM,MAE7C,MAAO,CAACgf,QAAUH,EAAQ5B,OAG9B,IAAK,SACH,OAAO7L,QAAS,WACd,IAAM6L,EAAOve,EAAc,OAAQE,EAAMC,EAAWC,GAC9Ca,EACFjB,EAAc,SAAUE,EAAMC,EAAWC,GAC7C,OAAOmgB,UAAYtf,EAAQsd,MAG/B,IAAK,OACH,IAAMiC,EAAOxgB,EAAc,OAAQE,EAAMC,EAAWC,GACpD,MAAO,CAACqgB,OACJzgB,EAAc,IAAKE,EAAMC,EAAWC,GAAwBogB,IAElE,IAAK,QACL,IAAK,SACGjC,EAAOve,EAAc,OAAQE,EAAMC,EAAWC,GAApD,IACMsgB,EACF1gB,EAAc,kBAAmBE,EAAMC,EAAWC,GAEhDa,EAASjB,EAAc,IAAKE,EAAMC,EAAWC,GAEnD,OAAOugB,QAAU1f,EAAQyf,EAAiBnC,GAE5C,IAAK,YACG1R,EACF7M,EAAc,UAAWE,EAAMC,EAAWC,GAD9C,IAEMob,EACFxb,EAAc,SAAUE,EAAMC,EAAWC,GACvCkB,EACFtB,EAAc,QAASE,EAAMC,EAAWC,GAC5C,MAAO,CAACwgB,YAAc/T,EAAS2O,EAAQla,IAEzC,IAAK,WACH,IAAM8V,EAAIpX,EAAc,IAAKE,EAAMC,EAAWC,GACxCyM,EACF7M,EAAc,UAAWE,EAAMC,EAAWC,GAC9C,MAAO,CAACygB,WAAazJ,EAAGvK,IAE1B,IAAK,gBACGA,EACF7M,EAAc,gBAAiBE,EAAMC,EAAWC,GAE9CkB,EACFtB,EAAc,cAAeE,EAAMC,EAAWC,GAJlD,IAKM0gB,EACF9gB,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CgD,EACFpD,EAAc,eAAgBE,EAAMC,EAAWC,GACnD,MAAO,CAACie,gBACJxR,EAASiU,EAAcxf,EACvBwf,EAAa3Y,QAAU/E,EAAa+E,MAChC/E,EACAA,EAAa6X,OAAO6F,EAAa3Y,SAE3C,QACE,MAAMsK,UAAU,aAAavS,EAAKuE,2BbvElBsc,CAAoB7gB,EAAMC,EAAWC,MACjD,IAAK,WACH,OAAOsS,QAAS,WAAM,Oc/D9B,SAACxS,EAAYC,EACZC,GACC,OAAQF,EAAKuE,IACX,IAAK,MACH,MAAO,CAACuc,MACJhhB,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,MAAO,CAAC6gB,OACJjhB,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,MAAO,CAAC8gB,OACJlhB,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,QACH,MAAO,CAAC+gB,QACJnhB,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,QACE,MAAMqS,UAAU,aAAavS,EAAKuE,2Bd2CV2c,CAAmBlhB,EAAMC,EAAWC,MAC5D,IAAK,iBACH,OAAOsS,QACH,WAAM,OenEuB,SAACxS,EACAC,EACAC,GAE5C,OAAQF,EAAKuE,IACX,IAAK,OACH,MAAO,CAAC4c,OACJrhB,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,QAASE,EAAMC,EAAWC,KAG9C,IAAK,aACH,IAAMme,EAAOve,EAAc,OAAQE,EAAMC,EAAWC,GACpD,MAAO,CAACkhB,aACJthB,EAAc,IAAKE,EAAMC,EAAWC,GAAwBme,IAElE,IAAK,UACGA,EAAOve,EAAc,OAAQE,EAAMC,EAAWC,GACpD,MAAO,CAACmhB,UACJvhB,EAAc,IAAKE,EAAMC,EAAWC,GAAwBme,IAGlE,IAAK,UACH,MAAO,CAACiD,UACJxhB,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,QAASE,EAAMC,EAAWC,KAE9C,IAAK,QACL,IAAK,MACH,MAAO,CAACqhB,MACJzhB,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,UAAWE,EAAMC,EAAWC,GAE1CJ,EAAc,gBAAiBE,EAAMC,EAAWC,KAEtD,IAAK,iBACH,IAAMshB,EACF1hB,EAAc,aAAcE,EAAMC,EAAWC,GAC3CuhB,EACF3hB,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,MAAO,CAACwhB,iBACJ5hB,EAAc,IAAKE,EAAMC,EAAWC,GACpCshB,EAAYC,IAElB,IAAK,iBACGD,EACF1hB,EAAc,aAAcE,EAAMC,EAAWC,GADjD,IAEMyhB,EACF7hB,EAAc,QAASE,EAAMC,EAAWC,GAC5C,MAAO,CAAC0hB,iBACJ9hB,EAAc,IAAKE,EAAMC,EAAWC,GACpCshB,EAAYG,IAElB,IAAK,eACH,IAAME,EACF/hB,EAAc,YAAaE,EAAMC,EAAWC,GAC1C+V,EACDnW,EAAc,aAAcE,EAAMC,EAAWC,GACrCgW,cAEb,MAAO,CAAC4L,eACJhiB,EAAc,IAAKE,EAAMC,EAAWC,GACpC2hB,EAAW5L,IAEjB,IAAK,cACH,MAAO,CAAC8L,cACJjiB,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,QAASE,EAAMC,EAAWC,KAE9C,QACE,MAAMqS,UAAU,aAAavS,EAAKuE,2BfHlByd,CAAyBhiB,EAAMC,EAAWC,MACtD,IAAK,SACH,IAAM+hB,EAAWriB,EAAgBI,EAAKuE,IACtC,GAAI0d,GAAYA,EAASC,eACvB,OAAOD,EAASC,eACZ,IAAIjX,EAAcjL,EAAMC,EAAWC,IAEvC,MAAMqS,UAAU,aAAavS,EAAKuE,0BAEtC,QACE,MAAMgO,UACF,eAAevS,EAAKuE,GAApB,wIApDV,CAwDGvE,EAAMC,EAAWC,GACxB,OAAIqB,aAAiB4gB,QACZ5gB,EAAM6gB,MAAK,SAACphB,GAAS,MAAA,GAAGsD,OAAOtD,MAEjC,GAAGsD,OAAO/C,GgBvEnB,iBAME,WACa8gB,EACAvT,EACAC,EACAH,gBAHAyT,mBACAvT,mBACAC,mBACAH,MAHAnK,eAAA4d,EACA5d,oBAAAqK,EACArK,mBAAAsK,EACAtK,iBAAAmK,EATLnK,iBAAc,CAAC2H,GAAI,EAAGkW,UAAW,GAAIC,YAAa,GAClD9d,cAAmC,CAACA,KAAK+d,aACzC/d,YAAS,EAQfA,KAAKge,4BAuIT,OApIUC,qBAAR,SAAiBtW,EAAYkW,GAC3B,MAAO,CAAClW,KAAIkW,YAAWC,YAAa,IAQtC1d,sBAAI6d,kCAOJ,WACE,OAAOje,KAAKke,cARd,SAAmBA,GACble,KAAKke,WAAaA,IACpBle,KAAKke,SAAWA,EAChBle,KAAKge,8DAWT5d,sBAAI6d,oCAAJ,WACE,OAAOje,KAAKme,mBAAmB,oCAOjC/d,sBAAI6d,qCAAJ,WACE,OAAOje,KAAKme,oDAGNF,sCAAR,WAEE,IADA,IAAMG,EAAQ,GACLlgB,EAAI,EAAGA,EAAI8B,KAAKke,SAASrgB,OAAS,EAAGK,IAAK,CACjD,IAAMggB,EAAWle,KAAKke,SAAS9hB,MAAM,EAAG4D,KAAKke,SAASrgB,OAASK,GAC/DkgB,EAAMrd,KAAKf,KAAKqe,qBAAqBH,IAEvCE,EAAMrd,KAAK,IACXf,KAAKme,mBAAqBC,GAGpBH,iCAAR,SAA6BC,GAC3B,OAAOA,EACHA,EACK7hB,KACG,SAAAZ,GAAW,OAAgB,IAAfA,EAAQkM,IAAoC,IAAxBlM,EAAQqiB,YACpC,GACGriB,EAAQoiB,cAAapiB,EAAQqiB,eACvCQ,KAAK,KACV,IAONL,uBAAA,SAAW9S,GACLnL,KAAKke,WACPle,KAAKue,SACLve,KAAKke,SAAWle,KAAKke,SAAS9hB,QAC9B4D,KAAKke,SAASnd,KAAKf,KAAKwe,SAASxe,KAAKue,OAAQpT,IAC9CnL,KAAKme,mBAAmBM,QAAQze,KAAKqe,qBAAqBre,KAAKke,aAQnED,sBAAA,WACE,KAAIje,KAAKke,UAAYle,KAAKke,SAASrgB,OAAS,GAK1C,MAAM,IAAIsF,MAAM,2CAJhBnD,KAAKke,SAAWle,KAAKke,SAAS9hB,QAC9B4D,KAAKke,SAASQ,QAAQ,GACtB1e,KAAK5C,kBAAkBuhB,SAU3BV,0BAAA,WACE,KAAIje,KAAKke,UAAYle,KAAKke,SAASrgB,OAAS,GAW1C,MAAM,IAAIsF,MAAM,yDAVhBnD,KAAKke,SAAWle,KAAKke,SAAS9hB,QAC9B4D,KAAKue,SACL,IAAM9iB,EACF2E,OAAOwe,OAAO,GAAI5e,KAAKke,SAASle,KAAKke,SAASrgB,OAAS,IAC3DpC,EAAQqiB,aAAe,EACvBriB,EAAQkM,GAAK3H,KAAKue,OAClBve,KAAKke,SAASQ,QAAQ,EAAG,EAAGjjB,GAC5BuE,KAAKme,mBAAmBO,OACpB,EAAG,EAAG1e,KAAKqe,qBAAqBre,KAAKke,YAM7CD,sBAAA,SAAU7iB,GACR,OAAO4E,KAAK4d,UAAUxiB,IAGxB6iB,2BAAA,SAAezS,GACbxL,KAAKqK,eAAemB,EAAY7D,IAAM6D,GAGxCyS,2BAAA,SAAetW,GACb,OAAO3H,KAAKqK,eAAe1C,IAG7BsW,0BAAA,SAAc7Q,GACZpN,KAAKsK,cAAc8C,EAAWzF,IAAMyF,GAGtC6Q,0BAAA,SAActW,GACZ,OAAO3H,KAAKsK,cAAc3C,IAG5BsW,oBAAA,WACE,IAAK,IAAM1c,KAAOvB,KAAKqK,eACrBrK,KAAKqK,eAAe9I,GAAK4L,gBAG3B,IAAK,IAAM5L,KAAOvB,KAAKsK,cACrBtK,KAAKsK,cAAc/I,GAAK4L,+BC/Id0R,EACZxgB,EAAwB2C,EACxB4c,GAYF,IAXA,IAAMkB,EAAY,IAAIC,IAChBC,EAA0B,GAC5BC,EAAoB,KACpBC,EAAuB,KAIrBC,EAAO,IAAIJ,IACXK,EACFhf,OAAOiB,KAAKhD,GAAQhC,KAAI,SAAAjB,GAAQ,OAAAsC,EAActC,GAAM,MAClDikB,EAAere,UACdqe,EAASxhB,OAAS,GAAG,CAC1B,IAAMtC,EAAO8jB,EAAS3V,OAClB4V,GAAc/jB,IAASgkB,GAAehkB,KACrB,MAAf0jB,IAEFC,GADAD,EAAc1jB,GACWiG,SAASnF,KAAI,SAAAmjB,GAAS,OAAAA,EAAMpkB,QACnCsX,QAAO,SAAAtX,GAAQ,OAAA0jB,EAAUW,IAAIrkB,OAGnD0jB,EAAUY,IAAInkB,EAAKH,MAGS,MAAxBwiB,EAAUriB,EAAKH,SAKwB,IAAvCgkB,EAAexU,QAAQrP,EAAKH,QAGL,IAAvBG,EAAK8C,OAAOR,OAIhBtC,EAAK8C,OAAOiD,SAAQ,SAAAc,GAEd+c,EAAKM,IAAIrd,EAAMhH,QAGnB+jB,EAAKO,IAAItd,EAAMhH,MACfikB,EAASte,KAAKqB,OATd4c,EAAcje,KAAKxF,EAAKH,QAY5B,MAAO,CAACiD,SAAQ2C,UAAS8d,YAAWE,gBAAeC,cAAaC,cA2ClE,IAAMS,GAAmB,CACvB,SAAU,QAAS,QAAS,OAAQ,gBAAiB,cACrD,iBAAkB,KAAM,SAEpBC,GAAoB,CACxB,sBAAuB,sBAAuB,sBAAuB,kBAGvDN,GAAc/jB,GAC5B,OAAOokB,GAAiB/U,QAAQrP,EAAKuE,KAAO,WAG9Byf,GAAehkB,GAC7B,OAAOqkB,GAAkBhV,QAAQrP,EAAKuE,KAAO,EC7G/C,kBAqFE,WAAoBT,EAAsBwgB,GAA1C,WAAoB7f,WAAAX,EAAsBW,YAAA6f,EApFlC7f,iBAAmC,IAAI8f,IACvC9f,gBAA8B,GAK9BA,eAAY,IACZA,gBAAqC,GACrCA,0BAA0D,GA6EhEA,KAAK+f,SAAW1gB,EAAM2B,QACtBhB,KAAKggB,QAAU3gB,EAAMhB,OACrB2B,KAAKigB,WAAa5gB,EAAMkB,UACxBP,KAAKkgB,WAAa7gB,EAAMqC,UAED,MAAnBrC,EAAMqC,WACRtB,OAAOiB,KAAKhC,EAAMqC,WAAWJ,SAAQ,SAAAlG,GACnCwF,EAAKuf,qBAAqB/kB,GACtB,IAAIglB,EAAc/gB,EAAMqC,UAAUtG,GAAOwF,MA8crD,OAjiBER,sBAAIggB,6BAAJ,WACE,OAAOpgB,KAAK6f,OAAS7f,KAAK6f,OAAOQ,UAAYrgB,KAAKsgB,4CAGpDlgB,sBAAIggB,uCAAJ,WACE,OAAOpgB,KAAK6f,OAAS7f,KAAK6f,OAAOU,oBACZvgB,KAAKmgB,sDAG5B/f,sBAAIggB,6BAAJ,WACE,OAAOpgB,KAAK6f,OAAS7f,KAAK6f,OAAOjC,UAAY5d,KAAKwgB,gBAGpD,SAAc5C,GACZ,IAAMyC,EAAYjgB,OAAOiB,KAAKuc,GAAWvhB,KACrC,SAAAkF,GAAO,OAAAqc,EAAUrc,GAAKlF,KAAI,SAAAC,GAAU,OAAAA,EAAOqL,SAC/C3H,KAAKsgB,WAAa,GAAGzgB,aAAH,GAAawgB,GAC/BrgB,KAAKwgB,WAAa5C,mCAGpBxd,sBAAIggB,0BAAJ,WACE,OAAOpgB,KAAKggB,QAAQ3jB,KAAI,SAAAd,GACtB,MAAO,CACLH,KAAMG,EAAKH,KACXuB,MAAOpB,EAAKsB,WAAkB,MAC1BtB,EAAKsB,WAAkB,MAAEC,WACzBlB,EACJ4H,MAAOjI,EAAKsB,WAAkB,MAC1BtB,EAAKsB,WAAkB,MAAEC,WACzBlB,uCAKVwE,sBAAIggB,2BAAJ,WACE,OAAOpgB,KAAK+f,SAAS1jB,KAAI,SAAAd,GACvB,MAAO,CACLH,KAAMG,EAAKH,KACXuB,MAAOpB,EAAKsB,WAAkB,MAC1BtB,EAAKsB,WAAkB,MAAEC,WACzBlB,EACJ4H,MAAOjI,EAAKsB,WAAkB,MAC1BtB,EAAKsB,WAAkB,MAAEC,WACzBlB,uCAKVwE,sBAAIggB,8BAAJ,WACE,OAAOpgB,KAAKggB,QAAQ3jB,KAAI,SAAAd,GAAQ,OAAAA,EAAKkG,cAAgBlG,EAAKH,yCAG5DgF,sBAAIggB,+BAAJ,WACE,OAAOpgB,KAAK+f,SAAS1jB,KAAI,SAACd,GACxB,IAAMH,EAAOG,EAAKkG,cAAgBlG,EAAKH,KACvC,OAAOG,EAAKuI,cAAoB1I,MAAQG,EAAKuI,cAAmB1I,sCAIpEgF,sBAAIggB,6BAAJ,WAAA,WACE,OAAOhgB,OAAOiB,KAAKrB,KAAKkgB,YAAYhgB,QAAO,SAAC7D,EAAKkF,GAE/C,OADAlF,EAAIkF,GAAOX,EAAKsf,WAAW3e,GAAKhB,UACzBlE,IACN,qCAyBG+jB,8BAAR,SAA0B/hB,EAAgB2C,GACxC,IAAMyf,EAAepiB,EAAOhC,KAAI,SAAAd,GAAQ,OAAAA,EAAKH,QAAMslB,OAC7CC,EAAgB3f,EAAQ3E,KAAI,SAAAd,GAAQ,OAAAA,EAAKH,QAAMslB,OACrD,OAAOD,EAAanC,KAAKte,KAAK4gB,WAAa,KACvCD,EAAcrC,KAAKte,KAAK4gB,YAOtBR,oBAAR,SAAgB/hB,EAAwB2C,GACtC,IAAM6f,EAAgBhC,EAAqBxgB,EAAQ2C,EAAShB,KAAK4d,WAC1DoB,kBAAeC,gBAAaC,eACnC,GAAmB,MAAfD,EACF,MAAM,IAAI9b,MACN,qCAAqC8b,EAAY7jB,KAAjD,gCACmB6jB,EAAYnf,GAD/B,4GAGoCof,OAG1C,GAAIF,EAAcnhB,OAAS,EAAG,CAC5B,IAAMijB,EAAW9f,EAAQ3E,KAAI,SAAAqe,GAAK,OAAAA,EAAEtf,QAC9B2lB,EAAU3gB,OAAOiB,KAAKhD,GAC5B,MAAM,IAAI8E,MACN,+BAA+B2d,EAA/B,+BACIC,uCAA4C/B,OAGtD,gBDpEA3f,EAAcue,EACdiD,GACK,IAAA/B,cAAWzgB,WACZghB,EAAmB,GACNjf,OAAOiB,KAAKhD,GACPhC,KAAI,SAAAjB,GAAQ,OAAAsC,EAActC,GAAM,MAChCiB,KAAI,SAAAjB,GAAQ,OAAAiE,EAAMsB,MAAMvF,MACrCkG,SAAQ,SAAAc,GACb0c,EAAUW,IAAIrd,EAAMhH,OACtBikB,EAASte,KAAKqB,MAGlB/C,EAAMqB,QAAQY,SAAQ,SAAA0f,GAChBlC,EAAUW,IAAIuB,EAAO5lB,OACvBikB,EAASte,KAAKigB,MAKlB,IAFA,IAAM7B,EAAO,IAAIJ,IACXkC,EAAuB,GACtB5B,EAASxhB,OAAS,GAAG,CAC1B,IAAMtC,EAAO8jB,EAAS3V,MACtByV,EAAKO,IAAInkB,EAAKH,MACTwiB,EAAUriB,EAAKH,OAClB6lB,EAAalgB,KAAKxF,GAEpBA,EAAKiG,SAASF,SAAQ,SAAAke,IACfL,EAAKM,IAAID,EAAMpkB,OAAS0jB,EAAUW,IAAID,EAAMpkB,OAC7CokB,EAAMnhB,OAAO6iB,OAAM,SAAA9e,GAAS,OAAA+c,EAAKM,IAAIrd,EAAMhH,UAC7CikB,EAASte,KAAKye,MAIpB,OAAOyB,ECoCEE,CACHnhB,KAAKX,MAAOW,KAAK4d,UAAWiD,IAYlCT,oBAAA,SAAQ/hB,EAAwB2C,GAAhC,WACE3C,EAAS2B,KAAKohB,UAAU/iB,GACxB,IAAM+f,EAAQhe,OAAOiB,KAAKhD,GAAQqiB,OAClC1gB,KAAKqhB,YAAYhjB,GACjB2B,KAAKshB,uBAAuBjjB,GAC5B2C,EAAUhB,KAAKuhB,WAAWvgB,GAC1BhB,KAAKwhB,aAAaxgB,GAClB,IAAMygB,EACFrD,EAAM/hB,KAAI,SAAAjB,GAAQ,OAAAwF,EAAKvB,MAAMsB,MAAMjD,EAActC,GAAM,OACrDsmB,EACF1gB,EAAQ3E,KAAI,SAAAjB,GAAQ,OAAAwF,EAAKvB,MAAMsB,MAAMjD,EAActC,GAAM,OACvDumB,EAAiB3hB,KAAK4hB,kBAAkBH,EAAYC,GAEtDT,EAAejhB,KAAK6hB,YAAYC,IAAIH,GACpB,MAAhBV,IACFA,EAAejhB,KAAK+hB,QAAQ1jB,EAAQqjB,GACpC1hB,KAAK6hB,YAAYG,IAAIL,EAAgBV,IAEvC,IAAM5W,EAAiC,GACjCC,EAA+B,GACrC,OAAOrB,QAAK,WACV,IAAMxN,EAAU,IAAIwiB,EAChBrd,EAAKgd,UAAWvT,EAAgBC,EAChC1J,EAAK2f,qBACHxjB,OAAkC6D,EAAKgd,WAC7Cxd,OAAOiB,KAAKhD,GAAQiD,SAAQ,SAAAlG,GACpB,IAAA4B,OAACC,OACD4K,EAAoB,GAC1BA,QAAiBxJ,EAAOjD,GACxB2B,EAAWE,GAAY4K,KAIzB,IAFA,IAAMoa,EAAgBrhB,EAAKshB,mBAAmBnlB,GACxColB,EAA2D,GACxDjkB,EAAI,EAAGA,EAAI+iB,EAAapjB,OAAQK,IAAK,CAC5C,IAAM3C,EAAO0lB,EAAa/iB,GAC1B,IAAKnB,EAAWxB,EAAKH,MAAO,CAC1B,IAAMyM,EAAU+B,EAAUrO,EAAMwB,EAAYtB,GAC5C,GAAIoM,aAAmB6V,QACrB,MAAM,IAAIva,MACN,4BAA4B5H,EAAKuE,GAAjC,kEAGN/C,EAAWxB,EAAKH,MAAQyM,EACxBjH,EAAKwhB,uBACD7mB,EAAKH,KAAMG,EAAMwB,EAAYtB,EAASwmB,EAAejhB,EACrDmhB,IAOR,OAHmB,MAAfvhB,EAAKif,QACPpkB,EAAQqM,UAEH9G,EAAQ3E,KAAI,SAAAjB,GAAQ,OAAAc,EAAUd,EAAM2B,EAAYtB,UAInD2kB,+BAAR,SAA2B5kB,GACzB,IAAM6mB,EAAM,GAAGxiB,OAAO6E,MAClB,GACAtE,OAAOiB,KAAK7F,GACPa,KAAI,SAAAkF,GAAO,OAAA/F,EAAU+F,MACrBlF,KAAI,SAAAwL,GAAW,OAAAA,EAAQxL,KAAI,SAAAC,GAAU,OAAAA,EAAOqL,UACrD,OAAO,IAAIoX,IAAIsD,IAETjC,mCAAR,SACInjB,EAAkB1B,EAAYC,EAC9BC,EAA2BwmB,EAC3BK,EACAH,GAGoB,YAAlB5mB,EAAK6C,WAA6D,IAAnCkkB,EAAY1X,QAAQ3N,KAIvDzB,EAAUyB,GAAUqE,SAAQ,SAAAhF,GACZ,MAAVA,IACF6lB,EAAgC7lB,EAAOqL,KAClCwa,EAAgC7lB,EAAOqL,KAAO,GAC/CpM,EAAKiG,SAAS3D,WAGtBtC,EAAK8C,OAAOiD,SAAQ,SAAAc,GAGlB,GAAuB,YAAnBA,EAAMhE,SAAwB,CAChC,IAAMyJ,WzCxLVzM,EAAc2B,EACdtB,GACF,OAAOsB,EAAWO,EAAyBlC,EAAMK,EAAQgC,mByCuL/C8kB,CAA6BngB,EAAMhH,KAAMI,EAAWC,GACzC,MAAXoM,GACFA,EAAQvG,SAAQ,SAAAhF,GACd,GAAIA,IAAW2lB,EAAcxC,IAAInjB,EAAOqL,IAAK,CAC3C,IAAM6a,EAAQL,EAAgC7lB,EAAOqL,IACvC,IAAV6a,GACFlmB,EAAOwL,iBACAqa,EAAgC7lB,EAAOqL,KAC5B,MAAT6a,GAGTL,EAAgC7lB,EAAOqL,gBAkB/CyY,yBAAN,SAAmB/hB,EAAwB2C,sEAEzC,SAAOhB,KAAKyiB,cAAcpkB,EAAQ2C,WAiBtBof,0BAAd,SACI/hB,EAAwB2C,EAAmB0hB,EAC3CrY,EACAC,uBAF2CoY,mBAC3CrY,mBACAC,8GAgBgB,OAfboY,IACHrkB,EAAS2B,KAAKohB,UAAU/iB,GACxB2B,KAAKqhB,YAAYhjB,GACjB2B,KAAKshB,uBAAuBjjB,GAC5B2C,EAAUhB,KAAKuhB,WAAWvgB,GAC1BhB,KAAKwhB,aAAaxgB,IAGdvF,EAAU,IAAIwiB,EAChBje,KAAK4d,UAAWvT,EAAgBC,EAChCtK,KAAKugB,wBAKevgB,KAAK2iB,uBACzBtkB,EAAQ5C,EAASuF,EAAS0hB,WAsB9B,OAvBMlnB,EAAYwB,SAEZ4lB,EAAU5hB,EAAQ3E,KAAI,SAAAjB,GAAQ,OAAAc,EAAUd,EAAMI,EAAWC,MAGzDonB,EAAY,IAAI9D,IAAY6D,EAAQvmB,KAAI,SAAA8L,GAAK,OAAAA,EAAER,OAC/Cmb,EACF,IAAI/D,IAAY3e,OAAOiB,KAAKhD,GAAQhC,KAAI,SAAAjB,GAAQ,OAAAiD,EAAOjD,GAAMuM,OACjEvH,OAAOiB,KAAK7F,GAAW8F,SAAQ,SAAAC,GACT/F,EAAU+F,GAClBD,SAAQ,SAAAhF,IACdA,GAAWA,EAAOymB,YAAeF,EAAUpD,IAAInjB,EAAOqL,KACrDmb,EAASrD,IAAInjB,EAAOqL,MACkB,IAAvC/G,EAAKyf,UAAUzV,QAAQtO,EAAOqL,KAChCrL,EAAOwL,gBAKM,MAAf9H,KAAK6f,QACPpkB,EAAQqM,aAGH8a,WAGHxC,iCAAN,SACI/hB,EAAkBgM,EAClBC,mFAMF,OALM0Y,EAAe3kB,EAAO6B,QAAO,SAAC7D,EAAKC,EAAQY,GAE/C,OADAb,EAAIuE,EAAKvC,OAAOnB,GAAO9B,MAAQkB,EACxBD,IACN,OAEI2D,KAAKyiB,cACRO,EAAchjB,KAAK0hB,aAAa,EAAMrX,EAAgBC,WAS9C8V,mCAAd,SACI/hB,EAAwB5C,EAA2B6mB,EACnDI,wIACItE,EAAQhe,OAAOiB,KAAKhD,GACpBojB,EACFrD,EAAM/hB,KAAI,SAAAjB,GAAQ,OAAAwF,EAAKvB,MAAMsB,MAAMjD,EAActC,GAAM,OACrDsmB,EACFY,EAAYjmB,KAAI,SAAAjB,GAAQ,OAAAwF,EAAKvB,MAAMsB,MAAMjD,EAActC,GAAM,OAC3D4B,EACF6hB,EAAqBxgB,EAAQqjB,EAAa1hB,KAAK4d,WAD5CkB,cAAWE,kBAAeC,gBAAaC,eAGxC3W,EACEkZ,SAAezhB,KAAKX,MAAMqB,SAASrE,KAAI,SAAAd,GACzC,MAAO,CAACA,OAAM2iB,SAAUziB,EAAQwnB,mBAEhClmB,OAAkCiD,KAAK4d,WAC7Cxd,OAAOiB,KAAKhD,GAAQiD,SAAQ,SAAAlG,GACpB,IAAA4B,OAACC,OACD4K,EAAoB,GAC1BA,QAAiBxJ,EAAOjD,GACxB2B,EAAWE,GAAY4K,KAEnBsa,EAA2D,GAC3DF,EAAgBjiB,KAAKkiB,mBAAmBnlB,GACxCmmB,EAAkC,2BACjC3a,EAAM1K,OAAS,GACdslB,EAAWnjB,KAAKojB,aAClB3B,EAAYlZ,EAAO9M,EAASsB,EAAYmmB,EAAOjB,EAC/CK,EAAaH,EAAiCrD,MAC5CpB,QAAQ2F,IAAIF,yBAAlBjZ,sBAaF,GAXmB,MAAf+U,GAAwByD,GAC1B5K,QAAQC,KACJ,oIAGAuL,EACF5B,EACKhP,QACG,SAAAnX,GAAQ,OAAC+jB,GAAc/jB,KAClBW,EAAUX,EAAKH,KAAM2B,EAAYtB,MACzCY,KAAI,SAAAd,GAAQ,OAAAA,EAAKH,SACPyC,OAAS,EAO1B,MANI0lB,EAAiB,GACF,MAAftE,IACFsE,EACI,wFAC2BrE,OAE3B,IAAI/b,MACN,+BAA+BmgB,EAA/B,+BACWlF,EADX,gDAEIY,QAAmBuE,GAE7B,SAAOxmB,WAGDqjB,yBAAR,SACIqB,EAAoBlZ,EAA2B9M,EAC/CD,EAA4B0nB,EAC5BjB,EAA4BK,EAC5BH,EACArD,GAEF,IAPF,WAMQqE,EAAqC,gBAEzC,IAAMK,EAAOjb,EAAMmB,MACnBjO,EAAQwnB,eAAiBO,EAAKtF,SAC9B,IAAIjhB,EAAW,GAUf,GANqB,UAAjBumB,EAAKjoB,KAAKuE,IACVzE,EAAc,aAAcmoB,EAAKjoB,KAAMC,EAAWC,KACnDwB,wBAIoC,IAAnCwkB,EAAW7W,QAAQ4Y,EAAKjoB,MAAc,CACxC,IAAMsM,EAAU+B,EAAU4Z,EAAKjoB,KAAMC,EAAWC,GAC3CwB,IACFA,uBAEH,IAAMwmB,EAAiBhoB,EAAQwnB,eAC3Bpb,aAAmB6V,QACrByF,EAASpiB,KAAK8G,EAAQ8V,MAAK,SAAAxV,GAQzB,OAPA3M,EAAUyB,GAAYkL,EACtB1M,EAAQwnB,eAAiBQ,EACzB7iB,EAAKwhB,uBACDnlB,EAAUumB,EAAKjoB,KAAMC,EAAWC,EAASwmB,EACzCK,EAAaH,GACjBvhB,EAAK8iB,kBACDF,EAAKjoB,KAAMgN,EAAO9M,EAASD,EAAW0nB,EAAOpE,GAC1C3W,OAGT3M,EAAUyB,GAAY4K,EACtB8b,EAAKvB,uBACDnlB,EAAUumB,EAAKjoB,KAAMC,EAAWC,EAASwmB,EACzCK,EAAaH,GACjBwB,EAAKD,kBACDF,EAAKjoB,KAAMgN,EAAO9M,EAASD,EAAW0nB,EAAOpE,SAGnD6E,EAAKD,kBACDF,EAAKjoB,KAAMgN,EAAO9M,EAASD,EAAW0nB,EAAOpE,WAxC9CvW,EAAM1K,OAAS,OA2CtB,OAAOslB,GAGD/C,8BAAR,SACI7kB,EAAYgN,EAA2B9M,EACvCD,EAA4B0nB,EAC5BpE,GACFvjB,EAAKiG,SAASF,SAAQ,SAACsiB,GACd,IAAA3mB,kBACHimB,EAAMjmB,IAAc6hB,EAAUW,IAAImE,EAAUxoB,QAI3B,UAAjBwoB,EAAU9jB,GACR8jB,EAAUznB,WAAW0nB,MAAK,SAAAzoB,GACxB,QAASc,EAAUd,EAAMI,EAAWC,QAExCynB,EAAMjmB,IAAY,EAClBsL,EAAMxH,KAAK,CAACmd,SAAUziB,EAAQwnB,eAAgB1nB,KAAMqoB,KAGhDA,EAAUznB,WAAW+kB,OAAM,SAAA9lB,GACzB,QAASc,EAAUd,EAAMI,EAAWC,QAE5CynB,EAAMjmB,IAAY,EAClBsL,EAAMxH,KAAK,CAACmd,SAAUziB,EAAQwnB,eAAgB1nB,KAAMqoB,UAQ1DxD,oBAAA,WAAA,WACEhgB,OAAOiB,KAAKrB,KAAK4d,WACZtc,SACG,SAAAC,GAAO,OAAAX,EAAKgd,UAAUrc,GAAKD,SAAQ,SAAAhF,GAAU,OAAAA,EAAOwL,iBAGtDsY,mCAAR,SAA+B/hB,GAA/B,WACE+B,OAAOiB,KAAKhD,GAAQiD,SAAQ,SAAAlG,GAC1B,IAAMgH,EAAQ/D,EAAOjD,GACd6B,UACD1B,EAAOqF,EAAKvB,MAAMsB,MAAM1D,GAC9B,GAAI1B,EAAKsB,WAAkB,OAAKtB,EAAKsB,WAAkB,MAAEC,MAAO,CAC9D,IAAMgnB,EAAQvoB,EAAKsB,WAAkB,MAAEC,MACjCinB,EAAQD,EAAMjmB,SAAWuE,EAAMzF,MAAMkB,QACvCuE,EAAMzF,MAAMukB,OACR,SAAC/a,EAAKjJ,GAAU,OAAkB,IAAlB4mB,EAAM5mB,IAAiB4mB,EAAM5mB,KAAWiJ,KAChEU,OAAKC,OACDid,GACA,WAAM,MAAA,sBAAsBxoB,EAAKH,KAA3B,+CAC8B0oB,EAD9B,eAEE1hB,EAAMzF,aAEhBpB,EAAKsB,WAAkB,OAAKtB,EAAKsB,WAAkB,MAAEC,OACvD+J,OAAKC,OACD1E,EAAMoB,QAAUjI,EAAKsB,WAAkB,MAAEC,OACzC,WAAM,MAAA,sBAAsBvB,EAAKH,KAA3B,8CAECG,EAAKsB,WAAkB,MAAEC,mBAAkBsF,EAAMoB,aAK1D4c,sBAAR,SAAkB/hB,GAChB,IAAMwM,EAAyB,GAC/B,IAAK,IAAMrN,KAAaa,EAAQ,CAC9B,GAAuB,MAAnB2B,KAAKigB,YAAgD,MAA1BjgB,KAAKigB,WAAW5hB,QACN,MAArC2B,KAAKigB,WAAW5hB,OAAOb,GAEzBqN,EADe7K,KAAKigB,WAAW5hB,OAAOb,GACxBpC,MAAQiD,EAAOb,QAE7BqN,EAAOrN,GAAaa,EAAOb,GAG/B,OAAOqN,GAGDuV,wBAAR,SAAoB/hB,GAApB,WACQ2lB,EAAa5jB,OAAOiB,KAAKhD,GAAQqU,QAAO,SAAAtX,GACrC,IAAA6B,UACP,OAAqC,MAA9B2D,EAAKvB,MAAMsB,MAAM1D,MAE1B,GAAI+mB,EAAWnmB,OAAS,EACtB,MAAM,IAAIsF,MACN,uDACU6gB,mCAIV5D,uBAAR,SAAmBpf,GAAnB,WACE,OAAOA,EAAQ3E,KAAI,SAAAjB,GACjB,OAAuB,MAAnBwF,EAAKqf,YAAiD,MAA3Brf,EAAKqf,WAAWjf,SACV,MAAjCJ,EAAKqf,WAAWjf,QAAQ5F,GACXwF,EAAKqf,WAAWjf,QAAQ5F,GACzBA,KAETA,IACN,KAEGglB,yBAAR,SAAqBpf,GAArB,WACEA,EAAQM,SAAQ,SAAAlG,GACP,IAAA6oB,UACP,IAAKrjB,EAAKvB,MAAMsB,MAAMsjB,GACpB,MAAM,IAAI9gB,MAAM,eAAe/H,wDC/frC,WACY8oB,EACAC,gBAAAA,MADAnkB,cAAAkkB,EACAlkB,iBAAAmkB,EAvCJnkB,aAAU,MAwCG,MAAfmkB,IACFnkB,KAAKmkB,YAAc,IAoQzB,OAzSE/jB,sBAAIgkB,gCAAJ,WACE,OAAOpkB,KAAKqkB,yCAGdjkB,sBAAIgkB,8BAAJ,WACE,OAAOpkB,KAAKskB,SAAS7C,4CAGvBrhB,sBAAIgkB,+BAAJ,WACE,OAAOpkB,KAAKskB,SAAS5C,6CAGvBthB,sBAAIgkB,0BAAJ,WACE,OAAOpkB,KAAKskB,SAASjmB,wCAGvB+B,sBAAIgkB,2BAAJ,WACE,OAAOpkB,KAAKskB,SAAStjB,yCAGvBZ,sBAAIgkB,2BAAJ,WACE,OAAOpkB,KAAKskB,SAAS1G,2CAoBfwG,0BAAR,WACE,IAAMG,EAAOvkB,KAAKkkB,SAClB,GAAmC,MAA9BK,EAAsBC,KAEzBxkB,KAAKykB,QAAUF,OACV,GAAoC,MAAhCvkB,KAAKmkB,YAAYO,YAC1B1kB,KAAKykB,QAAUE,KAAGC,mBAAmBL,EAAgBvkB,KAAKmkB,iBACrD,CACL,IAAMU,EAAWF,KAAGG,gBAAgBP,EAAgBvkB,KAAKmkB,aACzD,GAAwB,IAApBU,EAAShnB,OAGXgnB,EAAS9jB,KAAK4jB,KAAGC,mBAAmBL,EAAgBvkB,KAAKmkB,mBACpD,GAAIU,EAAShnB,OAAS,EAC3B,MAAM,IAAIsF,MACN,wBAAwB0hB,EAAShnB,OAAjC,4BACQ,CAAC0mB,QAEfvkB,KAAKykB,QAAUI,EAAS,KAQtBT,iBAAN,2GAEE,GADApkB,KAAK+kB,gBACoB,MAArB/kB,KAAKykB,QAAQD,KACf,MAAM,IAAIrhB,MACN,iHAGY,SAAMnD,KAAKykB,QAAQD,eAErC,OAFMQ,EAAYhoB,YAEXgD,KAAKilB,SAASD,YAQvBZ,qBAAA,SAASY,GACPhlB,KAAKglB,UAAYA,EACjB,IAAM3lB,EAAQW,KAAKglB,UAAUE,cACzB3kB,EAAY,GAC0B,MAAtCP,KAAKglB,UAAUG,sBACjB5kB,EACKP,KAAKglB,UAAUG,oBAA4B5kB,WAIlDP,KAAKqkB,QAAahlB,EAAM+lB,SAASC,aAAYhmB,EAAM+lB,SAASE,YAC5D,IAAM1H,EACF+G,KAAGY,cAAcvlB,KAAKglB,UAAUQ,WAAYxlB,KAAKglB,UAAUS,aAI/D,OAHAzlB,KAAKskB,SAAW,IAAIlE,GAChB/f,EAAgBqlB,SAASC,eAAetmB,EAAOkB,IACnDP,KAAKskB,SAAS1G,UAAY5d,KAAK4lB,6BAA6BhI,IACrD,GAgDHwG,iBAAN,SAAWyB,EAAmCC,4EAE5C,GAA4B,iBAAjBD,EAA2B,CAEpC,GAAwB,KADlBhB,EAAWF,KAAGoB,gBAAgBF,IACvBhoB,OACX,MAAM,IAAIsF,MACN,0CAA0C0iB,OACzC,GAAIhB,EAAShnB,OAAS,EAC3B,MAAM,IAAIsF,MACN,wBAAwB0hB,EAAShnB,OAAjC,4BACQgoB,OAEdA,EAAehB,EAAS,GAE1B,GAAyB,MAArBgB,EAAaG,KACf,MAAM,IAAI7iB,MACN,+GAIN,SAAO0iB,EAAaG,KAAKhmB,KAAKglB,mBAwChCZ,oBAAA,SAAQ/lB,EAAwCynB,GAE9C,OAAO9lB,KAAKimB,QAAQ5nB,EAAQ2B,KAAK0hB,cAG3B0C,4BAAR,SAAwB/lB,GAEtB,KAAMA,aAAkB6nB,UAAY5hB,MAAMC,QAAQlG,IAEhD,OAAOA,EAGT,IADAA,EAASiG,MAAMC,QAAQlG,GAAUA,EAAS,CAACA,IAChCR,SAAWmC,KAAKyhB,WAAW5jB,OACpC,MAAM,IAAIsF,MACN,mDACuBnD,KAAKyhB,WAAW5jB,OADvC,kCAEmBQ,EAAOR,0BAEhC,OAAOmC,KAAKyhB,WAAWvhB,QAAO,SAAC7D,EAAKmB,EAAWU,GAE7C,OADA7B,EAAImB,GAAca,EAAoBH,GAC/B7B,IACN,KAGG+nB,6BAAR,SAAyBpjB,GAEvB,OADAA,EAAUA,GAAWhB,KAAK0hB,YAClBpd,MAAMC,QAAQvD,GAAuBA,EAAZ,CAACA,IAkBpCojB,oBAAA,SAAQ/lB,EAAwC2C,GAE9C3C,EAAS2B,KAAKmmB,gBAAgB9nB,GAC9B2C,EAAUhB,KAAKomB,iBAAiBplB,GAChC,IAAM6J,EAAS7K,KAAKskB,SAAS2B,QAAQ5nB,EAAQ2C,GAC7C,OAAO6J,EAAOhN,OAAS,EAAIgN,EAASA,EAAO,IAiBvCuZ,yBAAN,SACI/lB,EACA2C,mGAGa,OAFf3C,EAAS2B,KAAKmmB,gBAAgB9nB,GAC9B2C,EAAUhB,KAAKomB,iBAAiBplB,MACXhB,KAAKskB,SAAS+B,aAAahoB,EAAQ2C,WACxD,UADM6J,EAAS7N,UACDa,OAAS,EAAIgN,EAASA,EAAO,YAGrCuZ,yCAAR,SAAqC/nB,GACnC,OAAO+D,OAAOiB,KAAKhF,GAAK6D,QAAO,SAAComB,EAAyB/kB,GAEvD,OADA+kB,EAAO/kB,GAAO,CAAClF,EAAIkF,IACZ+kB,IACN,KAOLlC,oBAAA,WACEpkB,KAAKskB,SAASxc,wD3CtQW1M,UACpBF,EAAWE,8B2CuShB8oB,EACAqC,uBAAAA,+FACF,GAAgB,MAAZrC,EACF,MAAM,IAAI/gB,MACN,0GAgBN,OAbe,MAAXojB,IACFA,EAAU,IAGRA,EAAQC,WAC6B,MAAlCtC,EAA0BM,OACvBN,EAAoBuC,SAAS,OACjCvC,GAAkC,KAEpCA,GAAW,mCAGTwC,EAAQ,IAAItC,GAAWF,EAAUqC,IAC3B/B,eACZ,OADAxnB,YACO0pB,iC3C1VkBtrB,EAAcurB,GACvC,IAAMnJ,EAAqB,CACzBrf,SAAU/C,EACVgD,SAAU,SACVC,OAAQ,GACRC,MAAO,GACPmf,eAAgBkJ,GAGlBzrB,EAAWE,GAAQoiB,uB4CpDL"}